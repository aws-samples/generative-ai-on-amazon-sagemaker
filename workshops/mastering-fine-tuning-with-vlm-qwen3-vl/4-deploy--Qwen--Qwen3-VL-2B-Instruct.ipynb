{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a8b6105-ecec-4213-b56d-589238844dca",
   "metadata": {},
   "source": [
    "# Model deployment with Amazon SageMaker AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae8979e-d4ff-4fbf-a258-f7ce6c30a4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import json\n",
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.estimator import Estimator\n",
    "from nb_local_utils.helpers import (\n",
    "    pretty_print_html,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a8dde1-0a05-4f5b-a8aa-449faeba9973",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = Session()\n",
    "sagemaker_session_bucket = None\n",
    "\n",
    "if sagemaker_session_bucket is None and sagemaker_session is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.session.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client(\"iam\")\n",
    "    role = iam.get_role(RoleName=\"sagemaker_execution_role\")[\"Role\"][\"Arn\"]\n",
    "\n",
    "sagemaker_session = Session(default_bucket=sagemaker_session_bucket)\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix\n",
    "\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=sagemaker_session.boto_region_name)\n",
    "sts = boto3.client(\"sts\", region_name=sagemaker_session.boto_region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8689204e-4e37-45bd-9a01-6229547c8c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print_html(f\"sagemaker role arn: {role}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec89fdbf-6dd7-4263-9a9a-4932792b707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print_html(f\"sagemaker bucket: {sagemaker_session_bucket}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf58248-71b3-4ddc-b959-b985c7a55b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print_html(f\"sagemaker session region: {sagemaker_session.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c64bded-48a3-44cb-a39c-6e73fb5b2f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r full_training_job_name\n",
    "pretty_print_html(f\"Your training job name: {full_training_job_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ee8524-78cf-41e4-964a-c2a3b28ddb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_state = Estimator.attach(\n",
    "    training_job_name=full_training_job_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77bbc25-2008-4e28-948e-c82a6f887904",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_model_data_uri = estimator_state.model_data\n",
    "pretty_print_html(f\"Fine-tuned model location: {s3_model_data_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c7c70f",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd2070",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_S3_URI = os.path.join(s3_model_data_uri[\"S3DataSource\"][\"S3Uri\"], \"Qwen/Qwen3-VL-2B-Instruct/full_model/\")\n",
    "\n",
    "model_id = \"Qwen/Qwen3-VL-2B-Instruct\"\n",
    "\n",
    "model_name = f\"{model_id.split(\"/\")[-1].replace(\".\", \"-\")}-vllm\"\n",
    "endpoint_config_name = f\"{model_id.split(\"/\")[-1].replace(\".\", \"-\")}-config\"\n",
    "endpoint_name = f\"{model_id.split('/')[-1].replace('.', '-')}\"\n",
    "ic_name = f\"custom-{model_id.split('/')[-1].replace('.', '-')}-vllm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b017d7-7653-4a16-a78a-1d094ffb2cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print_html(f\"- Model: {model_name}\\n- Endpoint Config: {endpoint_config_name}\\n- Endpoint: {endpoint_name}\\n- Inference Component: {ic_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de767b0",
   "metadata": {},
   "source": [
    "### Utility functions\n",
    "\n",
    "Utility functions to check the creation status of endpoints and inference components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3815a3df-4d64-4aec-b2a5-e2c46ea15496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fba24df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_endpoint(sm_client, endpoint_name):\n",
    "    while True:\n",
    "        status = sm_client.describe_endpoint(EndpointName=endpoint_name)[\n",
    "            \"EndpointStatus\"\n",
    "        ]\n",
    "        print(f\"Endpoint status: {status}\")\n",
    "        if status in [\"InService\", \"Failed\"]:\n",
    "            return status\n",
    "        time.sleep(30)\n",
    "\n",
    "\n",
    "def wait_for_inference_component(sm_client, component_name):\n",
    "    while True:\n",
    "        status = sm_client.describe_inference_component(\n",
    "            InferenceComponentName=component_name\n",
    "        )[\"InferenceComponentStatus\"]\n",
    "        print(f\"Inference component status: {status}\")\n",
    "        if status in [\"InService\", \"Failed\"]:\n",
    "            return status\n",
    "        time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da81686e-d27f-4c7b-bec6-f596e7dbaa32",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8328b8fd-737d-4555-9824-56de5e202825",
   "metadata": {},
   "source": [
    "# Model Deployment\n",
    "\n",
    "In the following sections, we are going to deploy the fine-tuned model on an Amazon SageMaker Real-time endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f9b625-a113-43bc-befa-35294ec97a09",
   "metadata": {},
   "source": [
    "#### Delete Existing SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582bf680-91a0-440f-a653-5e5755b1423e",
   "metadata": {},
   "source": [
    "Let's delete a pre-existing `tuned-Qwen3-VL-2B-Instruct-*` ARNs that was predeployed for this workshop. You need to delete,\n",
    "1. Endpoint (Deployed endpoint consuming a `ml.g5.2xlarge`)\n",
    "2. Endpoint Config (Endpoint configuration ARN associated with deployed endpoint)\n",
    "3. Model (Model ARN associated with deployed endpoint)\n",
    "\n",
    "> [!WARNING]\n",
    "> Please dont change the values in the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc01a48-9238-4402-be77-45ae75174bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tuned_endpoint_name=\"tuned-Qwen3-VL-2B-Instruct-ep\"\n",
    "old_tuned_endpoint_config_name=\"tuned-Qwen3-VL-2B-Instruct-ep-config\"\n",
    "old_tuned_model_name=\"tuned-Qwen3-VL-2B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7100cc-a15b-43a8-8fb5-360272d7278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sm_client.delete_endpoint(EndpointName=old_tuned_endpoint_name)\n",
    "    time.sleep(2)\n",
    "    pretty_print_html(f\"Deleted EndpointName: {old_tuned_endpoint_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Issue deleting EndpointName, its likely deleted: {old_tuned_endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc520b-5b9d-4974-a7e6-400b7e5a260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sm_client.delete_endpoint_config(EndpointConfigName=old_tuned_endpoint_config_name)\n",
    "    time.sleep(2)\n",
    "    pretty_print_html(f\"Deleted EndpointConfigName: {old_tuned_endpoint_config_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Issue deleting EndpointConfigName, its likely deleted: {old_tuned_endpoint_config_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ba404f-f307-4919-8a67-0a77aaab0526",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    sm_client.delete_model(ModelName=old_tuned_model_name)\n",
    "    time.sleep(2)\n",
    "    pretty_print_html(f\"Deleted ModelName: {old_tuned_model_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Issue deleting ModelName, its likely deleted: {old_tuned_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ad916f-fd81-4a80-9400-a3b641f127db",
   "metadata": {},
   "source": [
    "#### Waiter for Instance Clean up - **[Mandatory]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0e51d2-4c98-425b-ac68-4b60b8c46936",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sleeping for a few seconds for instance free up...\")\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eeba4b-cfc9-4aae-be86-8d2f3c4e5cb0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Inference configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f29f2d8-b3b3-4b27-a0d2-e49812f56a21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:41:10.492877Z",
     "start_time": "2023-11-20T18:41:10.488495Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "instance_count = 1\n",
    "instance_type = \"ml.g5.2xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 700"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edee6e30",
   "metadata": {},
   "source": [
    "#### Create the Endpoint configuration\n",
    "\n",
    "An Endpoint Configuration in SageMaker defines which model(s), instance type, and scaling settings an endpoint should use when it is created or deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c0c00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "            \"InstanceType\": instance_type,\n",
    "            \"InitialInstanceCount\": instance_count,\n",
    "            \"ModelDataDownloadTimeoutInSeconds\": health_check_timeout,\n",
    "            \"RoutingConfig\": {\"RoutingStrategy\": \"LEAST_OUTSTANDING_REQUESTS\"},\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "pretty_print_html(json.dumps(endpoint_config_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429d546f",
   "metadata": {},
   "source": [
    "#### Create endpoint\n",
    "\n",
    "A SageMaker Endpoint is a fully managed, always-on HTTPS API that hosts your deployed model and serves real-time inference requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9035076-ac69-4859-9824-dcbf07c0f2b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:45:49.265298Z",
     "start_time": "2023-11-20T18:41:14.621743Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "\n",
    "pretty_print_html(json.dumps(endpoint_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef96ac41",
   "metadata": {},
   "source": [
    "Let's wait for the creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687c7fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_for_endpoint(sm_client, endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ce2781",
   "metadata": {},
   "source": [
    "#### Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831f366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "account_id = sts.get_caller_identity()[\"Account\"]\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "repo_name = \"qwen3-vl-vllm\"\n",
    "tag = \"latest\"\n",
    "\n",
    "image_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{repo_name}:{tag}\"\n",
    "\n",
    "pretty_print_html(f\"Using inference image URI: {image_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21d8f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = {\n",
    "    \"OPTION_MODEL\": \"/opt/ml/model/\",\n",
    "    \"OPTION_SERVED_MODEL_NAME\": \"model\",\n",
    "    \"OPTION_TENSOR_PARALLEL_SIZE\": json.dumps(number_of_gpu),\n",
    "    \"OPTION_DTYPE\": \"bfloat16\",\n",
    "    \"OPTION_MAX_MODEL_LEN\": json.dumps(1024 * 16),\n",
    "    \"OPTION_GPU_MEMORY_UTILIZATION\": \"0.85\",\n",
    "    \"OPTION_LIMIT_MM_PER_PROMPT\": json.dumps({\"image\": 5, \"video\": 0}),\n",
    "    \"OMP_NUM_THREADS\": \"1\",\n",
    "}\n",
    "\n",
    "pretty_print_html(f\"Model Environment: {json.dumps(env)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14541e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\n",
    "        \"Image\": image_uri,\n",
    "        \"Environment\": env,\n",
    "        \"ModelDataSource\": {\n",
    "            \"S3DataSource\": {\n",
    "                \"S3Uri\": MODEL_S3_URI,\n",
    "                \"S3DataType\": \"S3Prefix\",\n",
    "                \"CompressionType\": \"None\",\n",
    "            }\n",
    "        },\n",
    "    },\n",
    ")\n",
    "pretty_print_html(json.dumps(model_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7d1d49",
   "metadata": {},
   "source": [
    "#### Create inference component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8898f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_response = sm_client.create_inference_component(\n",
    "    InferenceComponentName=ic_name,\n",
    "    EndpointName=endpoint_name,\n",
    "    VariantName=\"AllTraffic\",\n",
    "    Specification={\n",
    "        \"ModelName\": model_name,\n",
    "        \"ComputeResourceRequirements\": {\n",
    "            \"MinMemoryRequiredInMb\": 12288,\n",
    "            \"NumberOfAcceleratorDevicesRequired\": 1,\n",
    "        },\n",
    "    },\n",
    "    RuntimeConfig={\"CopyCount\": 1},\n",
    ")\n",
    "\n",
    "pretty_print_html(json.dumps(ic_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1ccd45",
   "metadata": {},
   "source": [
    "Let's wait for the creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303315f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_for_inference_component(sm_client, ic_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f340402",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9903dfa6",
   "metadata": {},
   "source": [
    "## Test endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46179b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import boto3\n",
    "import base64\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7538e9b8-4468-4dd3-923a-ac2ace1567e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client = boto3.client(service_name=\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e32e092",
   "metadata": {},
   "source": [
    "### Iterator class for streaming inference\n",
    "\n",
    "Utility class to parse streaming responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineIterator:\n",
    "    def __init__(self, stream):\n",
    "        self.byte_iterator = iter(stream)\n",
    "        self.buffer = io.BytesIO()\n",
    "        self.read_pos = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        while True:\n",
    "            self.buffer.seek(self.read_pos)\n",
    "            line = self.buffer.readline()\n",
    "\n",
    "            if line and line[-1] == ord(\"\\n\"):\n",
    "                self.read_pos += len(line)\n",
    "                return line[:-1]\n",
    "\n",
    "            try:\n",
    "                chunk = next(self.byte_iterator)\n",
    "            except StopIteration:\n",
    "                if self.read_pos < self.buffer.getbuffer().nbytes:\n",
    "                    continue\n",
    "                raise\n",
    "\n",
    "            if \"PayloadPart\" not in chunk:\n",
    "                continue\n",
    "\n",
    "            self.buffer.seek(0, io.SEEK_END)\n",
    "            self.buffer.write(chunk[\"PayloadPart\"][\"Bytes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068b443d",
   "metadata": {},
   "source": [
    "Utility function to parse model answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45d59d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_streaming_response(line_str):\n",
    "    \"\"\"Parse a single streaming response line and return content if found.\"\"\"\n",
    "    if not line_str.strip() or line_str.strip() == \"data: [DONE]\":\n",
    "        return None\n",
    "\n",
    "    if line_str.startswith(\"data: \"):\n",
    "        line_str = line_str[6:]\n",
    "\n",
    "    try:\n",
    "        data = json.loads(line_str)\n",
    "        if \"choices\" in data:\n",
    "            for choice in data[\"choices\"]:\n",
    "                if \"delta\" in choice and \"content\" in choice[\"delta\"]:\n",
    "                    return choice[\"delta\"][\"content\"]\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6a00b9",
   "metadata": {},
   "source": [
    "Utility function to convert an image in base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac5df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_to_base64(pil_img, resize_perc=0.5):\n",
    "    \"\"\"Convert a PIL image to base64-encoded PNG string.\"\"\"\n",
    "    pil_img = pil_img.resize([int(resize_perc * s) for s in pil_img.size])\n",
    "    buffer = BytesIO()\n",
    "    pil_img.save(buffer, format=\"PNG\")\n",
    "    return base64.b64encode(buffer.getvalue()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f3a010",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Describe the content of the image\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b42c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "img = Image.open(\"./images/image_1.png\")\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0eb3e1-a8f5-4f10-8191-4f290fb76577",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_base64 = pil_to_base64(img)\n",
    "\n",
    "request_body = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64}\"},\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 4096,\n",
    "    \"temperature\": 0.3,\n",
    "    \"top_p\": 0.9,\n",
    "    \"stop\": [\"<|im_end|>\"],\n",
    "    \"stream\": True,\n",
    "}\n",
    "\n",
    "response = sagemaker_client.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    InferenceComponentName=ic_name,\n",
    "    Body=json.dumps(request_body),\n",
    "    ContentType=\"application/json\",\n",
    ")\n",
    "\n",
    "generated_text = \"\"\n",
    "\n",
    "for line in LineIterator(response[\"Body\"]):\n",
    "    if line:\n",
    "        content = parse_streaming_response(line.decode(\"utf-8\"))\n",
    "        if content:\n",
    "            generated_text += content\n",
    "            print(content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6d81c4",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82d65c1",
   "metadata": {},
   "source": [
    "## Delete resources (Uncomment to Delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64013bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boto3\n",
    "\n",
    "# sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "# model_id = \"Qwen/Qwen3-VL-2B-Instruct\"\n",
    "\n",
    "# model_name = f\"{model_id.split(\"/\")[-1].replace(\".\", \"-\")}-vllm\"\n",
    "# endpoint_config_name = f\"{model_id.split(\"/\")[-1].replace(\".\", \"-\")}-config\"\n",
    "# endpoint_name = f\"{model_id.split('/')[-1].replace('.', '-')}\"\n",
    "# ic_name = f\"custom-{model_id.split('/')[-1].replace('.', '-')}-vllm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cfdf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delete inference component\n",
    "# sm_client.delete_inference_component(InferenceComponentName=ic_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2806c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delete model\n",
    "# sm_client.delete_model(ModelName=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399b3817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delete endpoint config (optional)\n",
    "# sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20009321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delete endpoint (optional - if you want to remove the endpoint too)\n",
    "# sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4513ea2b-dcd2-4fdb-affe-806f70746cc5",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "END OF LAB 4\n",
    "--- \n",
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
