{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e853a14",
   "metadata": {},
   "source": [
    "# Supervised Fine-Tuning (SFT) with Serverless customization on SageMaker AI\n",
    "\n",
    "## Lab 4 - LLM Deployment\n",
    "\n",
    "In this notebook, we are going to deploy the fine-tuned LLM using SageMaker Real-time endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b6949b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a0a20b",
   "metadata": {},
   "source": [
    "### Prerequistes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f431a9f",
   "metadata": {},
   "source": [
    "#### Setup and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dd0c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "from rich.pretty import pprint\n",
    "from sagemaker.core.helper.session_helper import Session, get_execution_role\n",
    "\n",
    "sess = Session()\n",
    "sagemaker_session_bucket = None\n",
    "\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client(\"iam\")\n",
    "    role = iam.get_role(RoleName=\"sagemaker_execution_role\")[\"Role\"][\"Arn\"]\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sess = Session(default_bucket=sagemaker_session_bucket)\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=sess.boto_region_name)\n",
    "bucket_name = sess.default_bucket()\n",
    "default_prefix = sess.default_bucket_prefix\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89088cc1",
   "metadata": {},
   "source": [
    "Edit model package group name and model package version if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4206486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.core.resources import ModelPackage, ModelPackageGroup\n",
    "\n",
    "base_model_id = \"huggingface-llm-qwen2-5-7b-instruct\"\n",
    "\n",
    "model_package_group_name = f\"{base_model_id}-mpg\"\n",
    "model_package_version = \"1\"\n",
    "\n",
    "model_name = f\"{base_model_id}-sft\"\n",
    "endpoint_config_name = f\"{base_model_id}-sft-config\"\n",
    "endpoint_name = f\"{base_model_id}-sft-endpoint\"\n",
    "ic_name = f\"{base_model_id}-sft-ic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e911f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_group = ModelPackageGroup.get(model_package_group_name)\n",
    "\n",
    "fine_tuned_model_package_group_arn = model_package_group.model_package_group_arn\n",
    "print(f\"Fine-tuned Model Package Group ARN: {fine_tuned_model_package_group_arn}\")\n",
    "\n",
    "fine_tuned_model_package_arn = f\"{model_package_group.model_package_group_arn.replace(\"model-package-group\", \"model-package\", 1)}/{model_package_version}\"\n",
    "print(f\"Fine-tuned Model Package ARN: {fine_tuned_model_package_arn}\")\n",
    "\n",
    "model_package = ModelPackage.get(fine_tuned_model_package_arn)\n",
    "\n",
    "model_s3_uri = os.path.join(model_package.inference_specification.containers[0].model_data_source.s3_data_source.s3_uri, \"checkpoints\", \"hf_merged\")\n",
    "if not model_s3_uri.endswith(\"/\"):\n",
    "    model_s3_uri += \"/\"\n",
    "print(f\"Fine-tuned Model S3 Path: {model_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42771136",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee351ee0",
   "metadata": {},
   "source": [
    "### Utility functions\n",
    "\n",
    "Utility functions to check the creation status of endpoints and inference components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aa553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd003cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_endpoint(sm_client, endpoint_name):\n",
    "    while True:\n",
    "        status = sm_client.describe_endpoint(EndpointName=endpoint_name)[\n",
    "            \"EndpointStatus\"\n",
    "        ]\n",
    "        print(f\"Endpoint status: {status}\")\n",
    "        if status in [\"InService\", \"Failed\"]:\n",
    "            return status\n",
    "        time.sleep(30)\n",
    "\n",
    "\n",
    "def wait_for_inference_component(sm_client, component_name):\n",
    "    while True:\n",
    "        status = sm_client.describe_inference_component(\n",
    "            InferenceComponentName=component_name\n",
    "        )[\"InferenceComponentStatus\"]\n",
    "        print(f\"Inference component status: {status}\")\n",
    "        if status in [\"InService\", \"Failed\"]:\n",
    "            return status\n",
    "        time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a65760",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f461ff",
   "metadata": {},
   "source": [
    "### Create Endpoint Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419e1659",
   "metadata": {},
   "source": [
    "Define inference configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b880a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_count = 1\n",
    "instance_type = \"ml.g5.2xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a6c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "            \"InstanceType\": instance_type,\n",
    "            \"InitialInstanceCount\": instance_count,\n",
    "            \"ModelDataDownloadTimeoutInSeconds\": health_check_timeout,\n",
    "            \"RoutingConfig\": {\"RoutingStrategy\": \"LEAST_OUTSTANDING_REQUESTS\"},\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "pprint(endpoint_config_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa07dafe",
   "metadata": {},
   "source": [
    "### Create Endpoint\n",
    "\n",
    "A SageMaker Endpoint is a fully managed, always-on HTTPS API that hosts your deployed model and serves real-time inference requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81084de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "\n",
    "pprint(endpoint_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186077a6",
   "metadata": {},
   "source": [
    "Let's wait for the creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495b5f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_for_endpoint(sm_client, endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eb6a0d",
   "metadata": {},
   "source": [
    "### Create Model from Model Package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a99d052",
   "metadata": {},
   "source": [
    "Get the image URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d5f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.core import image_uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ecdc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = image_uris.retrieve(\n",
    "    framework=\"djl-lmi\",\n",
    "    region=sess.boto_region_name,\n",
    "    version=\"latest\",\n",
    ")\n",
    "\n",
    "image_uri = image_uri.split(\"/\")[0] + \"/djl-inference:0.36.0-lmi18.0.0-cu128\"\n",
    "\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c3de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = {\n",
    "    \"HF_MODEL_ID\": \"/opt/ml/model\",  # path to where sagemaker stores the model\n",
    "    \"OPTION_TRUST_REMOTE_CODE\": \"true\",\n",
    "    \"OPTION_MODEL_LOADING_TIMEOUT\": \"3600\",\n",
    "    \"OPTION_TENSOR_PARALLEL_DEGREE\": \"max\",\n",
    "    \"SERVING_FAIL_FAST\": \"true\",\n",
    "    \"OPTION_ROLLING_BATCH\": \"disable\",\n",
    "    \"OPTION_ASYNC_MODE\": \"true\",\n",
    "    \"OPTION_ENTRYPOINT\": \"djl_python.lmi_vllm.vllm_async_service\",\n",
    "    \"OPTION_DTYPE\": \"bf16\",\n",
    "    \"OPTION_QUANTIZE\": \"fp8\",\n",
    "    \"OPTION_MAX_MODEL_LEN\": json.dumps(1024 * 32)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ecb663",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\n",
    "        \"Image\": image_uri,\n",
    "        \"Environment\": env,\n",
    "        \"ModelDataSource\": {\n",
    "            \"S3DataSource\": {\n",
    "                \"S3Uri\": model_s3_uri,\n",
    "                \"S3DataType\": \"S3Prefix\",\n",
    "                \"CompressionType\": \"None\",\n",
    "            }\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "pprint(model_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6171776f",
   "metadata": {},
   "source": [
    "### Create Inference Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effa4f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_response = sm_client.create_inference_component(\n",
    "    InferenceComponentName=ic_name,\n",
    "    EndpointName=endpoint_name,\n",
    "    VariantName=\"AllTraffic\",\n",
    "    Specification={\n",
    "        \"ModelName\": model_name,\n",
    "        \"ComputeResourceRequirements\": {\n",
    "            \"MinMemoryRequiredInMb\": 12288,\n",
    "            \"NumberOfAcceleratorDevicesRequired\": 1,\n",
    "        },\n",
    "    },\n",
    "    RuntimeConfig={\"CopyCount\": 1},\n",
    ")\n",
    "\n",
    "pprint(ic_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea57435",
   "metadata": {},
   "source": [
    "Let's wait for the creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0b2ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_for_inference_component(sm_client, ic_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad58db98",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aed6e4c",
   "metadata": {},
   "source": [
    "### Test endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406ab812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84e657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client = boto3.client(service_name=\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18b62cf",
   "metadata": {},
   "source": [
    "### Iterator class for streaming inference\n",
    "\n",
    "Utility class to parse streaming responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0b2e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineIterator:\n",
    "    def __init__(self, stream):\n",
    "        self.byte_iterator = iter(stream)\n",
    "        self.buffer = io.BytesIO()\n",
    "        self.read_pos = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        while True:\n",
    "            self.buffer.seek(self.read_pos)\n",
    "            line = self.buffer.readline()\n",
    "\n",
    "            if line and line[-1] == ord(\"\\n\"):\n",
    "                self.read_pos += len(line)\n",
    "                return line[:-1]\n",
    "\n",
    "            try:\n",
    "                chunk = next(self.byte_iterator)\n",
    "            except StopIteration:\n",
    "                if self.read_pos < self.buffer.getbuffer().nbytes:\n",
    "                    continue\n",
    "                raise\n",
    "\n",
    "            if \"PayloadPart\" not in chunk:\n",
    "                continue\n",
    "\n",
    "            self.buffer.seek(0, io.SEEK_END)\n",
    "            self.buffer.write(chunk[\"PayloadPart\"][\"Bytes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5211bfc9",
   "metadata": {},
   "source": [
    "Utility function to parse model answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13c87e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_streaming_response(line_str):\n",
    "    \"\"\"Parse a single streaming response line and return content if found.\"\"\"\n",
    "    if not line_str.strip() or line_str.strip() == \"data: [DONE]\":\n",
    "        return None\n",
    "\n",
    "    if line_str.startswith(\"data: \"):\n",
    "        line_str = line_str[6:]\n",
    "\n",
    "    try:\n",
    "        data = json.loads(line_str)\n",
    "        if \"choices\" in data:\n",
    "            for choice in data[\"choices\"]:\n",
    "                if \"delta\" in choice and \"content\" in choice[\"delta\"]:\n",
    "                    return choice[\"delta\"][\"content\"]\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0048bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Regarding the temporomandibular joint, which statements are true or false: \n",
    "Is the temporomandibular joint a synovial joint? \n",
    "Is the articular disc a remnant of the tendon of the medial pterygoid? \n",
    "Do gliding movements occur in the lower compartment and rotatory movements occur in the upper compartment? \n",
    "Is the joint capsule thick and tight in the lower part and loose and lax in the upper part? \n",
    "Does the sphenomandibular ligament act as a false support to the joint and attach to the angle of the mandible?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8596d43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_body = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 4096,\n",
    "    \"temperature\": 0.3,\n",
    "    \"top_p\": 0.9,\n",
    "    \"stop\": [\"<|im_end|>\"],\n",
    "    \"stream\": True,\n",
    "}\n",
    "\n",
    "response = sagemaker_client.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    InferenceComponentName=ic_name,\n",
    "    Body=json.dumps(request_body),\n",
    "    ContentType=\"application/json\",\n",
    ")\n",
    "\n",
    "generated_text = \"\"\n",
    "\n",
    "for line in LineIterator(response[\"Body\"]):\n",
    "    if line:\n",
    "        content = parse_streaming_response(line.decode(\"utf-8\"))\n",
    "        if content:\n",
    "            generated_text += content\n",
    "            print(content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496d7fc7",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f49cb0c",
   "metadata": {},
   "source": [
    "### Delete resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e1beb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "base_model_id = \"huggingface-llm-qwen2-5-7b-instruct\"\n",
    "\n",
    "model_name = f\"{base_model_id}-sft\"\n",
    "endpoint_config_name = f\"{base_model_id}-sft-config\"\n",
    "endpoint_name = f\"{base_model_id}-sft-endpoint\"\n",
    "ic_name = f\"{base_model_id}-sft-ic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6386ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete inference component\n",
    "sm_client.delete_inference_component(InferenceComponentName=ic_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a27b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete model\n",
    "sm_client.delete_model(ModelName=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cd8274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete endpoint config (optional)\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a529aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete endpoint (optional - if you want to remove the endpoint too)\n",
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python312-sm3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
