{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe766eb7",
   "metadata": {},
   "source": [
    "# Reinforcement Learning from Verifiable Rewards (RLVR) with SageMaker\n",
    "\n",
    "## Lab 2 — Fine-Tuning with RLVRTrainer\n",
    "\n",
    "In this lab, you will launch a **serverless RLVR training job** using the SageMaker `RLVRTrainer` to fine-tune **Qwen 2.5 — 7B Instruct** on the math dataset you prepared in Lab 1.\n",
    "\n",
    "### What you'll do in this notebook\n",
    "\n",
    "1. Set up your SageMaker session and retrieve the datasets from Lab 1\n",
    "2. Create a Model Package Group to store the fine-tuned model\n",
    "3. Configure the `RLVRTrainer` with model, data, and hyperparameters\n",
    "4. Submit the serverless training job and monitor progress\n",
    "\n",
    "### How serverless RLVR training works\n",
    "\n",
    "With SageMaker serverless customization, you don't need to provision or manage any compute infrastructure. SageMaker automatically:\n",
    "- Selects the right instance types and cluster size for your model\n",
    "- Runs the RLVR training loop (policy rollouts → reward verification → policy update)\n",
    "- Logs metrics to MLflow for experiment tracking\n",
    "- Saves the fine-tuned model to S3 and registers it in the Model Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8e9836",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Prerequisites\n",
    "\n",
    "### Set up the SageMaker session\n",
    "\n",
    "We initialize the SageMaker session and resolve the IAM role, just like in Lab 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bee7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "from sagemaker.core.helper.session_helper import Session, get_execution_role\n",
    "\n",
    "sess = Session()\n",
    "sagemaker_session_bucket = None\n",
    "\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client(\"iam\")\n",
    "    role = iam.get_role(RoleName=\"sagemaker_execution_role\")[\"Role\"][\"Arn\"]\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sess = Session(default_bucket=sagemaker_session_bucket)\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=sess.boto_region_name)\n",
    "bucket_name = sess.default_bucket()\n",
    "default_prefix = sess.default_bucket_prefix\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retrieve_datasets_header",
   "metadata": {},
   "source": [
    "### Retrieve datasets and configure the job\n",
    "\n",
    "We fetch the training and validation datasets that were registered in the SageMaker AI Registry during Lab 1. We also define the base model ID, output path, and MLflow experiment name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a604450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.ai_registry.dataset import DataSet\n",
    "\n",
    "# Required config\n",
    "base_model_id = \"huggingface-llm-qwen2-5-7b-instruct\"\n",
    "training_dataset = DataSet.get(name=\"rlvr-train\")\n",
    "validation_dataset = DataSet.get(name=\"rlvr-val\")\n",
    "\n",
    "# Optional configs\n",
    "job_name = f\"rlvr-{base_model_id.split('/')[-1].replace('.', '-')}\"\n",
    "mlflow_experiment_name = \"qwen2-5-7b-rlvr\"\n",
    "\n",
    "if default_prefix:\n",
    "    output_path = f\"s3://{bucket_name}/{default_prefix}/{base_model_id}-rlvr\"\n",
    "else:\n",
    "    output_path = f\"s3://{bucket_name}/{base_model_id}-rlvr\"\n",
    "\n",
    "os.environ[\"SAGEMAKER_MLFLOW_CUSTOM_ENDPOINT\"] = (\n",
    "    f\"https://mlflow.sagemaker.{sess.boto_region_name}.app.aws\"\n",
    ")\n",
    "\n",
    "print(f\"Base model:    {base_model_id}\")\n",
    "print(f\"Training data: {training_dataset.arn}\")\n",
    "print(f\"Val data:      {validation_dataset.arn}\")\n",
    "print(f\"Output path:   {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ead4b63",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Create a Model Package Group\n",
    "\n",
    "A **Model Package Group** is a container in the SageMaker Model Registry that holds versioned model artifacts. Each time you run a training job, the resulting model is saved as a new version in this group — making it easy to compare runs and roll back if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b463d77a-91c7-42ea-82f8-8612bbfb8a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.core.resources import ModelPackageGroup\n",
    "\n",
    "model_package_group_name = f\"{base_model_id}-rlvr\"\n",
    "\n",
    "model_package_group = ModelPackageGroup.create(\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    model_package_group_description='Store models from SageMaker serverless RLVR customization'\n",
    ")\n",
    "\n",
    "print(f\"Model Package Group: {model_package_group_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trainer_header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Configure the RLVR Trainer\n",
    "\n",
    "The `RLVRTrainer` is the high-level API for serverless RLVR training. You provide:\n",
    "\n",
    "| Parameter | Description |\n",
    "|---|---|\n",
    "| `model` | Base model ID from the SageMaker Hub |\n",
    "| `training_dataset` | Registered training dataset from the AI Registry |\n",
    "| `validation_dataset` | Registered validation dataset from the AI Registry |\n",
    "| `model_package_group` | Where to store the fine-tuned model versions |\n",
    "| `s3_output_path` | S3 location for model artifacts |\n",
    "| `mlflow_experiment_name` | MLflow experiment name for metric tracking |\n",
    "\n",
    "> **Note:** Setting `accept_eula=True` is required for gated models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7abd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.train.rlvr_trainer import RLVRTrainer\n",
    "\n",
    "trainer = RLVRTrainer(\n",
    "    model=base_model_id,\n",
    "    model_package_group=model_package_group,\n",
    "    training_dataset=training_dataset,\n",
    "    validation_dataset=validation_dataset,\n",
    "    s3_output_path=output_path,\n",
    "    mlflow_experiment_name=mlflow_experiment_name,\n",
    "    base_job_name=job_name,\n",
    "    sagemaker_session=sess,\n",
    "    accept_eula=True,\n",
    "    role=role\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hp_header",
   "metadata": {},
   "source": [
    "### Vie hyperparameters\n",
    "\n",
    "The trainer comes with sensible defaults. Let's inspect them first, you can also override the ones you want to change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac695f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.pretty import pprint\n",
    "\n",
    "print(\"Default finetuning options:\")\n",
    "pprint(trainer.hyperparameters.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train_header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Submit the training job\n",
    "\n",
    "Calling `trainer.train(wait=True)` submits the job and blocks until it completes. SageMaker will:\n",
    "\n",
    "1. Provision the compute cluster automatically\n",
    "2. Download the base model and datasets\n",
    "3. Run the RLVR training loop for the configured number of epochs\n",
    "4. Upload the fine-tuned model artifacts to S3\n",
    "5. Register the model in the Model Package Group\n",
    "\n",
    "> **⏱ Expected duration:** 15-20 minutes. You can monitor progress in SageMaker Studio under **Jobs → Training**, or check the MLflow experiment for live metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e215fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.pretty import pprint\n",
    "\n",
    "training_job = trainer.train(wait=True)\n",
    "\n",
    "TRAINING_JOB_NAME = training_job.training_job_name\n",
    "\n",
    "pprint(training_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next_steps",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next steps\n",
    "\n",
    "Your RLVR-tuned model is now registered in the SageMaker Model Registry. In the next notebook, you'll evaluate it against the base model to measure the improvement on math reasoning tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 5,
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
