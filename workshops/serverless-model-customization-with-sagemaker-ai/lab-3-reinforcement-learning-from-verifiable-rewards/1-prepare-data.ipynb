{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d29fdc55",
   "metadata": {},
   "source": [
    "# Reinforcement Learning from Verifiable Rewards (RLVR) with SageMaker\n",
    "\n",
    "## Lab 1 — Data Preparation\n",
    "\n",
    "In this lab, you will prepare a dataset for **Reinforcement Learning from Verifiable Rewards (RLVR)** training on the **Qwen 2.5 — 7B Instruct** model.\n",
    "\n",
    "### What is RLVR?\n",
    "\n",
    "RLVR is a technique for fine-tuning large language models by automatically rewarding correct solutions to tasks that have **objectively verifiable answers** — such as math problems or coding challenges. Unlike RLHF (Reinforcement Learning from Human Feedback), RLVR doesn't require human annotators; instead, a rule-based reward function checks whether the model's output matches the known correct answer.\n",
    "\n",
    "### What you'll do in this notebook\n",
    "\n",
    "1. Install dependencies and set up your SageMaker session\n",
    "2. Load the **GSM8K** math dataset from Hugging Face\n",
    "3. Transform each sample into the RLVR training format\n",
    "4. Split the data into train / validation / test sets\n",
    "5. Upload the prepared data to Amazon S3\n",
    "6. Register the datasets in the SageMaker AI Registry\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d054b18c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Prerequisites\n",
    "\n",
    "First, install the required Python packages. We need:\n",
    "\n",
    "- `sagemaker` — the SageMaker Python SDK for session management and registry access\n",
    "- `datasets` — Hugging Face library for loading and manipulating datasets\n",
    "- `huggingface_hub` — for authenticating with the Hugging Face Hub\n",
    "- `fsspec` — filesystem abstraction used by `datasets` under the hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0224a386",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade sagemaker fsspec datasets huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de3e60b",
   "metadata": {},
   "source": [
    "### Set up the SageMaker session\n",
    "\n",
    "Next, we initialize a SageMaker session and resolve the IAM execution role. The session gives us a default S3 bucket where we'll store the prepared dataset, and the role is used by SageMaker to access AWS resources on our behalf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c684b517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker.core.helper.session_helper import Session, get_execution_role\n",
    "\n",
    "sess = Session()\n",
    "sagemaker_session_bucket = None\n",
    "\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client(\"iam\")\n",
    "    role = iam.get_role(RoleName=\"sagemaker_execution_role\")[\"Role\"][\"Arn\"]\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sess = Session(default_bucket=sagemaker_session_bucket)\n",
    "bucket_name = sess.default_bucket()\n",
    "default_prefix = sess.default_bucket_prefix\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f21377",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Load the GSM8K dataset\n",
    "\n",
    "[GSM8K](https://huggingface.co/datasets/openai/gsm8k) (Grade School Math 8K) is a dataset of ~8,000 grade-school math word problems created by OpenAI. Each sample contains a natural-language **question** and a step-by-step **answer** that ends with the final numerical result after a `####` delimiter.\n",
    "\n",
    "For this workshop we take a subset of **1,000 samples** to keep training fast. We stream the dataset and shuffle it to get a random sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c16c856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = (\n",
    "    load_dataset(\n",
    "        \"openai/gsm8k\",\n",
    "        \"main\",\n",
    "        split=\"train\",\n",
    "        streaming=True,\n",
    "    )\n",
    "    .take(1000)\n",
    "    .shuffle(buffer_size=1000)\n",
    ")\n",
    "\n",
    "dataset = datasets.Dataset.from_generator(lambda: dataset, features=dataset.features)\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)} samples\")\n",
    "pd.DataFrame(dataset).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transform_header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Transform to RLVR format\n",
    "\n",
    "SageMaker's RLVR training expects each sample to be a JSON object with the following fields:\n",
    "\n",
    "| Field | Description |\n",
    "|---|---|\n",
    "| `prompt` | A chat-formatted list of messages (role + content) containing the question |\n",
    "| `reward_model` | The ground-truth answer and verification style (`\"rule\"` for exact-match checking) |\n",
    "| `data_source` | Identifier for the source dataset |\n",
    "| `ability` | The skill being tested (e.g., `\"math\"`) |\n",
    "| `extra_info` | Optional metadata (original question, answer, index, split) |\n",
    "\n",
    "The helper function below:\n",
    "1. Extracts the final numerical answer from the GSM8K `####` delimiter\n",
    "2. Wraps the question in a chat prompt that instructs the model to think step-by-step\n",
    "3. Packages everything into the required schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transform_fn",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def extract_answer(answer_text):\n",
    "    \"\"\"Extract the final numerical answer after ####\"\"\"\n",
    "    match = re.search(r\"####\\s*(.+)\", answer_text)\n",
    "    return match.group(1).strip().replace(\",\", \"\") if match else \"\"\n",
    "\n",
    "\n",
    "def prepare_rlvr_sample(sample, index):\n",
    "    \"\"\"Convert a single GSM8K sample into the RLVR training format.\"\"\"\n",
    "    ground_truth = extract_answer(sample[\"answer\"])\n",
    "    yield {\n",
    "        \"data_source\": \"openai/gsm8k\",\n",
    "        \"prompt\": [\n",
    "            {\n",
    "                \"content\": f\"{sample['question']} Let's think step by step and output the final answer after \\\"####\\\".\",\n",
    "                \"role\": \"user\",\n",
    "            }\n",
    "        ],\n",
    "        \"ability\": \"math\",\n",
    "        \"reward_model\": {\"ground_truth\": ground_truth, \"style\": \"rule\"},\n",
    "        \"extra_info\": {\n",
    "            \"answer\": sample[\"answer\"],\n",
    "            \"index\": index,\n",
    "            \"question\": sample[\"question\"],\n",
    "            \"split\": \"train\",\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transform_run_header",
   "metadata": {},
   "source": [
    "Now let's apply the transformation to every sample in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transform_run",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "records = []\n",
    "for idx, row in tqdm(enumerate(dataset), total=len(dataset), desc=\"Converting to RLVR format\"):\n",
    "    for example in prepare_rlvr_sample(row, idx):\n",
    "        records.append(example)\n",
    "\n",
    "print(f\"Total RLVR samples: {len(records)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preview_header",
   "metadata": {},
   "source": [
    "Let's inspect a random sample to verify the format looks correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preview_sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from random import randint\n",
    "\n",
    "print(json.dumps(records[randint(0, len(records) - 1)], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split_header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Split the dataset\n",
    "\n",
    "We split the data into three sets:\n",
    "\n",
    "- **Train (72%)** — used by the RLVR training loop\n",
    "- **Validation (20%)** — used to monitor training progress and detect overfitting\n",
    "- **Test (8%)** — held out for final evaluation after training completes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data = train_test_split(records, test_size=0.2, random_state=42)\n",
    "train_data, test_data = train_test_split(train_data, test_size=0.1, random_state=42)\n",
    "\n",
    "print(f\"Train samples:      {len(train_data)}\")\n",
    "print(f\"Validation samples: {len(val_data)}\")\n",
    "print(f\"Test samples:       {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe75abd7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Upload to Amazon S3\n",
    "\n",
    "We write each split to a local JSONL file (one JSON object per line), then upload them to the SageMaker default S3 bucket. The files are organized under a `datasets/serverless-model-customization-rlvr/` prefix with separate folders for each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s3_paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "if default_prefix:\n",
    "    input_path = f\"{default_prefix}/datasets/serverless-model-customization-rlvr\"\n",
    "else:\n",
    "    input_path = \"datasets/serverless-model-customization-rlvr\"\n",
    "\n",
    "train_s3_path = f\"s3://{bucket_name}/{input_path}/train/train_rlvr.jsonl\"\n",
    "val_s3_path = f\"s3://{bucket_name}/{input_path}/val/val_rlvr.jsonl\"\n",
    "test_s3_path = f\"s3://{bucket_name}/{input_path}/test/test_rlvr.jsonl\"\n",
    "\n",
    "print(f\"Train path: {train_s3_path}\")\n",
    "print(f\"Val path:   {val_s3_path}\")\n",
    "print(f\"Test path:  {test_s3_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s3_upload",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "for name, split in [(\"train\", train_data), (\"val\", val_data), (\"test\", test_data)]:\n",
    "    with open(f\"./data/{name}_rlvr.jsonl\", \"w\") as f:\n",
    "        for item in split:\n",
    "            f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "s3_client.upload_file(\"./data/train_rlvr.jsonl\", bucket_name, f\"{input_path}/train/train_rlvr.jsonl\")\n",
    "s3_client.upload_file(\"./data/val_rlvr.jsonl\", bucket_name, f\"{input_path}/val/val_rlvr.jsonl\")\n",
    "s3_client.upload_file(\"./data/test_rlvr.jsonl\", bucket_name, f\"{input_path}/test/test_rlvr.jsonl\")\n",
    "\n",
    "shutil.rmtree(\"./data\")\n",
    "\n",
    "print(\"Upload complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76898ae6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Register datasets in SageMaker AI Registry\n",
    "\n",
    "Finally, we register each split as a **DataSet** resource in the SageMaker AI Registry. This makes the datasets discoverable and reusable across notebooks and training jobs. The ARNs printed below will be used in the next lab to kick off the RLVR training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84955967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.ai_registry.dataset import DataSet\n",
    "\n",
    "dataset_train = DataSet.create(\n",
    "    name=\"rlvr-train\",\n",
    "    source=train_s3_path,\n",
    "    wait=True,\n",
    ")\n",
    "print(f\"TRAINING_DATASET ARN: {dataset_train.arn}\")\n",
    "\n",
    "dataset_val = DataSet.create(\n",
    "    name=\"rlvr-val\",\n",
    "    source=val_s3_path,\n",
    "    wait=True,\n",
    ")\n",
    "print(f\"VALIDATION_DATASET ARN: {dataset_val.arn}\")\n",
    "\n",
    "dataset_test = DataSet.create(\n",
    "    name=\"rlvr-test\",\n",
    "    source=test_s3_path,\n",
    "    wait=True,\n",
    ")\n",
    "print(f\"TEST_DATASET ARN: {dataset_test.arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next_steps",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next steps\n",
    "\n",
    "Your data is now prepared and registered. In the next notebook, you'll use these dataset ARNs to launch an RLVR training job on SageMaker."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 5,
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
