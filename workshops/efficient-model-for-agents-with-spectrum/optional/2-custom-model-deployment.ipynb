{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ade3345",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r training_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef199910-2061-4d43-948e-91a6a8494409",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T10:40:27.648104Z",
     "iopub.status.busy": "2025-11-05T10:40:27.647861Z",
     "iopub.status.idle": "2025-11-05T10:40:27.747607Z",
     "shell.execute_reply": "2025-11-05T10:40:27.747162Z",
     "shell.execute_reply.started": "2025-11-05T10:40:27.648084Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Retrieve the model_data from the SageMaker Training job\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "model_data = sagemaker_client.describe_training_job(TrainingJobName=training_job_name)['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "# Setup the custom endpoint name\n",
    "CUSTOM_ENDPOINT_NAME = \"custom-qwen3-endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d15c1a2-0005-4f06-b6d2-0a0c020bc9fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T10:40:28.592313Z",
     "iopub.status.busy": "2025-11-05T10:40:28.592066Z",
     "iopub.status.idle": "2025-11-05T10:40:28.653151Z",
     "shell.execute_reply": "2025-11-05T10:40:28.652642Z",
     "shell.execute_reply.started": "2025-11-05T10:40:28.592294Z"
    }
   },
   "outputs": [],
   "source": [
    "# Deploy a SageMaker AI endpoint\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.model import Model\n",
    "from sagemaker import get_execution_role\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "\n",
    "# Get current region\n",
    "session = boto3.session.Session()\n",
    "region_name = session.region_name\n",
    "\n",
    "# Model configurations\n",
    "instance_count = 1  # Deploy on a single instance\n",
    "instance_type = \"ml.g5.2xlarge\"  # 1 GPU instance\n",
    "image_uri = f\"763104351884.dkr.ecr.{region_name}.amazonaws.com/djl-inference:0.34.0-lmi16.0.0-cu128-v1.2\"  # Hard-coding the latest DJL LMI image\n",
    "\n",
    "# Setup the model\n",
    "model = Model(\n",
    "    name=name_from_base(\"custom-qwen3\"),\n",
    "    model_data=model_data,\n",
    "    image_uri=image_uri,\n",
    "    role=get_execution_role(),\n",
    "    env={\n",
    "        'HF_MODEL_ID': \"/opt/ml/model\",\n",
    "        \"SERVING_FAIL_FAST\": \"true\",\n",
    "        \"OPTION_ASYNC_MODE\": \"true\",\n",
    "        \"OPTION_ROLLING_BATCH\": \"disable\",\n",
    "        \"OPTION_TENSOR_PARALLEL_DEGREE\": \"1\",\n",
    "        'OPTION_MAX_MODEL_LEN': json.dumps(1024 * 12),\n",
    "        'OPTION_MODEL_LOADING_TIMEOUT': '900',\n",
    "        'SAGEMAKER_MODEL_SERVER_TIMEOUT': '900',\n",
    "        \"OPTION_ENTRYPOINT\": \"djl_python.lmi_vllm.vllm_async_service\",\n",
    "        'OPTION_ENABLE_AUTO_TOOL_CHOICE': 'true',\n",
    "        'OPTION_ENABLE_REASONING': 'true',\n",
    "        'OPTION_REASONING_PARSER': 'qwen3',\n",
    "        'OPTION_TOOL_CALL_PARSER': 'hermes',\n",
    "    },\n",
    ")\n",
    "\n",
    "# Deploy the model to an endpoint\n",
    "model.deploy(\n",
    "    endpoint_name=CUSTOM_ENDPOINT_NAME,\n",
    "    initial_instance_count=instance_count,\n",
    "    instance_type=instance_type\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
