{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title-header",
   "metadata": {},
   "source": [
    "# Spectrum-Aware Fine-Tuning with Amazon SageMaker\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to perform spectrum-aware fine-tuning of the Qwen3 0.6B model for SQL generation tasks using Amazon SageMaker Training Jobs. Spectrum-aware fine-tuning is a cost-effective approach that selectively updates only the most important parameters of a model, making the training process faster and more affordable than traditional full fine-tuning.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "- How to prepare text-to-SQL datasets for fine-tuning\n",
    "- Configure spectrum-aware fine-tuning parameters\n",
    "- Use SageMaker ModelTrainer API for efficient training\n",
    "- Deploy and evaluate fine-tuned models\n",
    "\n",
    "### Key Technologies\n",
    "\n",
    "- **Model**: Qwen3 0.6B (Alibaba's efficient reasoning model)\n",
    "- **Dataset**: Synthetic Text-to-SQL from Gretel AI\n",
    "- **Training**: SageMaker Training Jobs with spectrum-aware fine-tuning\n",
    "- **Framework**: PyTorch with Hugging Face Transformers\n",
    "\n",
    "```\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4c5e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load variables from setup notebook\n",
    "%store -r account_id bucket_name region MLFLOW_TRACKING_URI\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "model_id = \"Qwen/Qwen3-0.6B\"\n",
    "filesafe_model_id = model_id.replace(\"/\", \"-\")\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-config-header",
   "metadata": {},
   "source": [
    "## 2. Spectrum Layer Configuration\n",
    "\n",
    "Next step is to configure spectrum-aware fine-tuning parameters for selective parameter updates using the `spectrum.py` file provided in the Spectrum repository. You have two options to proceed:\n",
    "\n",
    "1. Ignore the next cell, as we have pre-populated the spectrum layers in the `spectrum_layers` folder\n",
    "2. (suggested for advanced users) Run the following cell, then execute the output as a shell command in SageMaker Studio terminal. This will create the layers for Spectrum analysis of our model. Note that you MUST run the command in a terminal, since Spectrum's UI is interactive and cannot be run inside of this notebook.\n",
    "\t- If you do this, set Batch Size to 1 and select all layers in the prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441c1a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate spectrum analysis command\n",
    "spectrum_clone_folder = \"./spectrum\"\n",
    "spectrum_layer_percent = \"50\"\n",
    "\n",
    "command_to_execute = f\"cd {spectrum_clone_folder} && python3 spectrum.py --model-name {model_id} --top-percent {spectrum_layer_percent}\"\n",
    "print(f\"Run this command in terminal: {command_to_execute}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8d504d",
   "metadata": {},
   "source": [
    "(Optional) If you have run the command in the terminal, change the value below to `True`. Otherwise, just execute the cell as is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a71b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "have_you_run_the_command_in_terminal = False\n",
    "\n",
    "spectrum_output_filename = f\"snr_results_{filesafe_model_id}_unfrozenparameters_{spectrum_layer_percent}percent.yaml\"\n",
    "spectrum_output_filepath = (\n",
    "    f\"{spectrum_clone_folder}/{spectrum_output_filename}\"\n",
    "    if have_you_run_the_command_in_terminal\n",
    "    else f\"./spectrum_layers/{spectrum_output_filename}\"\n",
    ")\n",
    "spectrum_output_filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf31f93",
   "metadata": {},
   "source": [
    "This will copy the Spectrum output into your local scripts folder. It will be packaged with the code assets for your training job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6667cba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./scripts/spectrum-layer/\n",
    "!cp {spectrum_output_filepath} ./scripts/spectrum-layer/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading-header",
   "metadata": {},
   "source": [
    "## 3. Dataset Preparation\n",
    "\n",
    "Load and prepare training datasets for spectrum-aware fine-tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5347a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable xet in huggingface because of bug with ipykernel\n",
    "# https://github.com/huggingface/xet-core/issues/526\n",
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_XET\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dataset-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "\n",
    "nl2sql_text = load_dataset(\"gretelai/synthetic_text_to_sql\").shuffle(seed=42)\n",
    "ds = load_dataset(\"interstellarninja/hermes_reasoning_tool_use\").shuffle(\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d33f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo - Sample the dataset\n",
    "ds['train'] = ds['train'].select(range(600))\n",
    "nl2sql_text['train'] = nl2sql_text['train'].select(range(500))\n",
    "nl2sql_text['test'] = nl2sql_text['test'].select(range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tokenizer-header",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72884af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_tokenize_hermes_reasoning_tool_use(sample, tokenizer):\n",
    "    # Replace \"from\" key with \"role\", and \"value\" with \"content\"\n",
    "    for message in sample['conversations']:\n",
    "        message[\"role\"] = message.pop(\"from\")\n",
    "        message[\"content\"] = message.pop(\"value\")\n",
    "\n",
    "    # Replace \"human\" value with \"user\", and \"gpt\" with \"assistant\"\n",
    "    for message in sample['conversations']:\n",
    "        if message[\"role\"] == \"human\":\n",
    "            message[\"role\"] = \"user\"\n",
    "        elif message[\"role\"] == \"gpt\":\n",
    "            message[\"role\"] = \"assistant\"\n",
    "\n",
    "    # Apply the chat template\n",
    "    sample[\"text\"] = tokenizer.apply_chat_template(\n",
    "        sample['conversations'], tokenize=False, enable_thinking=False\n",
    "    )\n",
    "    return sample\n",
    "\n",
    "\n",
    "ds_v2 = ds[\"train\"].map(\n",
    "    convert_and_tokenize_hermes_reasoning_tool_use,\n",
    "    remove_columns=list(ds[\"train\"].features),\n",
    "    fn_kwargs={\"tokenizer\": tok},\n",
    ")\n",
    "ds_v2 = ds_v2.train_test_split(test_size=0.2)\n",
    "tool_call_train_dataset = ds_v2['train']\n",
    "tool_call_test_dataset = ds_v2['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a61eab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_tokenize_synthetic_text_to_sql(sample, tokenizer):\n",
    "    system = f\"\"\"\n",
    "        You are an expert SQL developer. Given the provided database schema and the following user question, generate a syntactically correct SQL query. \n",
    "        Only reply with the SQL query, nothing else. Do NOT use the backticks to identify the code, just reply with the pure SQL query.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "        -- Schema --\n",
    "        {sample[\"sql_context\"]}\n",
    "        -- Query --\n",
    "        {sample[\"sql_prompt\"]}\n",
    "        -- SQL --\n",
    "    \"\"\"\n",
    "    # reasoning = sample[\"sql_explanation\"]\n",
    "    answer = sample[\"sql\"]\n",
    "    chat = [\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "        # {\"role\": \"assistant\", \"reasoning_content\": reasoning, \"content\": answer},\n",
    "        {\"role\": \"assistant\", \"content\": answer},\n",
    "    ]\n",
    "    sample[\"text\"] = tokenizer.apply_chat_template(\n",
    "        chat, tokenize=False, enable_thinking=False\n",
    "    )\n",
    "    return sample\n",
    "\n",
    "\n",
    "nl2sql_train_dataset = nl2sql_text[\"train\"].map(\n",
    "    convert_and_tokenize_synthetic_text_to_sql,\n",
    "    remove_columns=list(nl2sql_text[\"train\"].features),\n",
    "    fn_kwargs={\"tokenizer\": tok},\n",
    ")\n",
    "nl2sql_test_dataset = nl2sql_text[\"test\"].map(\n",
    "    convert_and_tokenize_synthetic_text_to_sql,\n",
    "    remove_columns=list(nl2sql_text[\"test\"].features),\n",
    "    fn_kwargs={\"tokenizer\": tok},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dataset-info",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = concatenate_datasets(\n",
    "    [tool_call_train_dataset, nl2sql_train_dataset]\n",
    ")\n",
    "test_dataset = concatenate_datasets(\n",
    "    [tool_call_test_dataset, nl2sql_test_dataset]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-upload-header",
   "metadata": {},
   "source": [
    "## 5. Upload Training Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-upload",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import shutil\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix\n",
    "\n",
    "# save train_dataset to s3 using our SageMaker session\n",
    "if default_prefix:\n",
    "    input_path = f\"{default_prefix}/datasets/finetuning-modeltrainer-accelerate\"\n",
    "else:\n",
    "    input_path = f\"datasets/finetuning-modeltrainer-accelerate\"\n",
    "\n",
    "train_dataset_s3_path = f\"s3://{bucket_name}/{input_path}/train/dataset.json\"\n",
    "val_dataset_s3_path = f\"s3://{bucket_name}/{input_path}/val/dataset.json\"\n",
    "\n",
    "# Save datasets to s3\n",
    "# We will fine tune only with 20 records due to limited compute resource for the workshop\n",
    "train_dataset.to_json(\"./data/train/dataset.json\", orient=\"records\")\n",
    "test_dataset.to_json(\"./data/val/dataset.json\", orient=\"records\")\n",
    "\n",
    "s3_client.upload_file(\n",
    "    \"./data/train/dataset.json\", bucket_name, f\"{input_path}/train/dataset.json\"\n",
    ")\n",
    "s3_client.upload_file(\n",
    "    \"./data/val/dataset.json\", bucket_name, f\"{input_path}/val/dataset.json\"\n",
    ")\n",
    "\n",
    "shutil.rmtree(\"./data\")\n",
    "\n",
    "print(f\"Training data uploaded to:\")\n",
    "print(train_dataset_s3_path)\n",
    "print(val_dataset_s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-setup-header",
   "metadata": {},
   "source": [
    "## 6. Training Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.config import load_sagemaker_config\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix\n",
    "configs = load_sagemaker_config()\n",
    "instance_type = \"ml.g5.2xlarge\"  # \"ml.g5.2xlarge\"# , \"ml.p4d.24xlarge\" # Override the instance type if you want to get a different container version\n",
    "instance_count = 1\n",
    "config_filename = \"Qwen3-0.6B-spectrum.yaml\"\n",
    "accelerate_filename = \"deepspeed_zero3.yaml\"\n",
    "print(instance_type)\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"pytorch\",\n",
    "    region=sagemaker_session.boto_session.region_name,\n",
    "    version=\"2.6.0\",\n",
    "    instance_type=instance_type,\n",
    "    image_scope=\"training\",\n",
    ")\n",
    "print(config_filename)\n",
    "print(image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760b4b22",
   "metadata": {},
   "source": [
    "Set up the Model Trainer API to launch the training job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-trainer-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.modules.configs import (\n",
    "    CheckpointConfig,\n",
    "    Compute,\n",
    "    OutputDataConfig,\n",
    "    SourceCode,\n",
    "    StoppingCondition,\n",
    ")\n",
    "from sagemaker.modules.distributed import Torchrun\n",
    "from sagemaker.modules.train import ModelTrainer\n",
    "\n",
    "# environment variables\n",
    "env = {}\n",
    "env[\"FI_PROVIDER\"] = \"efa\"\n",
    "env[\"NCCL_PROTO\"] = \"simple\"\n",
    "env[\"NCCL_SOCKET_IFNAME\"] = \"eth0\"\n",
    "env[\"NCCL_IB_DISABLE\"] = \"1\"\n",
    "env[\"NCCL_DEBUG\"] = \"WARN\"\n",
    "env[\"HF_token\"] = \"\"  # os.environ['hf_token']\n",
    "env[\"CONFIG_PATH\"] = f\"recipes/{config_filename}\"\n",
    "env[\"ACCELERATE_CONFIG_PATH\"] = f\"accelerate_configs/{accelerate_filename}\"\n",
    "\n",
    "# hyper parameters\n",
    "params = {\n",
    "    'mlflow_tracking_uri': MLFLOW_TRACKING_URI,\n",
    "    'experiment_name': 'qwen3-spectrum-experiment',\n",
    "}\n",
    "# Define the script to be run\n",
    "source_code = SourceCode(\n",
    "    source_dir=\"./scripts\",\n",
    "    requirements=\"requirements.txt\",\n",
    "    entry_script=\"run_finetuning.sh\",\n",
    ")\n",
    "\n",
    "# Define the compute\n",
    "compute_configs = Compute(\n",
    "    instance_type=instance_type,\n",
    "    instance_count=instance_count,\n",
    "    keep_alive_period_in_seconds=3600,\n",
    ")\n",
    "\n",
    "# define Training Job Name\n",
    "job_name = f\"train-{model_id.split('/')[-1].replace('.', '-')}-accelerate\"\n",
    "\n",
    "# define OutputDataConfig path\n",
    "if default_prefix:\n",
    "    output_path = f\"s3://{bucket_name}/{default_prefix}/{job_name}\"\n",
    "else:\n",
    "    output_path = f\"s3://{bucket_name}/{job_name}\"\n",
    "\n",
    "# Define the ModelTrainer\n",
    "model_trainer = ModelTrainer(\n",
    "    training_image=image_uri,\n",
    "    environment=env,\n",
    "    hyperparameters=params,\n",
    "    source_code=source_code,\n",
    "    base_job_name=job_name,\n",
    "    compute=compute_configs,\n",
    "    stopping_condition=StoppingCondition(max_runtime_in_seconds=18000),\n",
    "    output_data_config=OutputDataConfig(s3_output_path=output_path),\n",
    "    checkpoint_config=CheckpointConfig(\n",
    "        s3_uri=output_path + \"/checkpoint\", local_path=\"/opt/ml/checkpoints\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "input-data-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.modules.configs import InputData\n",
    "\n",
    "# Pass the input data\n",
    "train_input = InputData(\n",
    "    channel_name=\"train\",\n",
    "    data_source=train_dataset_s3_path,  # S3 path where training data is stored\n",
    ")\n",
    "\n",
    "val_input = InputData(\n",
    "    channel_name=\"val\",\n",
    "    data_source=val_dataset_s3_path,  # S3 path where training data is stored\n",
    ")\n",
    "\n",
    "# Check input channels configured\n",
    "data = [train_input, val_input]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-execution-header",
   "metadata": {},
   "source": [
    "## 7. Start Training Job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-execution",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_trainer.train(input_data_config=data, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-download-header",
   "metadata": {},
   "source": [
    "## 8. Monitor Training Progress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-download-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor training job status\n",
    "model_trainer._latest_training_job.wait()\n",
    "training_job_name = model_trainer._latest_training_job.training_job_name\n",
    "print(f\"Training job: {training_job_name}\")\n",
    "print(f\"Status: {model_trainer._latest_training_job.training_job_status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78734675",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store training_job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion-header",
   "metadata": {},
   "source": [
    "## Training Complete\n",
    "\n",
    "Spectrum-aware fine-tuning job has been started. The model will be ready for evaluation once training completes.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "  <b>Important:</b> If you're running this at an AWS event, we have pre-deployed a SageMaker endpoint for you in a central account with the fine-tuned model. If you want to deploy your own endpoint based on this training job in the current account AFTER the training is complete, you can use the notebook in `optional/2-custom-model-deployment.ipynb`. <b>You can skip this in an AWS-led event!</b>\n",
    "</div>\n",
    "\n",
    "-----\n",
    "\n",
    "**Next**: Proceed to notebook 3 to evaluate the fine-tuned model performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
