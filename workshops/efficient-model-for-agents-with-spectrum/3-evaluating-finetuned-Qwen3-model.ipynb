{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3f2eb9-e10d-451b-a774-712ec7547bca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T18:18:43.013048Z",
     "iopub.status.busy": "2025-10-23T18:18:43.012683Z",
     "iopub.status.idle": "2025-10-23T18:18:43.018564Z",
     "shell.execute_reply": "2025-10-23T18:18:43.017455Z",
     "shell.execute_reply.started": "2025-10-23T18:18:43.012940Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load variables from setup notebook\n",
    "%store -r CUSTOM_ENDPOINT_NAME MLFLOW_TRACKING_URI account_id bucket_name region db_name s3_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7414962-9ede-4a18-92d6-d61d381da109",
   "metadata": {},
   "source": [
    "# Evaluating Fine-Tuned Qwen3 Model for SQL Generation\n",
    "\n",
    "This notebook evaluates the fine-tuned performance of the Qwen3 0.6B model for text-to-SQL generation tasks. We'll test the model's ability to generate SQL queries and assess its performance across different difficulty levels.\n",
    "\n",
    "**Prerequisites**: Run the setup notebook (0-setup.ipynb) and training notebook (2-model-finetuning.ipynb) first.\n",
    "\n",
    "## 1. Test Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80584d5-bc36-4a33-a65d-fb2996673b13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T18:18:44.483617Z",
     "iopub.status.busy": "2025-10-23T18:18:44.483355Z",
     "iopub.status.idle": "2025-10-23T18:19:00.843459Z",
     "shell.execute_reply": "2025-10-23T18:19:00.842356Z",
     "shell.execute_reply.started": "2025-10-23T18:18:44.483593Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sagemaker \n",
    "\n",
    "predictor = sagemaker.Predictor(\n",
    "    endpoint_name=CUSTOM_ENDPOINT_NAME,\n",
    "    serializer=sagemaker.serializers.JSONSerializer(),\n",
    "    deserializer=sagemaker.deserializers.JSONDeserializer(),\n",
    ")\n",
    "\n",
    "predictor.predict(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b645bbb-b50e-4be7-9f8c-b7fce249ea13",
   "metadata": {},
   "source": [
    "## 2. SQL Generation Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e99bb3-0d85-4e20-836c-73b6810eb932",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T18:19:21.272187Z",
     "iopub.status.busy": "2025-10-23T18:19:21.271906Z",
     "iopub.status.idle": "2025-10-23T18:19:21.276591Z",
     "shell.execute_reply": "2025-10-23T18:19:21.275511Z",
     "shell.execute_reply.started": "2025-10-23T18:19:21.272158Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.evaluation import (\n",
    "    execute_athena_query,\n",
    "    extract_sql,\n",
    "    collect_athena_metrics,\n",
    "    generate_sql,\n",
    "    analyze_qwen_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6a9b7f-6114-4c9f-9e3c-8355f28e0356",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T18:19:37.285218Z",
     "iopub.status.busy": "2025-10-23T18:19:37.284934Z",
     "iopub.status.idle": "2025-10-23T18:19:47.004906Z",
     "shell.execute_reply": "2025-10-23T18:19:47.003898Z",
     "shell.execute_reply.started": "2025-10-23T18:19:37.285192Z"
    }
   },
   "outputs": [],
   "source": [
    "schema = open(\"utils/data_schema.md\", \"r\").read()\n",
    "system = f\"\"\"\\\n",
    "You are an expert SQL developer. Given the provided database schema and the following user question, generate a syntactically correct SQL query. \n",
    "Only reply with the SQL query, nothing else. Do NOT use the backticks to identify the code, just reply with the pure SQL query.\n",
    "\n",
    "{schema}\n",
    "\"\"\"\n",
    "\n",
    "question = \"Calculate the moving average of sales using a 5-row window (2 preceding, 2 following, current row) ordered by row_id\"\n",
    "payload = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": question+\" /no_think\"},\n",
    "    ]\n",
    "}\n",
    "\n",
    "res = predictor.predict(payload)\n",
    "output = extract_sql(res[\"choices\"][0][\"message\"][\"content\"])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4cb3e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T18:19:47.005944Z",
     "iopub.status.busy": "2025-10-23T18:19:47.005650Z",
     "iopub.status.idle": "2025-10-23T18:19:49.552180Z",
     "shell.execute_reply": "2025-10-23T18:19:49.551045Z",
     "shell.execute_reply.started": "2025-10-23T18:19:47.005916Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verify database access\n",
    "execute_athena_query(\"SELECT COUNT(*) FROM orders\", db_name, s3_output)\n",
    "execute_athena_query(\"SELECT COUNT(*) FROM returns\", db_name, s3_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71c8aa3-09e7-4c05-9c00-848196d20dc2",
   "metadata": {},
   "source": [
    "## 3. Comprehensive Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce23e68-ec52-4507-bc99-aaa17761f8df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T18:19:53.783577Z",
     "iopub.status.busy": "2025-10-23T18:19:53.783116Z",
     "iopub.status.idle": "2025-10-23T18:19:53.789117Z",
     "shell.execute_reply": "2025-10-23T18:19:53.787968Z",
     "shell.execute_reply.started": "2025-10-23T18:19:53.783550Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load evaluation dataset\n",
    "data = []\n",
    "with open('eval_sql.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "print(f\"Loaded {len(data)} evaluation queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4341363",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "  <center><b>‚ö†Ô∏èÔ∏è Important ‚ö†Ô∏èÔ∏è</b></center>\n",
    "  The cell below takes <b>~5 minutes to run</b>. We recommend <b>executing the cell below, then proceed to notebook 4</b>. Come back later to this notebook to view the custom model evaluation results.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da04602-cf0e-42bd-b69e-364b0f1d5f6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import boto3\n",
    "\n",
    "\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "# Generate SQL queries for evaluation\n",
    "print(\"Generating SQL queries for evaluation ... \")\n",
    "for i, item in tqdm(enumerate(data), total=len(data)):\n",
    "    data[i]['qwen_ft_sql_query'] = generate_sql(item['question']+\" /no_think\", CUSTOM_ENDPOINT_NAME, smr_client)\n",
    "\n",
    "# Execute queries and collect metrics\n",
    "print(\"Executing queries and collecting metrics ... \")\n",
    "all_metrics = []\n",
    "for item in tqdm(data, total=len(data)):\n",
    "    metrics = collect_athena_metrics(\n",
    "        sql_query=item[\"qwen_ft_sql_query\"],\n",
    "        db_name=db_name,\n",
    "        s3_output=s3_output,\n",
    "        query_id=item[\"id\"],\n",
    "    )\n",
    "    all_metrics.append(metrics)\n",
    "\n",
    "# Save results\n",
    "df = pd.DataFrame(data)\n",
    "df.to_json('results/eval_sql_qwen_ft.json', orient='records', indent=2)\n",
    "\n",
    "with open('results/qwen3_ft_results.json', 'w') as f:\n",
    "    json.dump(all_metrics, f, indent=2)\n",
    "\n",
    "print(f\"Processed {len(all_metrics)} queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f7cdae-da1c-4f10-8d46-493d02195491",
   "metadata": {},
   "source": [
    "## 4. Performance Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639f3c72-b546-40b9-b1d4-416cf5b5fc22",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-23T18:37:32.915036Z",
     "iopub.status.idle": "2025-10-23T18:37:32.915890Z",
     "shell.execute_reply": "2025-10-23T18:37:32.915290Z",
     "shell.execute_reply.started": "2025-10-23T18:37:32.915263Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== FINE-TUNED MODEL PERFORMANCE ===\")\n",
    "df_ft, summary_ft, metrics_ft = analyze_qwen_results(\n",
    "    'results/qwen3_ft_results.json', 'results/eval_sql_qwen_ft.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d754da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from utils.mlflow_tracking import get_mlfow_url\n",
    "from IPython.display import Markdown\n",
    "import os\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment('qwen3-spectrum-experiment')\n",
    "\n",
    "# Redirect standard output to os.devnull (or a dummy file object)\n",
    "with redirect_stdout(open(os.devnull, 'w')):\n",
    "    with mlflow.start_run(run_name='ft-model-evaluation') as run:\n",
    "        mlflow.log_metrics(metrics_ft)\n",
    "Markdown(get_mlfow_url(\"aim410-mlflow-server\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113b2ac9",
   "metadata": {},
   "source": [
    "When running the fine-tuning at scale, we have obtained the following results:\n",
    "\n",
    "![fine-tuned-model-performances.png](./images/fine-tuned-model-performances.png)\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Looking for a more in-depth comparison between the two models? Go ahead and run the notebook <code>optional/3-evaluation-with-ragas.ipynb</code>, which leverages <a href=\"https://ragas.io\"><b>ragas</b></a>, an OSS framework for model and agent evaluation. <b>Warning:</b> running that notebook end-to-end takes ~15 minutes.\n",
    "</div>\n",
    "\n",
    "----\n",
    "\n",
    "You're done! üöÄÔ∏è You can now proceed to notebook `4-agents.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
