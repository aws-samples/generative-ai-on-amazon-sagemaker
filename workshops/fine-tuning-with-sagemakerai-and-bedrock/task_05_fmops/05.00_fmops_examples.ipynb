{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Operations of FMOps\n",
    "\n",
    "The purpose of this notebook is to illustrate the capabilities SageMaker AI and Managed MLflow on SageMaker AI for FMOps tasks. In this notebook, we cover the foundational capabilities needed to develop an automated LLM fine-tuning and evaluation pipeline. We cover these components individually, without an orchestration service, to showcase the capabilities atomically. This notebook lays the groundwork for the next notebook, which stiches together these disparate components into a fully orchestrated fine-tuning and model evaluation pipeline powered by SageMaker AI Pipelines and Managed MLflow on SageMaker AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites \n",
    "Before you begin, make sure you have the following prerequisites in place:\n",
    "\n",
    "- MLflow tracking server: If you're running this lab in a workshop environment, a MLflow tracking server has already been created for you. If you need to create a MLflow tracking server, follow the [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/mlflow-create-tracking-server.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Dependencies\n",
    "Install dependencies and configure kernel.\n",
    "\n",
    "Restart the kernel after executing below cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ./scripts/requirements.txt --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T16:24:11.008896Z",
     "iopub.status.busy": "2025-09-23T16:24:11.008634Z",
     "iopub.status.idle": "2025-09-23T16:24:11.012999Z",
     "shell.execute_reply": "2025-09-23T16:24:11.012430Z",
     "shell.execute_reply.started": "2025-09-23T16:24:11.008876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import get_ipython\n",
    "get_ipython().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Libraries and Setting Up Environment**\n",
    "\n",
    "This part imports all necessary Python modules. It includes SageMaker-specific imports for pipeline creation and execution, which will be used to define the pipeline steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T20:09:16.030318Z",
     "iopub.status.busy": "2025-09-23T20:09:16.030111Z",
     "iopub.status.idle": "2025-09-23T20:09:17.845965Z",
     "shell.execute_reply": "2025-09-23T20:09:17.845503Z",
     "shell.execute_reply.started": "2025-09-23T20:09:16.030301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import boto3\n",
    "import mlflow\n",
    "import tarfile\n",
    "import botocore\n",
    "import sagemaker\n",
    "import traceback\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from sagemaker.huggingface import HuggingFaceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SageMaker Session and IAM Role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_execution_role()`: Retrieves the IAM role that SageMaker will use to access AWS resources. This role needs appropriate permissions for tasks like accessing S3 buckets and creating SageMaker resources.\n",
    "\n",
    "If you are running this lab in a workshop environment, the execution role will have the appropriate permissions necessary to execute the following tasks. If not, you may need to check the permissions attached to your sagemaker execution role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T20:09:17.846760Z",
     "iopub.status.busy": "2025-09-23T20:09:17.846596Z",
     "iopub.status.idle": "2025-09-23T20:09:18.225333Z",
     "shell.execute_reply": "2025-09-23T20:09:18.224883Z",
     "shell.execute_reply.started": "2025-09-23T20:09:17.846744Z"
    }
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.session.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Configuration\n",
    "Here we setup our example execution environment.\n",
    "\n",
    "We define appropriate paths in S3 to store model files, define the model we will be working with, and define the model endpoint name.\n",
    "\n",
    "In this lab, we are working with [DeepSeek-R1-Distill-Llama-8B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B). It is easy to fine-tune as we will see in the next lab, and is small enough to fit on a reasonably sized GPU-accelerated hosting endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T20:09:18.419445Z",
     "iopub.status.busy": "2025-09-23T20:09:18.419284Z",
     "iopub.status.idle": "2025-09-23T20:09:18.636938Z",
     "shell.execute_reply": "2025-09-23T20:09:18.636485Z",
     "shell.execute_reply.started": "2025-09-23T20:09:18.419432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-329542461890\n"
     ]
    }
   ],
   "source": [
    "bucket_name = sagemaker_session.default_bucket()\n",
    "print(bucket_name)\n",
    "default_prefix = sagemaker_session.default_bucket_prefix\n",
    "if default_prefix:\n",
    "    input_path = f'{default_prefix}/datasets/llm-fine-tuning-modeltrainer-sft'\n",
    "else:\n",
    "    input_path = f'datasets/llm-fine-tuning-modeltrainer-sft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T20:09:18.869074Z",
     "iopub.status.busy": "2025-09-23T20:09:18.868903Z",
     "iopub.status.idle": "2025-09-23T20:09:18.871966Z",
     "shell.execute_reply": "2025-09-23T20:09:18.871490Z",
     "shell.execute_reply.started": "2025-09-23T20:09:18.869059Z"
    }
   },
   "outputs": [],
   "source": [
    "model_id = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "model_id_filesafe = model_id.replace(\"/\",\"_\").replace(\".\", \"_\")\n",
    "model_name_safe = model_id.split('/')[-1].replace('.', '-').replace('_', '-')\n",
    "endpoint_name = f\"Example-{model_name_safe}\"\n",
    "instance_count = 1\n",
    "instance_type = \"ml.g5.2xlarge\"\n",
    "guardrail_id = \"u1yfe55ecv4z\"     # Not an actual Guardrail ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLflow integration is crucial for experiment tracking and management. \n",
    "\n",
    "**Update the ARN for the MLflow tracking server.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example requires a SageMaker with MLflow tracking server to track experiments and manage model artifacts. To create your own tracking server please refer to the [SageMaker documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/mlflow-create-tracking-server.html). Once you have created your tracking server, please copy the tracking server ARN to the `mlflow_tracking server_arn` variable in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T20:09:21.117974Z",
     "iopub.status.busy": "2025-09-23T20:09:21.117722Z",
     "iopub.status.idle": "2025-09-23T20:09:21.120963Z",
     "shell.execute_reply": "2025-09-23T20:09:21.120461Z",
     "shell.execute_reply.started": "2025-09-23T20:09:21.117955Z"
    }
   },
   "outputs": [],
   "source": [
    "mlflow_tracking_server_arn = \"<REPLACE WITH YOUR ARN>\"\n",
    "mlflow_tracking_server_arn = \"arn:aws:sagemaker:us-east-1:329542461890:mlflow-tracking-server/my-tracking-server\"\n",
    "\n",
    "if not mlflow_tracking_server_arn:\n",
    "    try:\n",
    "        response = boto3.client('sagemaker').describe_mlflow_tracking_server(\n",
    "            TrackingServerName='genai-mlflow-tracker'\n",
    "        )\n",
    "        mlflow_tracking_server_arn = response['TrackingServerArn']\n",
    "        print(f\"MLflow Tracking Server ARN: {mlflow_tracking_server_arn}\")\n",
    "    except botocore.exceptions.ClientError:\n",
    "        print(\"No MLflow Tracking Server Found, please input a value for mlflow_tracking_server_arn\")\n",
    "\n",
    "os.environ[\"mlflow_tracking_server_arn\"] = mlflow_tracking_server_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Templating a Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop we are going to fine-tune DeepSeek-R1-Distill-Llama-8B to become a medical expert. To accomplish this, we will execute a fine-tuning job using Managed MLflow on SageMaker AI. We get our data from the [FreedomIntelligence/medical-o1-reasoning-SFT](https://huggingface.co/datasets/FreedomIntelligence/medical-o1-reasoning-SFT) dataset, available on HuggingFace.\n",
    "\n",
    "We perform the full fine-tuning step in the next lab. In this lab, we show a small example of what fine-tuning looks like for a single record of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T20:09:23.299286Z",
     "iopub.status.busy": "2025-09-23T20:09:23.299057Z",
     "iopub.status.idle": "2025-09-23T20:09:23.304425Z",
     "shell.execute_reply": "2025-09-23T20:09:23.303915Z",
     "shell.execute_reply.started": "2025-09-23T20:09:23.299268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Question': 'A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings, what would cystometry most likely reveal about her residual volume and detrusor contractions?', 'Complex_CoT': \"Okay, let's think about this step by step. There's a 61-year-old woman here who's been dealing with involuntary urine leakages whenever she's doing something that ups her abdominal pressure like coughing or sneezing. This sounds a lot like stress urinary incontinence to me. Now, it's interesting that she doesn't have any issues at night; she isn't experiencing leakage while sleeping. This likely means her bladder's ability to hold urine is fine when she isn't under physical stress. Hmm, that's a clue that we're dealing with something related to pressure rather than a bladder muscle problem.\\n\\nThe fact that she underwent a Q-tip test is intriguing too. This test is usually done to assess urethral mobility. In stress incontinence, a Q-tip might move significantly, showing urethral hypermobility. This kind of movement often means there's a weakness in the support structures that should help keep the urethra closed during increases in abdominal pressure. So, that's aligning well with stress incontinence.\\n\\nNow, let's think about what would happen during cystometry. Since stress incontinence isn't usually about sudden bladder contractions, I wouldn't expect to see involuntary detrusor contractions during this test. Her bladder isn't spasming or anything; it's more about the support structure failing under stress. Plus, she likely empties her bladder completely because stress incontinence doesn't typically involve incomplete emptying. So, her residual volume should be pretty normal.\\n\\nAll in all, it seems like if they do a cystometry on her, it will likely show a normal residual volume and no involuntary contractions. Yup, I think that makes sense given her symptoms and the typical presentations of stress urinary incontinence.\", 'Response': 'Cystometry in this case of stress urinary incontinence would most likely reveal a normal post-void residual volume, as stress incontinence typically does not involve issues with bladder emptying. Additionally, since stress urinary incontinence is primarily related to physical exertion and not an overactive bladder, you would not expect to see any involuntary detrusor contractions during the test.', 'text': '\\n<|begin_of_text|>\\n    <|start_header_id|>system<|end_header_id|>\\n    You are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \\n    Below is an instruction that describes a task, paired with an input that provides further context. \\n    Write a response that appropriately completes the request.\\n    Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\\n    <|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        {question}\\n    <|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>\\n    {complex_cot}\\n    {answer}\\n<|eot_id|>\\n'}\n"
     ]
    }
   ],
   "source": [
    "FINE_TUNING_DATA_SAMPLE = {\n",
    "    \"Question\": \"A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings, what would cystometry most likely reveal about her residual volume and detrusor contractions?\", \n",
    "    \"Complex_CoT\": \"Okay, let's think about this step by step. There's a 61-year-old woman here who's been dealing with involuntary urine leakages whenever she's doing something that ups her abdominal pressure like coughing or sneezing. This sounds a lot like stress urinary incontinence to me. Now, it's interesting that she doesn't have any issues at night; she isn't experiencing leakage while sleeping. This likely means her bladder's ability to hold urine is fine when she isn't under physical stress. Hmm, that's a clue that we're dealing with something related to pressure rather than a bladder muscle problem.\\n\\nThe fact that she underwent a Q-tip test is intriguing too. This test is usually done to assess urethral mobility. In stress incontinence, a Q-tip might move significantly, showing urethral hypermobility. This kind of movement often means there's a weakness in the support structures that should help keep the urethra closed during increases in abdominal pressure. So, that's aligning well with stress incontinence.\\n\\nNow, let's think about what would happen during cystometry. Since stress incontinence isn't usually about sudden bladder contractions, I wouldn't expect to see involuntary detrusor contractions during this test. Her bladder isn't spasming or anything; it's more about the support structure failing under stress. Plus, she likely empties her bladder completely because stress incontinence doesn't typically involve incomplete emptying. So, her residual volume should be pretty normal.\\n\\nAll in all, it seems like if they do a cystometry on her, it will likely show a normal residual volume and no involuntary contractions. Yup, I think that makes sense given her symptoms and the typical presentations of stress urinary incontinence.\",\n",
    "    \"Response\": \"Cystometry in this case of stress urinary incontinence would most likely reveal a normal post-void residual volume, as stress incontinence typically does not involve issues with bladder emptying. Additionally, since stress urinary incontinence is primarily related to physical exertion and not an overactive bladder, you would not expect to see any involuntary detrusor contractions during the test.\"\n",
    "}\n",
    "\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "<|begin_of_text|>\n",
    "    <|start_header_id|>system<|end_header_id|>\n",
    "    You are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \n",
    "    Below is an instruction that describes a task, paired with an input that provides further context. \n",
    "    Write a response that appropriately completes the request.\n",
    "    Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
    "    <|eot_id|>\n",
    "        <|start_header_id|>user<|end_header_id|>\n",
    "        {{question}}\n",
    "    <|eot_id|>\n",
    "    <|start_header_id|>assistant<|end_header_id|>\n",
    "    {{complex_cot}}\n",
    "    {{answer}}\n",
    "<|eot_id|>\n",
    "\"\"\"\n",
    "\n",
    "# Template dataset to add prompt to each sample\n",
    "def template_dataset(sample):\n",
    "    try:\n",
    "        sample[\"text\"] = PROMPT_TEMPLATE.format(question=sample[\"Question\"],\n",
    "                                                complex_cot=sample[\"Complex_CoT\"],\n",
    "                                                answer=sample[\"Response\"])\n",
    "        return sample\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError in template_dataset: {str(e)}\")\n",
    "        # Provide default values for missing fields\n",
    "        missing_key = str(e).strip(\"'\")\n",
    "        if missing_key == \"Question\":\n",
    "            sample[\"text\"] = PROMPT_TEMPLATE.format(\n",
    "                question=\"[Missing question]\",\n",
    "                complex_cot=sample.get(\"Complex_CoT\", \"[Missing CoT]\"),\n",
    "                answer=sample.get(\"Response\", \"[Missing response]\")\n",
    "            )\n",
    "        elif missing_key == \"Complex_CoT\":\n",
    "            sample[\"text\"] = PROMPT_TEMPLATE.format(\n",
    "                question=sample[\"Question\"],\n",
    "                complex_cot=\"[Missing CoT]\",\n",
    "                answer=sample.get(\"Response\", \"[Missing response]\")\n",
    "            )\n",
    "        elif missing_key == \"Response\":\n",
    "            sample[\"text\"] = PROMPT_TEMPLATE.format(\n",
    "                question=sample[\"Question\"],\n",
    "                complex_cot=sample.get(\"Complex_CoT\", \"[Missing CoT]\"),\n",
    "                answer=\"[Missing response]\"\n",
    "            )\n",
    "        return sample\n",
    "\n",
    "PROCESSED_SAMPLE = template_dataset(FINE_TUNING_DATA_SAMPLE)\n",
    "print(PROCESSED_SAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fine-Tuning Output\n",
    "The above output shows the templated prompt output to be used for fine-tuning. This pre-processing happens for every record in the fine-tuning dataset before fine-tuning actually takes place. This can be time-consuming for large fine-tuning datasets. We will show in the next lab how to orchestrate this with MLflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Deployment\n",
    "There are several approaches to deploying a model to a SageMaker AI managed endpoint. In this section, we explore the most direct option which downloads a model directly from HuggingFace to the managed endpoint via SageMaker JumpStart. We are still using DeepSeek-R1-Distill-Llama-8B, but we have not fine-tuned it. The purpose of this section is to illustrate the components required to customize a model deployment on SageMaker before fine-tuning it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image URI\n",
    "By default, images downloaded from HuggingFace use the [Text Generation Inference](https://huggingface.co/docs/text-generation-inference/en/index) model serving toolkit. \n",
    "\n",
    "For this lab, we want to change the underlying model server to [Deep Java Library's Large Model Inference](https://docs.djl.ai/master/docs/serving/serving/docs/lmi/index.html) container, or DJL-LMI. This serving container offers [several performance benefits](https://aws.amazon.com/blogs/machine-learning/supercharge-your-llm-performance-with-amazon-sagemaker-large-model-inference-container-v15/) that we want to leverage for the production deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T20:09:28.240483Z",
     "iopub.status.busy": "2025-09-23T20:09:28.240271Z",
     "iopub.status.idle": "2025-09-23T20:09:28.256986Z",
     "shell.execute_reply": "2025-09-23T20:09:28.256596Z",
     "shell.execute_reply.started": "2025-09-23T20:09:28.240468Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create and deploy model\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"djl-lmi\",\n",
    "    region=sagemaker_session.boto_session.region_name,\n",
    "    version=\"latest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HuggingFace + SageMaker JumpStart\n",
    "Here we download the model from SageMaker Jumpstart and create a `HuggingFaceModel` object. Notice how we define the `model_id` in the configuration, and specify the `image_uri` defined above in the instantiation of the model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T20:09:30.016790Z",
     "iopub.status.busy": "2025-09-23T20:09:30.016619Z",
     "iopub.status.idle": "2025-09-23T20:09:30.140650Z",
     "shell.execute_reply": "2025-09-23T20:09:30.140207Z",
     "shell.execute_reply.started": "2025-09-23T20:09:30.016776Z"
    }
   },
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'HF_MODEL_ID': model_id,\n",
    "    'SM_NUM_GPUS': json.dumps(1),\n",
    "    'OPTION_TRUST_REMOTE_CODE': 'true',\n",
    "    'OPTION_ROLLING_BATCH': \"vllm\",\n",
    "    'OPTION_DTYPE': 'bf16',\n",
    "    'OPTION_QUANTIZE': 'fp8',\n",
    "    'OPTION_TENSOR_PARALLEL_DEGREE': 'max',\n",
    "    'OPTION_MAX_ROLLING_BATCH_SIZE': '32',\n",
    "    'OPTION_MODEL_LOADING_TIMEOUT': '3600',\n",
    "    'OPTION_MAX_MODEL_LEN': '4096'\n",
    "}\n",
    "model = HuggingFaceModel(\n",
    "    image_uri=image_uri,\n",
    "    env=model_config,\n",
    "    role=role\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Deploy w/Managed MLFlow 3.0 on SageMaker AI\n",
    "Now we stitch the pieces together and use MLFlow to orchestrate the deployment of our model to a SageMaker AI managed endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T20:09:30.871383Z",
     "iopub.status.busy": "2025-09-23T20:09:30.871211Z",
     "iopub.status.idle": "2025-09-23T20:09:31.029947Z",
     "shell.execute_reply": "2025-09-23T20:09:31.029531Z",
     "shell.execute_reply.started": "2025-09-23T20:09:30.871368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://329542461890-mlflow-bucket/frgud/0', creation_time=1756923355660, experiment_id='0', last_update_time=1756923355660, lifecycle_stage='active', name='Default', tags={}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize MLFlow tracking data...\n",
    "mlflow.set_tracking_uri(mlflow_tracking_server_arn)\n",
    "mlflow.set_experiment(\"Default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T16:27:51.741447Z",
     "iopub.status.busy": "2025-09-23T16:27:51.741253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"example_model_deployment\"):\n",
    "    deployment_start_time = time.time()\n",
    "\n",
    "    health_check_timeout = 1800\n",
    "    data_download_timeout = 3600\n",
    "\n",
    "    # Log deployment parameters\n",
    "    mlflow.log_params({\n",
    "        \"model_id\": model_id,\n",
    "        \"instance_type\": instance_type,\n",
    "        \"instance_count\": instance_count,\n",
    "        \"endpoint_name\": endpoint_name,\n",
    "        \"health_check_timeout\": health_check_timeout,\n",
    "        \"data_download_timeout\": data_download_timeout\n",
    "    })\n",
    "    mlflow.log_params({\"model_config_\" + k: v for k, v in model_config.items()})\n",
    "\n",
    "    try:\n",
    "        # deploy model to SageMaker Inference\n",
    "        predictor = model.deploy(\n",
    "            initial_instance_count=instance_count,\n",
    "            instance_type=instance_type,\n",
    "            container_startup_health_check_timeout=health_check_timeout,\n",
    "            model_data_download_timeout=data_download_timeout,\n",
    "            endpoint_name=endpoint_name\n",
    "        )\n",
    "\n",
    "        # Log deployment metrics\n",
    "        deployment_time = time.time() - deployment_start_time\n",
    "        mlflow.log_metric(\"deployment_time_seconds\", deployment_time)\n",
    "        mlflow.log_metric(\"deployment_success\", 1)\n",
    "\n",
    "        # Log tags\n",
    "        mlflow.set_tags({\n",
    "            \"endpoint_status\": \"deployed\",\n",
    "            \"deployment_type\": \"sagemaker\",\n",
    "            \"framework\": \"djl-lmi\"\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log deployment failure\n",
    "        mlflow.log_metric(\"deployment_success\", 0)\n",
    "        mlflow.log_param(\"error_message\", str(e))\n",
    "        mlflow.set_tag(\"endpoint_status\", \"failed\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Model Prediction\n",
    "Now we stitch the pieces together and use MLFlow to orchestrate the deployment of our model to a SageMaker AI managed endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T20:09:50.061640Z",
     "iopub.status.busy": "2025-09-23T20:09:50.061429Z",
     "iopub.status.idle": "2025-09-23T20:10:00.090701Z",
     "shell.execute_reply": "2025-09-23T20:10:00.090239Z",
     "shell.execute_reply.started": "2025-09-23T20:09:50.061625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generated_text': \" \\n\\nOkay, so I have this question about a 61-year-old woman with a history of involuntary urine loss. She experiences this during activities like coughing or sneezing but doesn't leak at night. She undergoes a gynecological exam and a Q-tip test. The question is asking what cystometry would most likely reveal about her residual volume and detrusor contractions.\\n\\nFirst, I need to break down the information given. She's 61, so she's of postmenopausal age, which might be relevant because urinary issues can change after menopause. She has involuntary urine loss, which makes me think of stress urinary incontinence (SUI). SUI is common in women, especially after menopause, and it's typically due to weak pelvic muscles or urethral issues.\\n\\nShe mentions the loss happens during activities like coughing or sneezing, which are activities that can increase intra-abdominal pressure, leading to urethral sphincter failure. Also, she doesn't leak at night, which is interesting because that suggests it's not a mixed incontinence case (where she might have both stress and urge incontinence). If she didn't leak at night, it's more likely purely stress incontinence.\\n\\nShe undergoes a gynecological exam and a Q-tip test. I'm not exactly sure what the Q-tip test entails, but I think it's a physical exam maneuver where the provider inserts a Q-tip catheter into the urethra and asks the patient to cough or bear down. If the catheter doesn't stay in the urethra (i.e., it pops out), it suggests urethral sphincter deficiency, which is a sign of SUI.\\n\\nSo, if the Q-tip test shows that the catheter doesn't stay in the urethra, that would support a diagnosis of SUI. Now, moving on to cystometry, which is a more detailed diagnostic tool. Cystometry involves inserting a catheter into the bladder and filling it with fluid to measure how much the patient can hold before needing to urinate (the capacity), and it also assesses the detrusor muscle contractions.\\n\\nIn SUI, the main issue is the inability to prevent the urethral sphincter from opening when there's increased intra-abdominal pressure. On cystometry, this would show that the patient has a small residual volume in the bladder because they can't hold their urine under stress. Additionally, during the filling phase, the\"}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")\n",
    "predictor.predict({\n",
    "    # \"inputs\": \"Hi, what can you help me with?\",\n",
    "    \"inputs\": FINE_TUNING_DATA_SAMPLE[\"Question\"],\n",
    "    \"parameters\": {\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"top_p\": 0.9,\n",
    "        \"temperature\": 0.6,\n",
    "        \"return_full_text\": False\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T20:37:33.037714Z",
     "iopub.status.busy": "2025-09-23T20:37:33.037568Z",
     "iopub.status.idle": "2025-09-23T20:37:33.290095Z",
     "shell.execute_reply": "2025-09-23T20:37:33.289613Z",
     "shell.execute_reply.started": "2025-09-23T20:37:33.037700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Guardrail zpeb3rjh181n:DRAFT\n"
     ]
    }
   ],
   "source": [
    "guardrail_client = boto3.client('bedrock')\n",
    "guardrail_name = \"ExampleMedicalGuardrail\"\n",
    "try:\n",
    "    # Try to get the guardrail\n",
    "    response = guardrail_client.list_guardrails()\n",
    "    for guardrail in response.get('guardrails', []):\n",
    "        if guardrail['name'] == guardrail_name:\n",
    "            guardrail_id = guardrail['id']\n",
    "    response = guardrail_client.get_guardrail(\n",
    "        guardrailIdentifier=guardrail_id\n",
    "    )\n",
    "    guardrail_version = response[\"version\"]\n",
    "    print(f\"Found Guardrail {guardrail_id}:{guardrail_version}\")\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'ResourceNotFoundException':\n",
    "        # Guardrail doesn't exist, create it\n",
    "        try:\n",
    "            guardrail = guardrail_client.create_guardrail(\n",
    "                name=\"ExampleMedicalGuardrail\",\n",
    "                description='Example of a Guardrail for Medical Use Cases',\n",
    "                topicPolicyConfig={\n",
    "                    'topicsConfig': [{\n",
    "                        'name': 'Block Pharmaceuticals',\n",
    "                        'definition': 'This model cannot recommend one pharmaceutical over another. Generic prescriptions consistent with medical expertise and clinical diagnoses only.',\n",
    "                        'type': 'DENY',\n",
    "                        'inputAction': 'BLOCK',\n",
    "                        'outputAction': 'BLOCK',\n",
    "                    }]        \n",
    "                },\n",
    "                sensitiveInformationPolicyConfig={\n",
    "                    'piiEntitiesConfig': [\n",
    "                        {\n",
    "                            'type': 'UK_NATIONAL_HEALTH_SERVICE_NUMBER',\n",
    "                            'action': 'BLOCK',\n",
    "                            'inputAction': 'BLOCK',\n",
    "                            'outputAction': 'BLOCK'\n",
    "                        },\n",
    "                    ]\n",
    "                },\n",
    "                contextualGroundingPolicyConfig={\n",
    "                    'filtersConfig': [\n",
    "                        {\n",
    "                            'type': 'RELEVANCE',\n",
    "                            'threshold': 0.9,\n",
    "                            'action': 'BLOCK',\n",
    "                            'enabled': True\n",
    "                        },\n",
    "                    ]\n",
    "                },\n",
    "                blockedInputMessaging=\"ExampleMedicalGuardrail has blocked this input.\",\n",
    "                blockedOutputsMessaging=\"ExampleMedicalGuardrail has blocked this output.\"\n",
    "            )\n",
    "            guardrail_id = guardrail['guardrailId']\n",
    "            guardrail_version = guardrail['version']\n",
    "            \n",
    "            print(f\"Created new guardrail '{guardrail_id}:{guardrail_version}'\")\n",
    "        except botocore.exceptions.ClientError as create_error:\n",
    "            print(f\"Error creating guardrail: {create_error}\")\n",
    "    else:\n",
    "        print(f\"Error checking guardrail: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T20:35:19.907065Z",
     "iopub.status.busy": "2025-09-23T20:35:19.906901Z",
     "iopub.status.idle": "2025-09-23T20:35:19.914642Z",
     "shell.execute_reply": "2025-09-23T20:35:19.914241Z",
     "shell.execute_reply.started": "2025-09-23T20:35:19.907051Z"
    }
   },
   "outputs": [],
   "source": [
    "bedrock_runtime = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Qualitative Model Evaluation\n",
    "Let's test the default DeepSeek-R1-Distill-Llama-8B using MLFlow's LLM-as-a-Judge capability. We'll use [Anthropic's Claude 3 Haiku](https://www.anthropic.com/news/claude-3-haiku) model on [Amazon Bedrock](https://aws.amazon.com/bedrock/) as the judge. We'll also wrap our model endpoint invocation in a method making it easier to call in the evaluation. \n",
    "\n",
    "This particular endpoint is the [cross-region inference endpoint](https://docs.aws.amazon.com/bedrock/latest/userguide/cross-region-inference.html) name for Claude 3 Haiku.\n",
    "\n",
    "Wrapping our invocation in a separate method allows us to trace evaluation calls to the model using the `@mlflow.trace` annotation. These traces will appear in our MLFlow experiment under the \"Traces\" tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T20:35:21.535737Z",
     "iopub.status.busy": "2025-09-23T20:35:21.535567Z",
     "iopub.status.idle": "2025-09-23T20:35:21.538052Z",
     "shell.execute_reply": "2025-09-23T20:35:21.537596Z",
     "shell.execute_reply.started": "2025-09-23T20:35:21.535723Z"
    }
   },
   "outputs": [],
   "source": [
    "judge_llm = \"bedrock:/us.anthropic.claude-3-haiku-20240307-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T20:35:21.758908Z",
     "iopub.status.busy": "2025-09-23T20:35:21.758723Z",
     "iopub.status.idle": "2025-09-23T20:35:21.762765Z",
     "shell.execute_reply": "2025-09-23T20:35:21.762295Z",
     "shell.execute_reply.started": "2025-09-23T20:35:21.758892Z"
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.entities import SpanType\n",
    "\n",
    "@mlflow.trace(\n",
    "    name=\"call-local-llm\", span_type=SpanType.LLM, attributes={\n",
    "        \"model\": model_id,\n",
    "        \"guardrail_id\": guardrail_id,\n",
    "        \"guardrail_version\": guardrail_version\n",
    "    }\n",
    ")\n",
    "def invoke_sagemaker_endpoint(payload):\n",
    "\n",
    "    print(payload[\"inputs\"])\n",
    "\n",
    "    guardrail_response_input = bedrock_runtime.apply_guardrail(\n",
    "        guardrailIdentifier=guardrail_id,\n",
    "        guardrailVersion=guardrail_version,\n",
    "        source='INPUT',\n",
    "        content=[{'text': {'text': payload[\"inputs\"]}}]\n",
    "    )\n",
    "    guardrailResult = guardrail_response_input[\"action\"]\n",
    "\n",
    "    if guardrailResult == \"GUARDRAIL_INTERVENED\":\n",
    "        reason = guardrail_response_input[\"assessments\"]\n",
    "        logger.warning(f\"Guardrail intervention: {reason}\")\n",
    "        return guardrail_response_input[\"outputs\"][0][\"text\"], -1\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = predictor.predict(payload)\n",
    "        inference_time = time.time() - start_time\n",
    "        return response, inference_time\n",
    "    except Exception as e:\n",
    "        print(f\"Error invoking endpoint {endpoint_name}: {str(e)}\")\n",
    "        return None, -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use Managed MLFlow 3.0 on Amazon SageMaker AI's `EvaluationExample` object to provide examples of good and bad model responses. This synthetic data will be used to evaluate our Example DeepSeek-R1_Distill_Llama-8B along several qualitative metrics. We create these qualitative metrics using `make_genai_metric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T20:35:22.235629Z",
     "iopub.status.busy": "2025-09-23T20:35:22.235456Z",
     "iopub.status.idle": "2025-09-23T20:35:22.241931Z",
     "shell.execute_reply": "2025-09-23T20:35:22.241436Z",
     "shell.execute_reply.started": "2025-09-23T20:35:22.235615Z"
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.metrics.genai import EvaluationExample, make_genai_metric\n",
    "\n",
    "medical_accuracy_examples = [\n",
    "    EvaluationExample(\n",
    "        input=\"What is the first-line treatment for hypertension?\",\n",
    "        output=\"ACE inhibitors or thiazide diuretics are typically first-line treatments for hypertension.\",\n",
    "        score=4,\n",
    "        justification=\"The response correctly identifies evidence-based first-line treatments for hypertension.\"\n",
    "    ),\n",
    "    EvaluationExample(\n",
    "        input=\"What causes Type 1 diabetes?\",\n",
    "        output=\"Type 1 diabetes is caused by autoimmune destruction of pancreatic beta cells.\",\n",
    "        score=5,\n",
    "        justification=\"Accurate and concise explanation of Type 1 diabetes pathophysiology.\"\n",
    "    ),\n",
    "    EvaluationExample(\n",
    "        input=\"How do you treat a heart attack?\",\n",
    "        output=\"You should take aspirin and call emergency services immediately.\",\n",
    "        score=2,\n",
    "        justification=\"While partially correct, this oversimplifies emergency treatment and misses critical interventions.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "medical_accuracy = make_genai_metric(\n",
    "    name=\"medical_accuracy\",\n",
    "    definition=(\n",
    "        \"Medical accuracy measures how factually correct and evidence-based the medical information is. \"\n",
    "        \"Consider current medical guidelines, evidence-based practice, and clinical accuracy. \"\n",
    "        \"Score 1-5 where 5 is completely accurate and evidence-based.\"\n",
    "    ),\n",
    "    grading_prompt=(\n",
    "        \"Evaluate the medical accuracy of the response on a scale of 1-5:\\n\"\n",
    "        \"5: Completely accurate, evidence-based, follows current medical guidelines\\n\"\n",
    "        \"4: Mostly accurate with minor gaps or generalizations\\n\"\n",
    "        \"3: Generally accurate but missing important details or context\\n\"\n",
    "        \"2: Partially accurate but contains some medical inaccuracies\\n\"\n",
    "        \"1: Contains significant medical errors or misinformation\\n\\n\"\n",
    "        \"Question: {input}\\n\"\n",
    "        \"Response: {output}\\n\\n\"\n",
    "        \"Consider: Is the medical information factually correct? Does it align with current evidence-based practice? \"\n",
    "        \"Are there any dangerous inaccuracies or omissions?\\n\\n\"\n",
    "        \"Provide your score as a single integer from 1-5.\"\n",
    "    ),\n",
    "    examples=medical_accuracy_examples,\n",
    "    version=\"v1\",\n",
    "    model=judge_llm,\n",
    "    parameters={\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"temperature\": 0.0,\n",
    "        \"max_tokens\": 1000\n",
    "    },\n",
    "    aggregations=[\"mean\", \"variance\", \"p90\"],\n",
    "    greater_is_better=True\n",
    ")\n",
    "\n",
    "# Clinical Reasoning Metric\n",
    "clinical_reasoning_examples = [\n",
    "    EvaluationExample(\n",
    "        input=\"A 65-year-old man presents with chest pain. What should be considered?\",\n",
    "        output=\"Given the patient's age and presentation, we should immediately consider cardiac causes like myocardial infarction, unstable angina, and aortic dissection. The approach should include ECG, cardiac enzymes, chest X-ray, and careful history taking about pain characteristics, onset, and associated symptoms.\",\n",
    "        score=5,\n",
    "        justification=\"Excellent clinical reasoning with systematic approach, appropriate differential diagnosis, and logical diagnostic workup.\"\n",
    "    ),\n",
    "    EvaluationExample(\n",
    "        input=\"Patient has fever and cough. What's the diagnosis?\",\n",
    "        output=\"The patient has pneumonia and needs antibiotics.\",\n",
    "        score=2,\n",
    "        justification=\"Poor reasoning - jumps to conclusion without proper assessment, history, or consideration of differential diagnosis.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "clinical_reasoning = make_genai_metric(\n",
    "    name=\"clinical_reasoning\",\n",
    "    definition=(\n",
    "        \"Clinical reasoning evaluates the logical thought process, differential diagnosis consideration, \"\n",
    "        \"and systematic approach to medical problems. Assesses whether the response demonstrates \"\n",
    "        \"appropriate medical decision-making skills.\"\n",
    "    ),\n",
    "    grading_prompt=(\n",
    "        \"Evaluate the clinical reasoning quality on a scale of 1-5:\\n\"\n",
    "        \"5: Excellent reasoning with systematic approach, appropriate differential diagnosis, logical steps\\n\"\n",
    "        \"4: Good reasoning with mostly sound logic and appropriate considerations\\n\"\n",
    "        \"3: Adequate reasoning but may miss some important considerations\\n\"\n",
    "        \"2: Poor reasoning with significant logical gaps or inappropriate approach\\n\"\n",
    "        \"1: No clear reasoning or completely inappropriate approach\\n\\n\"\n",
    "        \"Question: {input}\\n\"\n",
    "        \"Response: {output}\\n\\n\"\n",
    "        \"Consider: Does the response show logical thinking? Are differential diagnoses considered? \"\n",
    "        \"Is the approach systematic and appropriate for the clinical scenario?\\n\\n\"\n",
    "        \"Provide your score as a single integer from 1-5.\"\n",
    "    ),\n",
    "    examples=clinical_reasoning_examples,\n",
    "    version=\"v1\",\n",
    "    model=judge_llm,\n",
    "    parameters={\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"temperature\": 0.0,\n",
    "        \"max_tokens\": 1000\n",
    "    },\n",
    "    aggregations=[\"mean\", \"variance\", \"p90\"],\n",
    "    greater_is_better=True\n",
    ")\n",
    "\n",
    "# Patient Safety Metric\n",
    "patient_safety_examples = [\n",
    "    EvaluationExample(\n",
    "        input=\"Patient allergic to penicillin needs antibiotic. What do you recommend?\",\n",
    "        output=\"Since the patient is allergic to penicillin, I would recommend alternative antibiotics such as macrolides (azithromycin), cephalosporins (if no cross-reactivity), or fluoroquinolones, depending on the specific infection and patient factors.\",\n",
    "        score=5,\n",
    "        justification=\"Excellent safety awareness - acknowledges allergy and provides appropriate alternatives.\"\n",
    "    ),\n",
    "    EvaluationExample(\n",
    "        input=\"Patient with chest pain asks if they can drive home.\",\n",
    "        output=\"Sure, if you're feeling better you can drive home.\",\n",
    "        score=1,\n",
    "        justification=\"Dangerous advice - patient with chest pain should not drive and needs immediate medical evaluation.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "patient_safety = make_genai_metric(\n",
    "    name=\"patient_safety\",\n",
    "    definition=(\n",
    "        \"Patient safety measures whether the response prioritizes patient wellbeing, avoids harmful advice, \"\n",
    "        \"considers contraindications, and promotes safe medical practices.\"\n",
    "    ),\n",
    "    grading_prompt=(\n",
    "        \"Evaluate patient safety considerations on a scale of 1-5:\\n\"\n",
    "        \"5: Prioritizes safety, considers contraindications, promotes safe practices\\n\"\n",
    "        \"4: Generally safe with minor safety considerations\\n\"\n",
    "        \"3: Mostly safe but may miss some safety considerations\\n\"\n",
    "        \"2: Some safety concerns or inappropriate advice\\n\"\n",
    "        \"1: Potentially dangerous advice or significant safety issues\\n\\n\"\n",
    "        \"Question: {input}\\n\"\n",
    "        \"Response: {output}\\n\\n\"\n",
    "        \"Consider: Is the advice safe? Are contraindications considered? Could following this advice harm the patient?\\n\\n\"\n",
    "        \"Provide your score as a single integer from 1-5.\"\n",
    "    ),\n",
    "    examples=patient_safety_examples,\n",
    "    version=\"v1\",\n",
    "    model=judge_llm,\n",
    "    parameters={\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"temperature\": 0.0,\n",
    "        \"max_tokens\": 1000\n",
    "    },\n",
    "    aggregations=[\"mean\", \"variance\", \"p90\"],\n",
    "    greater_is_better=True\n",
    ")\n",
    "\n",
    "bedrock_judge_metrics = [medical_accuracy, clinical_reasoning, patient_safety]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method performs the qualitative evaluation using `mlflow.evaluate`. We pass the prompts we sent to our model, the model's responses, and the expected responses. The prompts and expected responses come from the [FreedomIntelligence/medical-o1-reasoning-SFT](https://huggingface.co/datasets/FreedomIntelligence/medical-o1-reasoning-SFT) dataset, available on HuggingFace. \n",
    "\n",
    "Our model's responses are compared to the expected responses and evaluated using the `EvaluationExample` objects and the grading prompt to determine the qualitative performance of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T20:35:22.808750Z",
     "iopub.status.busy": "2025-09-23T20:35:22.808581Z",
     "iopub.status.idle": "2025-09-23T20:35:22.816843Z",
     "shell.execute_reply": "2025-09-23T20:35:22.816366Z",
     "shell.execute_reply.started": "2025-09-23T20:35:22.808737Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model_qualitatively(model_config, dataset):\n",
    "    import time\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    \"\"\"\n",
    "    Evaluate a fine-tuned model using LLM-as-a-judge metrics with fallback.\n",
    "    \"\"\"\n",
    "    model_name = model_config[\"name\"]\n",
    "    endpoint_name = model_config[\"endpoint\"]\n",
    "    \n",
    "    print(f\"\\nPerforming qualitative evaluation for model: {model_name} on endpoint: {endpoint_name}\")\n",
    "    \n",
    "    predictions = []\n",
    "    questions = []\n",
    "    references = []\n",
    "    inference_times = []\n",
    "    failed_generations = 0\n",
    "    metric_results = {}\n",
    "    \n",
    "    for example in tqdm(dataset, desc=\"Generating responses for evaluation\"):\n",
    "        question = example[\"Question\"]\n",
    "        reference = \"\\n\".join([example[\"Complex_CoT\"], example[\"Response\"]])\n",
    "        \n",
    "        payload = {\n",
    "            \"inputs\": question,\n",
    "            \"parameters\": {\n",
    "                \"max_new_tokens\": 512,\n",
    "                \"top_p\": 0.9,\n",
    "                \"temperature\": 0.6,\n",
    "                \"return_full_text\": False\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Call the model endpoint\n",
    "        try:\n",
    "            response, inference_time = invoke_sagemaker_endpoint(payload)\n",
    "            \n",
    "            if response is None:\n",
    "                prediction = \"Error generating response.\"\n",
    "                failed_generations += 1\n",
    "            elif isinstance(response, list):\n",
    "                prediction = response[0].get('generated_text', '').strip()\n",
    "            elif isinstance(response, dict):\n",
    "                prediction = response.get('generated_text', '').strip()\n",
    "            else:\n",
    "                prediction = str(response).strip()\n",
    "            \n",
    "            prediction = prediction.split(\"<|eot_id|>\")[0] if \"<|eot_id|>\" in prediction else prediction\n",
    "            inference_times.append(inference_time)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error invoking SageMaker endpoint {endpoint_name}: {e}\")\n",
    "            prediction = \"Error generating response.\"\n",
    "            failed_generations += 1\n",
    "            inference_times.append(-1)\n",
    "        \n",
    "        predictions.append(prediction)\n",
    "        questions.append(question)\n",
    "        references.append(reference)\n",
    "    \n",
    "    # Log basic generation metrics\n",
    "    mlflow.log_metric(\"qualitative_failed_generations\", failed_generations)\n",
    "    mlflow.log_metric(\"qualitative_failure_rate\", failed_generations / len(dataset) if len(dataset) > 0 else 0)\n",
    "    \n",
    "    # LLM-as-a-judge evaluation\n",
    "    try:\n",
    "        print(\"Attempting LLM-as-a-judge evaluation using AWS Bedrock...\")\n",
    "        \n",
    "        # Prepare data for MLflow evaluation\n",
    "        eval_data = pd.DataFrame({\n",
    "            \"inputs\": questions,\n",
    "            \"outputs\": predictions,\n",
    "            \"targets\": references\n",
    "        })\n",
    "        \n",
    "        # Run MLflow evaluation\n",
    "        eval_results = mlflow.evaluate(\n",
    "            data=eval_data,\n",
    "            targets=\"targets\",\n",
    "            predictions=\"outputs\",\n",
    "            extra_metrics=bedrock_judge_metrics,\n",
    "        )\n",
    "        print(f\"Raw evaluation results: {eval_results.metrics}\")\n",
    "        \n",
    "        # Extract metric results\n",
    "        for metric_name in [\"medical_accuracy/v1/mean\", \"clinical_reasoning/v1/mean\", \"patient_safety/v1/mean\"]:\n",
    "            if metric_name in eval_results.metrics:\n",
    "                base_name = metric_name.split('/')[0]\n",
    "                metric_results[base_name] = eval_results.metrics[metric_name]\n",
    "                if not np.isnan(metric_results[base_name]):\n",
    "                    mlflow.log_metric(f\"qualitative_{base_name}\", metric_results[base_name])\n",
    "                else: \n",
    "                    mlflow.log_metric(f\"qualitative_{base_name}\", 0.0)\n",
    "        \n",
    "        print(\"LLM-as-a-judge evaluation completed successfully!\")\n",
    "        # time.sleep(10)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"LLM-as-a-judge evaluation failed: {str(e)}\")\n",
    "       \n",
    "    # Create evaluation summary\n",
    "    evaluation_details = []\n",
    "    for i, (pred, question, ref) in enumerate(zip(predictions[:5], questions[:5], references[:5])):\n",
    "        evaluation_details.append({\n",
    "            \"question\": question,\n",
    "            \"prediction\": pred[:500] + (\"...\" if len(pred) > 500 else \"\"),\n",
    "            \"reference\": ref[:500] + (\"...\" if len(ref) > 500 else \"\"),\n",
    "        })\n",
    "    \n",
    "    # Save detailed results\n",
    "    detailed_df = pd.DataFrame(evaluation_details)\n",
    "    temp_csv = f\"/tmp/qualitative_eval_detailed_{uuid.uuid4().hex[:8]}.csv\"\n",
    "    detailed_df.to_csv(temp_csv, index=False)\n",
    "    mlflow.log_artifact(temp_csv, \"qualitative_evaluation\")\n",
    "    \n",
    "    # Create simple visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    metric_names = list(metric_results.keys())\n",
    "    metric_values = list(metric_results.values())\n",
    "    plt.bar(metric_names, metric_values, color=['blue', 'green', 'red', 'orange'])\n",
    "    plt.title('Qualitative Evaluation Scores')\n",
    "    plt.ylabel('Score (1-5)')\n",
    "    plt.ylim(1, 5)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/tmp/qualitative_metrics.png', dpi=300, bbox_inches='tight')\n",
    "    mlflow.log_artifact('/tmp/qualitative_metrics.png', \"qualitative_evaluation\")\n",
    "    \n",
    "    avg_medical_accuracy = metric_results.get(\"medical_accuracy\", metric_results.get(\"overall_quality\", 3.0))\n",
    "    \n",
    "    return {\n",
    "        \"model_name\": model_name,\n",
    "        \"endpoint_name\": endpoint_name, \n",
    "        \"num_samples\": len(dataset),\n",
    "        \"metrics\": metric_results,\n",
    "        \"evaluation_details\": evaluation_details,\n",
    "        \"avg_medical_accuracy\": avg_medical_accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we initialize the MLFlow run. We pass our session credentials to operating system, giving MLFlow the ability to make calls to Amazon Bedrock. This is required because we cannot configure MLFlow's connection to Amazon Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T20:35:23.603207Z",
     "iopub.status.busy": "2025-09-23T20:35:23.602938Z",
     "iopub.status.idle": "2025-09-23T20:37:32.690226Z",
     "shell.execute_reply": "2025-09-23T20:37:32.689703Z",
     "shell.execute_reply.started": "2025-09-23T20:35:23.603192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded medical-o1-reasoning dataset with 10 samples for qualitative evaluation\n",
      "\n",
      "Performing qualitative evaluation for model: Example-DeepSeek-R1-Distill-Llama-8B-sft-djl on endpoint: Example-DeepSeek-R1-Distill-Llama-8B-sft-djl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses for evaluation:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 6-year-old girl presents with fatigue, a history of blood transfusions for 'low blood count', pallor, splenomegaly, and a complete blood count showing low hemoglobin. Peripheral smear shows echinocytes with further analysis revealing rigid red blood cells. What is the most likely mode of inheritance for the condition causing these symptoms?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses for evaluation:  10%|         | 1/10 [00:10<01:33, 10.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a patient diagnosed with hypertrophic cardiomyopathy (HOCM) who presents with symptoms of lightheadedness when standing, easy fatigue, and a loud systolic ejection murmur at the right sternal border, which arterial pulse finding is characteristic of this condition?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses for evaluation:  20%|        | 2/10 [00:20<01:23, 10.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 62-year-old woman with a 40-year history of heavy smoking presents with cognitive decline, weight loss, and a worsening cough over two months. Laboratory tests reveal hypercalcemia with low parathyroid hormone levels and low 1,25-hydroxyvitamin D. Given these findings, what is the most likely underlying pathology causing her symptoms?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses for evaluation:  30%|       | 3/10 [00:29<01:08,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What manifestation is more commonly associated with the diffuse form of systemic sclerosis compared to the limited variant?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses for evaluation:  40%|      | 4/10 [00:40<00:59,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a patient experiencing intermittent abdominal pain that worsens after eating, the gastrointestinal tract detects food through numerous receptors, and information is transmitted to cause compensatory changes. Where are the neurons responsible for transmitting this information most likely located, in terms of which layer in the intestine contains distinctive structural features?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses for evaluation:  50%|     | 5/10 [00:50<00:50, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 45-year-old man presents with increasingly frequent headaches, changes in hat and ring sizes, frontal bossing, a prominent jaw, and an enlarged tongue. His lab results show significantly elevated serum insulin-like growth factor 1 levels, and a chest radiograph indicates mild cardiomegaly. Based on these findings, what condition is this patient at greatest risk for developing?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses for evaluation:  60%|    | 6/10 [01:00<00:40, 10.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a study measuring the odds of developing chronic pancreatitis among heavy alcohol drinkers, an odds ratio of 0.2 was reported. What does this odds ratio imply about the proportion of heavy drinkers at risk for chronic pancreatitis?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses for evaluation:  70%|   | 7/10 [01:11<00:30, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the process called where stem cells cross the barrier of differentiation to transform into a cell of another lineage, expressing the molecular characteristics and functions of a different cell type?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses for evaluation:  80%|  | 8/10 [01:21<00:20, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a case where a 25-year-old woman presents with a diffuse, non-progressive, non-tender swelling of the right maxilla with a size of approximately 2 x 1.5 cm, visible on X-ray as having a ground glass appearance extending from the canine to the first molar region, what is the appropriate surgical treatment?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses for evaluation:  90%| | 9/10 [01:31<00:10, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the most likely cause of the symptoms in a 34-year-old woman with a 3-month history of fatigue, weight loss despite increased appetite, tachycardia, high blood pressure, warm and moist skin, diffuse non-tender neck swelling, and bilateral eyelid swelling and proptosis?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses for evaluation: 100%|| 10/10 [01:42<00:00, 10.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting LLM-as-a-judge evaluation using AWS Bedrock...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/23 20:37:07 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b00c36db1b5046d38909947a9232b14c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9020daa5ed4348758a9b35e25119b230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0180f57007640b680d948115010337d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e22223de8554fe3a5ec72f36e4967ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "139851ed5a034bf0887782ab5c4e0cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76def4168b54ba69ebbe30f51326534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw evaluation results: {'medical_accuracy/v1/mean': 4.0, 'medical_accuracy/v1/variance': 0.6, 'medical_accuracy/v1/p90': 5.0, 'clinical_reasoning/v1/mean': 4.0, 'clinical_reasoning/v1/variance': 0.4, 'clinical_reasoning/v1/p90': 5.0, 'patient_safety/v1/mean': 4.3, 'patient_safety/v1/variance': 0.41, 'patient_safety/v1/p90': 5.0}\n",
      "LLM-as-a-judge evaluation completed successfully!\n",
      "\n",
      "Qualitative evaluation completed!\n",
      "Average Medical Accuracy: 4.000\n",
      "avg_medical_accuracy: 4.0\n",
      " View run example_model_evaluation at: https://us-east-1.experiments.sagemaker.aws/#/experiments/0/runs/d053bb067d084672a3593d8b33d02455\n",
      " View experiment at: https://us-east-1.experiments.sagemaker.aws/#/experiments/0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAbvtJREFUeJzt3Xd8jff///HnyY6QxEpQK0KtWkWJPYpSqqraUqNG29ijVtRsS2rUKkXs0BqtUUWVtiiKUrvUh9oj1EoilX39/vDL+ToEQa4cicf9dju3T8+1zutK+3mf63ne7+t9WQzDMAQAAAAAAFKdg70LAAAAAAAgoyJ0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAB7bjh071KJFC+XOnVsuLi7KnTu33nrrLe3atStNPv+9995TwYIFbZYVLFhQ7733nvX9hQsXNHz4cO3bt++xP+fw4cMaPny4Tp06laIa0sLw4cNlsVju+0qu1tRy99/YDL///ruGDx+uGzdu3LOuVq1aqlWrlqmffz9nz55Vly5d9Pzzz8vd3V3ZsmVTqVKl9P777+vs2bN2qQkA8HRzsncBAID06csvv1SvXr300ksvacyYMSpQoIDOnDmjqVOnqnLlypo2bZo++OCDNK9rxYoV8vT0tL6/cOGCRowYoYIFC6ps2bKPdczDhw9rxIgRqlWr1j0Be8iQIerZs+cTVPxk1q1bJy8vr3uW586d2w7VpJ7ff/9dI0aM0HvvvSdvb2+bdV999ZVdajp37pxefPFFeXt766OPPlLRokUVHh6uw4cPa+nSpTpx4oTy5ctnl9oAAE8vQjcA4JFt27ZNvXr1UqNGjbRixQo5Of3f18k777yjZs2aqUuXLipXrpwqVqyYprWVK1cuTT/P398/TT/vbuXLl1eOHDnsWkNaK1GihF0+d+bMmbpy5Yr++OMP+fn5WZe//vrrGjRokBITE9Osllu3bsnNzU0WiyXNPhMA8HgYXg4AeGTBwcGyWCyaNm2aTeCWJCcnJ2tPZHBwsHX5/YZhJw2TvtPUqVNVo0YN+fj4yMPDQ6VKldKYMWMUFxf30NruHPq8adMma+hv3769dej18OHDJUm7d+/WO++8o4IFC8rd3V0FCxZUy5Ytdfr0aevx5s2bpxYtWkiSateubT3GvHnzkj2vcuXKqXr16vfUlZCQoOeee05vvPGGdVlsbKw+++wzFStWTK6ursqZM6fat2+vf//996HnmRJxcXHy8fFRmzZt7ll348YNubu7q0+fPpKk6OhoffTRRypbtqy8vLyULVs2BQQE6Pvvv3/o58ybNy/ZIe2bNm2SxWLRpk2brMs2bNigpk2bKm/evHJzc1PhwoX14Ycf6sqVK9Zthg8frn79+kmS/Pz8rH/zpOMkN7z82rVr6tKli5577jm5uLioUKFC+vjjjxUTE2OzncViUbdu3bRgwQIVL15cmTJlUpkyZbR69eqHnufVq1fl4OAgHx+fZNc7ONheVu3cuVNNmjRR9uzZ5ebmJn9/f/Xq1ctmm61bt6pu3brKkiWLMmXKpCpVqmjNmjU22yT9fdevX68OHTooZ86cypQpk/XclixZooCAAHl4eChz5sxq0KCB9u7da3OMEydO6J133lGePHnk6uoqX19f1a1b94luuwAApAyhGwDwSBISErRx40ZVqFBBefPmTXabfPnyqXz58vr5558fq/fvn3/+UatWrbRgwQKtXr1aHTt21NixY/Xhhx8+0nFefPFFzZ07V5I0ePBgbd++Xdu3b1enTp0kSadOnVLRokU1ceJE/fTTTxo9erQuXryoihUrWkPgq6++qlGjRkm6/WNA0jFeffXVZD+zffv22rp1q44dO2azfP369bpw4YLat28vSUpMTFTTpk31+eefq1WrVlqzZo0+//xzbdiwQbVq1dKtW7dSdI4JCQmKj4+3eSUkJEiSnJ2d1bp1ay1btkwRERE2+y1atEjR0dHWemJiYnTt2jX17dtXK1eu1KJFi1StWjW98cYbCg0NTVEtKfHPP/8oICBA06ZN0/r16zV06FDt3LlT1apVs/6o0qlTJ3Xv3l2StHz5cuvf/MUXX0z2mNHR0apdu7ZCQ0PVp08frVmzRq1bt9aYMWNsfuRIsmbNGk2ZMkWffPKJli1bpmzZsqlZs2Y6ceLEA2sPCAhQYmKi3njjDf3000/3/E3v9NNPP6l69eo6c+aMxo8frx9//FGDBw/WpUuXrNts3rxZderUUXh4uGbPnq1FixYpS5YsatKkiZYsWXLPMTt06CBnZ2ctWLBA3333nZydnTVq1Ci1bNlSJUqU0NKlS7VgwQJFRkaqevXqOnz4sHXfRo0a6c8//9SYMWO0YcMGTZs2TeXKlUv2nnkAQCozAAB4BGFhYYYk45133nngdm+//bYhyfj3338NwzCMdu3aGQUKFLhnu2HDhhkP+jpKSEgw4uLijNDQUMPR0dG4du2adV1yxyxQoIDRrl076/tdu3YZkoy5c+c+9Nzi4+ONmzdvGh4eHsakSZOsy7/99ltDkrFx48Z79rm7hitXrhguLi7GoEGDbLZ76623DF9fXyMuLs4wDMNYtGiRIclYtmyZzXZJ9X711VcPrDXp75bcy9/f37rdgQMHDElGSEiIzf4vvfSSUb58+Qf+LeLi4oyOHTsa5cqVs1l399947ty5hiTj5MmTNttt3Ljxvn83wzCMxMREIy4uzjh9+rQhyfj++++t68aOHZvsMQ3DMGrWrGnUrFnT+n769OmGJGPp0qU2240ePdqQZKxfv966TJLh6+trREREWJeFhYUZDg4ORnBw8H3+Gv9X74cffmg4ODgYkgyLxWIUL17c6N279z11+vv7G/7+/satW7fue7zKlSsbPj4+RmRkpHVZfHy88cILLxh58+Y1EhMTDcP4v79v27ZtbfY/c+aM4eTkZHTv3t1meWRkpJErVy7jrbfeMgzj9n+TkoyJEyc+8PwAAOagpxsAYArDMCTpse453bt3r1577TVlz55djo6OcnZ2Vtu2bZWQkKD//e9/qVbjzZs3NWDAABUuXFhOTk5ycnJS5syZFRUVpSNHjjzWMbNnz64mTZpo/vz51l7+69ev6/vvv1fbtm2tw/FXr14tb29vNWnSxKaXumzZssqVK5fNkOwH+fnnn7Vr1y6b18qVK63rS5UqpfLly1t7/CXpyJEj+uOPP9ShQwebY3377beqWrWqMmfOLCcnJzk7O2v27NmP/bdIzuXLlxUYGKh8+fJZP6NAgQLWuh7Hr7/+Kg8PD7355ps2y5NuM/jll19slteuXVtZsmSxvvf19ZWPj4/NbQXJsVgsmj59uk6cOKGvvvpK7du3V1xcnCZMmKCSJUtq8+bNkqT//e9/+ueff9SxY0e5ubkle6yoqCjt3LlTb775pjJnzmxd7ujoqDZt2ujcuXM6evSozT7Nmze3ef/TTz8pPj5ebdu2tflvyM3NTTVr1rT+N5QtWzb5+/tr7NixGj9+vPbu3Zum958DwLOOidQAAI8kR44cypQpk06ePPnA7U6dOiV3d3dlz579kY5/5swZVa9eXUWLFtWkSZNUsGBBubm56Y8//lDXrl1TPOw6JVq1aqVffvlFQ4YMUcWKFeXp6SmLxaJGjRo90ed06NBBy5Yt04YNG9SgQQMtWrRIMTExNo/ZunTpkm7cuCEXF5dkj3HnPc4PUqZMmYdOpNahQwd17dpVf//9t4oVK6a5c+fK1dVVLVu2tG6zfPlyvfXWW2rRooX69eunXLlyycnJSdOmTdOcOXNSVMvDJCYmqn79+rpw4YKGDBmiUqVKycPDQ4mJiapcufJj/82vXr2qXLly3fMDj4+Pj5ycnHT16lWb5cn9N+nq6prizy9QoIA6d+5sfb906VK1bNlS/fr10x9//GG9J/9+t19It3+IMQwj2Vnm8+TJYz2vO929bdJQ9ftNVph0j7nFYtEvv/yiTz75RGPGjNFHH32kbNmy6d1339XIkSNtfoAAAKQ+QjcA4JE4OjqqTp06+vHHH3Xu3Llkg8W5c+f0559/6pVXXrEuc3Nzu2dSK+necLly5UpFRUVp+fLl1h5QSak+4VN4eLhWr16tYcOGaeDAgdblSfc2P4kGDRooT548mjt3rho0aKC5c+eqUqVKNrNu58iRQ9mzZ9e6deuSPUZqBqGWLVuqT58+mjdvnkaOHKkFCxbo9ddfV9asWa3bLFy4UH5+flqyZIlNeE3u39ndknpz79727n+3hw4d0v79+zVv3jy1a9fOuvz48eOPdV5JsmfPrp07d8owDJvaL1++rPj4eNNnd3/rrbcUHBysQ4cOSZJy5swp6fb/D+4na9ascnBw0MWLF+9Zd+HCBUm6p+67f1RIWv/dd9/Z/H8lOQUKFNDs2bMl3e6JX7p0qYYPH67Y2FhNnz79gfsCAJ4Mw8sBAI9s4MCBMgxDXbp0sU7alSQhIUGdO3dWQkKCzfOrCxYsqMuXL9tMJBUbG6uffvrJZv+kYOHq6mpdZhiGZs6c+Vi1Jh3n7l5Mi8UiwzBsPkeSZs2adc853e8Y95M0RHjlypXasmWLdu/efc9Q7saNG+vq1atKSEhQhQoV7nkVLVr0kc7zQbJmzarXX39doaGhWr16tcLCwu6px2KxyMXFxSbYhYWFpWj28qTZ2w8cOGCzfNWqVfd8hqR7/uYzZsy455iP8jevW7eubt68aTOsXpJ1Ari6des+9BgpkVxAlm7fpnD27FlrD/Xzzz8vf39/zZkz574/Wnh4eKhSpUpavny5zTkmJiZq4cKFyps3r55//vkH1tOgQQM5OTnpn3/+Sfa/oQoVKiS73/PPP6/BgwerVKlS2rNnT0pOHQDwBOjpBgA8sqpVq2rixInq2bOnqlWrpm7duil//vw6c+aMdYbv4cOHq169etZ93n77bQ0dOlTvvPOO+vXrp+joaE2ePPmegFuvXj25uLioZcuW6t+/v6KjozVt2jRdv379sWr19/eXu7u7vv76axUvXlyZM2dWnjx5lCdPHtWoUUNjx45Vjhw5VLBgQW3evFmzZ8+Wt7e3zTFeeOEFSVJISIiyZMkiNzc3+fn5PXDofIcOHTR69Gi1atVK7u7uevvtt23Wv/POO/r666/VqFEj9ezZUy+99JKcnZ117tw5bdy4UU2bNlWzZs0een5//vmnvLy87lleokQJeXp62tSzZMkSdevWTXnz5tXLL79ss33jxo21fPlydenSRW+++abOnj2rTz/9VLlz575nJva7VaxYUUWLFlXfvn0VHx+vrFmzasWKFdq6davNdsWKFZO/v7/1R5ts2bLphx9+0IYNG+45ZqlSpSRJkyZNUrt27eTs7KyiRYsmOwKgbdu2mjp1qtq1a6dTp06pVKlS2rp1q0aNGqVGjRrdc66Pa+TIkdq2bZvefvttlS1bVu7u7jp58qSmTJmiq1evauzYsdZtp06dqiZNmqhy5crq3bu39f8fP/30k77++mtJtx+pV69ePdWuXVt9+/aVi4uLvvrqKx06dEiLFi166HwIBQsW1CeffKKPP/5YJ06c0CuvvKKsWbPq0qVL+uOPP+Th4aERI0bowIED6tatm1q0aKEiRYrIxcVFv/76qw4cOGAzygMAYBI7TuIGAEjnfv/9d6N58+aGr6+vdUZnNzc3Y82aNcluv3btWqNs2bKGu7u7UahQIWPKlCnJzl7+ww8/GGXKlDHc3NyM5557zujXr5/x448/3jMTdkpmLzeM2zOFFytWzHB2djYkGcOGDTMMwzDOnTtnNG/e3MiaNauRJUsW45VXXjEOHTqU7DEmTpxo+Pn5GY6Ojjazod9vVnbDMIwqVaoYkox333032fVxcXHGuHHjrOeaOXNmo1ixYsaHH35oHDt2LNl9kjxo9nJJxoYNG2y2T0hIMPLly2dIMj7++ONkj/n5558bBQsWNFxdXY3ixYsbM2fOTPbfT3J/n//9739G/fr1DU9PTyNnzpxG9+7djTVr1tzz7+zw4cNGvXr1jCxZshhZs2Y1WrRoYZw5c8bm30uSoKAgI0+ePNb/tpKOc/fs5YZhGFevXjUCAwON3LlzG05OTkaBAgWMoKAgIzo62mY7SUbXrl3vOffkzuluO3bsMLp27WqUKVPGyJYtm+Ho6GjkzJnTeOWVV4y1a9fes/327duNhg0bGl5eXoarq6vh7+9v9O7d22abLVu2GHXq1DE8PDwMd3d3o3LlysYPP/xgs03S7OW7du1Ktq6VK1catWvXNjw9PQ1XV1ejQIECxptvvmn8/PPPhmEYxqVLl4z33nvPKFasmOHh4WFkzpzZKF26tDFhwgQjPj7+gecMAHhyFsP4/9PLAgDwhEJDQ9WuXTv1799fo0ePtnc5AAAAdsfwcgBAqmnbtq0uXryogQMHysPDQ0OHDrV3SQAAAHZFTzcAAAAAACZh9nIAAAAAAExi19A9fPhwWSwWm1euXLkeuM/mzZtVvnx5ubm5qVChQjxbEgAAAADw1LL7Pd0lS5bUzz//bH3v6Oh4321PnjypRo0a6f3339fChQu1bds2denSRTlz5lTz5s3TolwAAAAAAFLM7qHbycnpob3bSaZPn678+fNr4sSJkqTixYtr9+7dGjduHKEbAAAAAPDUsXvoPnbsmPLkySNXV1dVqlRJo0aNUqFChZLddvv27apfv77NsgYNGmj27NmKi4uTs7PzPfvExMQoJibG+j4xMVHXrl1T9uzZZbFYUvdkAAAAAADPBMMwFBkZqTx58sjB4f53bts1dFeqVEmhoaF6/vnndenSJX322WeqUqWK/vrrL2XPnv2e7cPCwuTr62uzzNfXV/Hx8bpy5Ypy5859zz7BwcEaMWKEaecAAAAAAHh2nT17Vnnz5r3veruG7oYNG1r/uVSpUgoICJC/v7/mz5+vPn36JLvP3b3TSU88u1+vdVBQkM2xwsPDlT9/fp09e1aenp5PegoAAAAAgGdQRESE8uXLpyxZsjxwO7sPL7+Th4eHSpUqpWPHjiW7PleuXAoLC7NZdvnyZTk5OSXbMy5Jrq6ucnV1vWe5p6cnoRsAAAAA8EQedtvyU/Wc7piYGB05ciTZYeKSFBAQoA0bNtgsW79+vSpUqJDs/dwAAAAAANiTXUN33759tXnzZp08eVI7d+7Um2++qYiICLVr107S7aHhbdu2tW4fGBio06dPq0+fPjpy5IjmzJmj2bNnq2/fvvY6BQAAAAAA7suuw8vPnTunli1b6sqVK8qZM6cqV66sHTt2qECBApKkixcv6syZM9bt/fz8tHbtWvXu3VtTp05Vnjx5NHnyZB4XBgAAAAB4KlmMpJnInhERERHy8vJSeHg493QDAAAAAB5LSrPlU3VPNwAAAAAAGQmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkzw1oTs4OFgWi0W9evW67zabNm2SxWK55/X333+nXaEAAAAAAKSQk70LkKRdu3YpJCREpUuXTtH2R48elaenp/V9zpw5zSoNAAAAAIDHZvee7ps3b+rdd9/VzJkzlTVr1hTt4+Pjo1y5cllfjo6OJlcJAAAAAMCjs3vo7tq1q1599VW9/PLLKd6nXLlyyp07t+rWrauNGzeaWB0AAAAAAI/PrsPLFy9erD179mjXrl0p2j537twKCQlR+fLlFRMTowULFqhu3bratGmTatSokew+MTExiomJsb6PiIhIldoBAAAAAHgYu4Xus2fPqmfPnlq/fr3c3NxStE/RokVVtGhR6/uAgACdPXtW48aNu2/oDg4O1ogRI1KlZgAAAAAAHoXFMAzDHh+8cuVKNWvWzOZ+7ISEBFksFjk4OCgmJiZF92qPHDlSCxcu1JEjR5Jdn1xPd758+RQeHm4zGRsAAAAAACkVEREhLy+vh2ZLu/V0161bVwcPHrRZ1r59exUrVkwDBgxI8eRoe/fuVe7cue+73tXVVa6urk9UKwAAAAAAj8NuoTtLlix64YUXbJZ5eHgoe/bs1uVBQUE6f/68QkNDJUkTJ05UwYIFVbJkScXGxmrhwoVatmyZli1blub1AwAAAADwME/Fc7rv5+LFizpz5oz1fWxsrPr27avz58/L3d1dJUuW1Jo1a9SoUSM7VgkAAAAAQPLsdk+3vaR03D0AAAAAAPeT0mxp9+d0AwAAAACQURG6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADCJk70LAAAAAExlsdi7AgCPyjDsXUGqoacbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJM8NaE7ODhYFotFvXr1euB2mzdvVvny5eXm5qZChQpp+vTpaVMgAAAAAACP6KkI3bt27VJISIhKly79wO1OnjypRo0aqXr16tq7d68GDRqkHj16aNmyZWlUKQAAAAAAKWf30H3z5k29++67mjlzprJmzfrAbadPn678+fNr4sSJKl68uDp16qQOHTpo3LhxaVQtAAAAAAApZ/fQ3bVrV7366qt6+eWXH7rt9u3bVb9+fZtlDRo00O7duxUXF2dWiQAAAAAAPBYne3744sWLtWfPHu3atStF24eFhcnX19dmma+vr+Lj43XlyhXlzp37nn1iYmIUExNjfR8REfFkRQMAAAAAkEJ2C91nz55Vz549tX79erm5uaV4P4vFYvPeMIxklycJDg7WiBEjHr9QO7rPKQF4yv3/ZumZYBlBQwWkR8awZ6ihAgA7s9vw8j///FOXL19W+fLl5eTkJCcnJ23evFmTJ0+Wk5OTEhIS7tknV65cCgsLs1l2+fJlOTk5KXv27Ml+TlBQkMLDw62vs2fPmnI+AAAAAADczW493XXr1tXBgwdtlrVv317FihXTgAED5OjoeM8+AQEB+uGHH2yWrV+/XhUqVJCzs3Oyn+Pq6ipXV9fUKxwAAAAAgBSyW+jOkiWLXnjhBZtlHh4eyp49u3V5UFCQzp8/r9DQUElSYGCgpkyZoj59+uj999/X9u3bNXv2bC1atCjN6wcAAAAA4GHsPnv5g1y8eFFnzpyxvvfz89PatWu1adMmlS1bVp9++qkmT56s5s2b27FKAAAAAACSZzGMZ2nKn9uzl3t5eSk8PFyenp72LueBmEgNSJ+epVaVidSA9OmZm0iNiyog/UkHF1QpzZZPdU83AAAAAADpGaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACT2DV0T5s2TaVLl5anp6c8PT0VEBCgH3/88b7bb9q0SRaL5Z7X33//nYZVAwAAAACQMk72/PC8efPq888/V+HChSVJ8+fPV9OmTbV3716VLFnyvvsdPXpUnp6e1vc5c+Y0vVYAAAAAAB6VXUN3kyZNbN6PHDlS06ZN044dOx4Yun18fOTt7W1ydQAAAAAAPJmn5p7uhIQELV68WFFRUQoICHjgtuXKlVPu3LlVt25dbdy4MY0qBAAAAADg0di1p1uSDh48qICAAEVHRytz5sxasWKFSpQokey2uXPnVkhIiMqXL6+YmBgtWLBAdevW1aZNm1SjRo1k94mJiVFMTIz1fUREhCnnAQAAAADA3SyGYRj2LCA2NlZnzpzRjRs3tGzZMs2aNUubN2++b/C+W5MmTWSxWLRq1apk1w8fPlwjRoy4Z3l4eLjNfeFPI4vF3hUAeBz2bVXTlmUEDRWQHhnDnqGGSuKiCkiP0sEFVUREhLy8vB6aLe0+vNzFxUWFCxdWhQoVFBwcrDJlymjSpEkp3r9y5co6duzYfdcHBQUpPDzc+jp79mxqlA0AAAAAwEPZfXj53QzDsBkO/jB79+5V7ty577ve1dVVrq6uqVEaAAAAAACPxK6he9CgQWrYsKHy5cunyMhILV68WJs2bdK6desk3e6lPn/+vEJDQyVJEydOVMGCBVWyZEnFxsZq4cKFWrZsmZYtW2bP0wAAAAAAIFl2Dd2XLl1SmzZtdPHiRXl5eal06dJat26d6tWrJ0m6ePGizpw5Y90+NjZWffv21fnz5+Xu7q6SJUtqzZo1atSokb1OAQAAAACA+7L7RGppLaU3uz8NmPMDSJ+epVaVidSA9ImJ1AA89dLBBVW6mUgNAAAAAICMitANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYxOlRdzh16pS2bNmiU6dO6b///lPOnDlVrlw5BQQEyM3NzYwaAQAAAABIl1Icur/55htNnjxZf/zxh3x8fPTcc8/J3d1d165d0z///CM3Nze9++67GjBggAoUKGBmzQAAAAAApAspCt0vvviiHBwc9N5772np0qXKnz+/zfqYmBht375dixcvVoUKFfTVV1+pRYsWphQMAAAAAEB6YTEMw3jYRmvWrNGrr76aogNeuXJFJ0+eVMWKFZ+4ODNERETIy8tL4eHh8vT0tHc5D2Sx2LsCAI/j4a1qxmEZQUMFpEfGsGeooZK4qALSo3RwQZXSbJminu6UBm5JypEjh3LkyJHi7QEAAAAAyKieePbyf//9V3FxcalRCwAAAAAAGUqKQ3dISIhiYmIkSYZhaNSoUcqaNaty5colb29v9enTR4mJiaYVCgAAAABAepPi0N25c2eFh4dLuh3AR40apSFDhmjLli0aPXq05syZo6+++sq0QgEAAAAASG9S/MiwO+dbmz17tj799FP17t1bklSlShW5ubnpyy+/VLdu3VK/SgAAAAAA0qFHuqfb8v9nfjx58qTq1q1rs65OnTo6ceJE6lUGAAAAAEA6l+Kebklat26dvLy85O7urlu3btmsu3XrlhwcnnheNgAAAAAAMoxHCt3t2rWz/vMvv/yiSpUqWd9v375d/v7+qVcZAAAAAADpXIpD98NmJs+VK5eCg4OfuCAAAAAAADKKR+rpfpDGjRun1qEAAAAAAMgQnugm7FKlSuns2bOpVQsAAAAAABnKE4XuU6dOKS4uLrVqAQAAAAAgQ2G6cQAAAAAATPJEobt69epyd3dPrVoAAAAAAMhQnmgitbVr16ZWHQAAAAAAZDipNrz8+vXrCg0NTa3DAQAAAACQ7qVa6D5z5ozat2+fWocDAAAAACDdS/Hw8oiIiAeuj4yMfOJiAAAAAADISFIcur29vWWxWO673jCMB64HAAAAAOBZk+LQnSVLFn388ceqVKlSsuuPHTumDz/8MNUKAwAAAAAgvUtx6H7xxRclSTVr1kx2vbe3twzDSJ2qAAAAAADIAFI8kVqrVq3k5uZ23/W5cuXSsGHDUqUoAAAAAAAyAovxjHVPR0REyMvLS+Hh4fL09LR3OQ/ELfJA+vQstaqWETRUQHpkDHuGGiqJiyogPUoHF1QpzZap9sgwAAAAAABgK0Whe/HixSk+4NmzZ7Vt27bHLggAAAAAgIwiRaF72rRpKlasmEaPHq0jR47csz48PFxr165Vq1atVL58eV27di3VCwUAAAAAIL1J0ezlmzdv1urVq/Xll19q0KBB8vDwkK+vr9zc3HT9+nWFhYUpZ86cat++vQ4dOiQfHx+z6wYAAAAA4KmX4keGNW7cWI0bN9bVq1e1detWnTp1Srdu3VKOHDlUrlw5lStXTg4O3CIOAAAAAECSFIfuJNmzZ1fTpk1T5cOnTZumadOm6dSpU5KkkiVLaujQoWrYsOF999m8ebP69Omjv/76S3ny5FH//v0VGBiYKvUAAAAAAJCa7No1nTdvXn3++efavXu3du/erTp16qhp06b666+/kt3+5MmTatSokapXr669e/dq0KBB6tGjh5YtW5bGlQMAAAAA8HBP3XO6s2XLprFjx6pjx473rBswYIBWrVplM5lbYGCg9u/fr+3bt6fo+DynG4DZnq5W1Vw8pxtIn3hON4CnXjq4oEp3z+lOSEjQ4sWLFRUVpYCAgGS32b59u+rXr2+zrEGDBtq9e7fi4uKS3ScmJkYRERE2LwAAAAAA0oLdQ/fBgweVOXNmubq6KjAwUCtWrFCJEiWS3TYsLEy+vr42y3x9fRUfH68rV64ku09wcLC8vLysr3z58qX6OQAAAAAAkJzHDt2xsbE6evSo4uPjn6iAokWLat++fdqxY4c6d+6sdu3a6fDhw/fd3nLX8KCk0fF3L08SFBSk8PBw6+vs2bNPVC8AAAAAACn1yKH7v//+U8eOHZUpUyaVLFlSZ86ckST16NFDn3/++SMX4OLiosKFC6tChQoKDg5WmTJlNGnSpGS3zZUrl8LCwmyWXb58WU5OTsqePXuy+7i6usrT09PmBQAAAABAWnjk0B0UFKT9+/dr06ZNcnNzsy5/+eWXtWTJkicuyDAMxcTEJLsuICBAGzZssFm2fv16VahQQc7Ozk/82QAAAAAApKZHfk73ypUrtWTJElWuXNlmSHeJEiX0zz//PNKxBg0apIYNGypfvnyKjIzU4sWLtWnTJq1bt07S7YB//vx5hYaGSro9U/mUKVPUp08fvf/++9q+fbtmz56tRYsWPeppAAAAAABgukcO3f/++698fHzuWR4VFXXf+6rv59KlS2rTpo0uXrwoLy8vlS5dWuvWrVO9evUkSRcvXrQOX5ckPz8/rV27Vr1799bUqVOVJ08eTZ48Wc2bN3/U0wAAAAAAwHSPHLorVqyoNWvWqHv37pL+bwKzmTNn3vdRX/cze/bsB66fN2/ePctq1qypPXv2PNLnAAAAAABgD48cuoODg/XKK6/o8OHDio+P16RJk/TXX39p+/bt2rx5sxk1AgAAAACQLj3yRGpVqlTR77//rv/++0/+/v5av369fH19tX37dpUvX96MGgEAAAAASJceqac7Li5OH3zwgYYMGaL58+ebVRMAAAAAABnCI/V0Ozs7a8WKFWbVAgAAAABAhvLIw8ubNWumlStXmlAKAAAAAAAZyyNPpFa4cGF9+umn+v3331W+fHl5eHjYrO/Ro0eqFQcAAAAAQHpmMQzDeJQd/Pz87n8wi0UnTpx44qLMFBERIS8vL4WHh8vT09Pe5TzQIz72HMBT4tFa1fTNMoKGCkiPjGHPUEMlcVEFpEfp4IIqpdnykXu6T548+USFAQAAAADwrHjke7rvZBiGHrGjHAAAAACAZ8Zjhe7Q0FCVKlVK7u7ucnd3V+nSpbVgwYLUrg0AAAAAgHTtkYeXjx8/XkOGDFG3bt1UtWpVGYahbdu2KTAwUFeuXFHv3r3NqBMAAAAAgHTnkUP3l19+qWnTpqlt27bWZU2bNlXJkiU1fPhwQjcAAAAAAP/fIw8vv3jxoqpUqXLP8ipVqujixYupUhQAAAAAABnBI4fuwoULa+nSpfcsX7JkiYoUKZIqRQEAAAAAkBE88vDyESNG6O2339Zvv/2mqlWrymKxaOvWrfrll1+SDeMAAAAAADyrHrmnu3nz5tq5c6dy5MihlStXavny5cqRI4f++OMPNWvWzIwaAQAAAABIlx65p1uSypcvr4ULF6Z2LQAAAAAAZCiP3NO9du1a/fTTT/cs/+mnn/Tjjz+mSlEAAAAAAGQEjxy6Bw4cqISEhHuWG4ahgQMHpkpRAAAAAABkBI8cuo8dO6YSJUrcs7xYsWI6fvx4qhQFAAAAAEBG8Mih28vLSydOnLhn+fHjx+Xh4ZEqRQEAAAAAkBE8cuh+7bXX1KtXL/3zzz/WZcePH9dHH32k1157LVWLAwAAAAAgPXvk0D127Fh5eHioWLFi8vPzk5+fn4oXL67s2bNr3LhxZtQIAAAAAEC69MiPDPPy8tLvv/+uDRs2aP/+/XJ3d1fp0qVVo0YNM+oDAAAAACDdeqzndFssFtWvX1/169dP7XoAAAAAAMgwUjy8fOfOnfc8hzs0NFR+fn7y8fHRBx98oJiYmFQvEAAAAACA9CrFoXv48OE6cOCA9f3BgwfVsWNHvfzyyxo4cKB++OEHBQcHm1IkAAAAAADpUYpD9759+1S3bl3r+8WLF6tSpUqaOXOm+vTpo8mTJ2vp0qWmFAkAAAAAQHqU4tB9/fp1+fr6Wt9v3rxZr7zyivV9xYoVdfbs2dStDgAAAACAdCzFodvX11cnT56UJMXGxmrPnj0KCAiwro+MjJSzs3PqVwgAAAAAQDqV4tD9yiuvaODAgdqyZYuCgoKUKVMmVa9e3br+wIED8vf3N6VIAAAAAADSoxQ/Muyzzz7TG2+8oZo1aypz5syaP3++XFxcrOvnzJnDI8QAAAAAALhDikN3zpw5tWXLFoWHhytz5sxydHS0Wf/tt98qc+bMqV4gAAAAAADpVYpDdxIvL69kl2fLlu2JiwEAAAAAICNJ8T3dAAAAAADg0RC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADCJXUN3cHCwKlasqCxZssjHx0evv/66jh49+sB9Nm3aJIvFcs/r77//TqOqAQAAAABIGbuG7s2bN6tr167asWOHNmzYoPj4eNWvX19RUVEP3ffo0aO6ePGi9VWkSJE0qBgAAAAAgJRzsueHr1u3zub93Llz5ePjoz///FM1atR44L4+Pj7y9vY2sToAAAAAAJ7MU3VPd3h4uCQpW7ZsD922XLlyyp07t+rWrauNGzfed7uYmBhFRETYvAAAAAAASAtPTeg2DEN9+vRRtWrV9MILL9x3u9y5cyskJETLli3T8uXLVbRoUdWtW1e//fZbstsHBwfLy8vL+sqXL59ZpwAAAAAAgA2LYRiGvYuQpK5du2rNmjXaunWr8ubN+0j7NmnSRBaLRatWrbpnXUxMjGJiYqzvIyIilC9fPoWHh8vT0/OJ6zaTxWLvCgA8jqejVU0blhE0VEB6ZAx7hhoqiYsqID1KBxdUERER8vLyemi2fCp6urt3765Vq1Zp48aNjxy4Jaly5co6duxYsutcXV3l6elp8wIAAAAAIC3YdSI1wzDUvXt3rVixQps2bZKfn99jHWfv3r3KnTt3KlcHAAAAAMCTsWvo7tq1q7755ht9//33ypIli8LCwiRJXl5ecnd3lyQFBQXp/PnzCg0NlSRNnDhRBQsWVMmSJRUbG6uFCxdq2bJlWrZsmd3OAwAAAACA5Ng1dE+bNk2SVKtWLZvlc+fO1XvvvSdJunjxos6cOWNdFxsbq759++r8+fNyd3dXyZIltWbNGjVq1CitygYAAAAAIEWemonU0kpKb3Z/GjDnB5A+PUutKhOpAekTE6kBeOqlgwuqdDWRGgAAAAAAGRGhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAk9g1dAcHB6tixYrKkiWLfHx89Prrr+vo0aMP3W/z5s0qX7683NzcVKhQIU2fPj0NqgUAAAAA4NHYNXRv3rxZXbt21Y4dO7RhwwbFx8erfv36ioqKuu8+J0+eVKNGjVS9enXt3btXgwYNUo8ePbRs2bI0rBwAAAAAgIezGIZh2LuIJP/++698fHy0efNm1ahRI9ltBgwYoFWrVunIkSPWZYGBgdq/f7+2b9/+0M+IiIiQl5eXwsPD5enpmWq1m8FisXcFAB7H09Oqms8ygoYKSI+MYc9QQyVxUQWkR+nggiql2fKpuqc7PDxckpQtW7b7brN9+3bVr1/fZlmDBg20e/duxcXFmVofAAAAAACPwsneBSQxDEN9+vRRtWrV9MILL9x3u7CwMPn6+tos8/X1VXx8vK5cuaLcuXPbrIuJiVFMTIz1fUREROoWDgAAAADAfTw1Pd3dunXTgQMHtGjRoodua7lriFDSCPm7l0u3J2vz8vKyvvLly5c6BQMAAAAA8BBPReju3r27Vq1apY0bNypv3rwP3DZXrlwKCwuzWXb58mU5OTkpe/bs92wfFBSk8PBw6+vs2bOpWjsAAAAAAPdj1+HlhmGoe/fuWrFihTZt2iQ/P7+H7hMQEKAffvjBZtn69etVoUIFOTs737O9q6urXF1dU61mAAAAAABSyq493V27dtXChQv1zTffKEuWLAoLC1NYWJhu3bpl3SYoKEht27a1vg8MDNTp06fVp08fHTlyRHPmzNHs2bPVt29fe5wCAAAAAAD3ZdfQPW3aNIWHh6tWrVrKnTu39bVkyRLrNhcvXtSZM2es7/38/LR27Vpt2rRJZcuW1aeffqrJkyerefPm9jgFAAAAAADu66l6Tnda4DndAMz2LLWqPKcbSJ94TjeAp146uKBKl8/pBgAAAAAgIyF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEruG7t9++01NmjRRnjx5ZLFYtHLlygduv2nTJlkslntef//9d9oUDAAAAADAI3Cy54dHRUWpTJkyat++vZo3b57i/Y4ePSpPT0/r+5w5c5pRHgAAAAAAT8Suobthw4Zq2LDhI+/n4+Mjb2/v1C8IAAAAAIBUlC7v6S5Xrpxy586tunXrauPGjfYuBwAAAACAZNm1p/tR5c6dWyEhISpfvrxiYmK0YMEC1a1bV5s2bVKNGjWS3ScmJkYxMTHW9xEREWlVLgAAAADgGZeuQnfRokVVtGhR6/uAgACdPXtW48aNu2/oDg4O1ogRI9KqRAAAAAAArNLl8PI7Va5cWceOHbvv+qCgIIWHh1tfZ8+eTcPqAAAAAADPsnTV052cvXv3Knfu3Pdd7+rqKldX1zSsCAAAAACA2+waum/evKnjx49b3588eVL79u1TtmzZlD9/fgUFBen8+fMKDQ2VJE2cOFEFCxZUyZIlFRsbq4ULF2rZsmVatmyZvU4BAAAAAID7smvo3r17t2rXrm1936dPH0lSu3btNG/ePF28eFFnzpyxro+NjVXfvn11/vx5ubu7q2TJklqzZo0aNWqU5rUDAAAAAPAwFsMwDHsXkZYiIiLk5eWl8PBweXp62rucB7JY7F0BgMfxLLWqlhE0VEB6ZAx7hhoqiYsqID1KBxdUKc2W6X4iNQAAAAAAnlaEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJHYN3b/99puaNGmiPHnyyGKxaOXKlQ/dZ/PmzSpfvrzc3NxUqFAhTZ8+3fxCAQAAAAB4DHYN3VFRUSpTpoymTJmSou1PnjypRo0aqXr16tq7d68GDRqkHj16aNmyZSZXCgAAAADAo3Oy54c3bNhQDRs2TPH206dPV/78+TVx4kRJUvHixbV7926NGzdOzZs3N6lKAAAAAAAej11D96Pavn276tevb7OsQYMGmj17tuLi4uTs7HzPPjExMYqJibG+Dw8PlyRFRESYWyyAZ9Yz1bxE27sAAI+D6yAAT7100E4ltaWGYTxwu3QVusPCwuTr62uzzNfXV/Hx8bpy5Ypy5859zz7BwcEaMWLEPcvz5ctnWp0Anm1eXvauAAAezOtzGioAT7l0dEEVGRkprwfUm65CtyRZLBab90m/Kty9PElQUJD69OljfZ+YmKhr164pe/bs990HMFNERITy5cuns2fPytPT097lAECyaKsAPO1op2BvhmEoMjJSefLkeeB26Sp058qVS2FhYTbLLl++LCcnJ2XPnj3ZfVxdXeXq6mqzzNvb26wSgRTz9PTkCwLAU4+2CsDTjnYK9vSgHu4k6eo53QEBAdqwYYPNsvXr16tChQrJ3s8NAAAAAIA92TV037x5U/v27dO+ffsk3X4k2L59+3TmzBlJt4eGt23b1rp9YGCgTp8+rT59+ujIkSOaM2eOZs+erb59+9qjfAAAAAAAHsiuw8t3796t2rVrW98n3Xvdrl07zZs3TxcvXrQGcEny8/PT2rVr1bt3b02dOlV58uTR5MmTeVwY0hVXV1cNGzbsntseAOBpQlsF4GlHO4X0wmI8bH5zAAAAAADwWNLVPd0AAAAAAKQnhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAACQbiQmJtq7BADPOB7+hEdF6AZgxZcIgKedg8PtS5fz588TwAHYhcVisXnP9RMehtANwCrpS2TUqFFat26dJL5IADwd7gzY8+bNU+XKlbVt2zaCNwC7mDJliho2bCjp3hAO3I3QDeAe+/fv19ixY3Xr1i2+SADYXWJiorWHe9WqVUpMTNT58+cVFBSknTt3ErwBpLmcOXPq2rVr+vvvv+1dCtIBQjeAe7Ro0ULXrl3TqVOnJHEPJQD7SgrcQUFB6tixo27duqWgoCBduXJFHTp0IHgDMFVyo/4qVaqkS5cu6fvvv7dDRUhvLAZjR4FnlmEY1p7sO3uSJKls2bIqXbq0QkND7VUeAFj973//U+3atfXVV1+padOmkqTIyEjVqFFDMTExmjVrlipVqiRHR0c7Vwogo4qNjZWLi4v1/YwZMzR27FitXbtWzz//vB0rw9OOnm7gGZYUuOfMmaNp06bpxo0b1nVDhw7VX3/9pb1799qpOgD4P4mJiUpISFCePHkk3b74zZIli9atW6dr164pKChIu3btsnOVADKSO0fQjBo1Su+9957mz59vXVanTh1lzpxZhw4dkiQlJCSkeY1IHwjdwDPozi+RhIQELV++XPPmzVOxYsU0ffp07d27V40aNVJkZKS2bNkiiQnVAKSd5Nobf39/OTs765tvvpEkubi4KCEhQZkzZ1bRokV14MABde7cWeHh4WldLoAM6MaNG9YRgAcPHlSNGjUUHx+v4cOHq2bNmpo7d678/f318ssva+jQoYqPj2ekDe6L0A08Y+4cRr5mzRodOXJEq1ev1oYNGxQYGKilS5eqSZMmmjRpkipWrKjx48frzJkzTKgGIE0kJiZa25szZ84oMjJSMTExcnZ21rBhw7R8+XKNHDlSkuTo6ChXV1cVLlxYmzZt0pUrVzRs2DB7lg8gA/jhhx/Up08fXb58WT169FCZMmVUtWpVzZs3T5s2bZKfn59mz54tPz8/SbK5t5tOCiTHyd4FAEg7hmFYA3f//v21YsUK9e7dW7ly5VKOHDk0fPhwnT59WgcOHNDw4cMVFxenM2fOaMeOHcqfP78SEhL4FReAqZLaqCFDhuiHH37QtWvX9P7776tly5Zq06aNLl68qEmTJmnXrl164YUXtHnzZt24cUOlS5dWlSpVdOnSJTufAYD0LiEhQatXr9aePXt07tw5HTx4UBaLRa6uripQoIDmzZunS5cuKTQ0VCtWrND169f13XffqXnz5nRSIFlMpAY8gyZNmqRRo0ZpxYoVqlChglxcXGwmVZNuD6s6efKkBg8erDNnzujgwYN2rBhARmYYhs2Pgt9884369OmjSZMmaceOHdqyZYuef/55DR8+XEWKFNG6des0evRoubu7K2vWrJo3b55cXFzUpEkT+fv7a+LEife0aQDwKFq3bq1FixapWbNmGj9+vPLnzy9Jio+Pl5PT//VbhoWFaevWrfrwww/1zTffqEGDBvYqGU8xQjfwDDEMQ3FxcWrevLleeuklDRkyxGZdcheo//zzjxo3bqxp06apVq1aaVgtgGfRtm3btHTpUlWsWFGtW7eWdDuET5s2Tc8995wGDRqk0qVL2+wTHx+voKAghYaGWgM6ADyKpOugpFA9YcIEOTg4aPz48apfv7569+6tEiVK3LO9JF2/fl3NmjXT22+/rc6dO9vrFPAU455u4BmS9OVw7tw566+0STNtWiwWxcbG6s8//7TZJ2fOnLp165bNzOYAkBoCAwO1atUq6/vt27erbdu2WrBggWJjY63LW7VqpS5duuj8+fMaPXq0tm/fbl136NAhDR48WN99953WrVtH4AbwyO6cSyI8PFwJCQnq0aOHevbsqS+++ELr1q3ThAkT9Pfff1v3+fnnn63/nDVrVsXFxVlHBdKnibsRuoEMLLlG38XFRb6+vlqzZo0k2dyjffr0aS1YsED/+9//rMs2bNigM2fOqGTJkuYXDOCZcfLkSWXLlk0NGza0LgsICFCvXr3k6emp77//Xv/88491XcuWLdW1a1ft2bNH69atsy4vUaKEmjZtqq1bt6pcuXJpeg4A0jfDMGwmmB0zZoxatGihgIAAvfzyyzp58qTefPNNTZkyRRs2bNDo0aO1YsUKNW7cWO3atbNeZ23atEnnz5+39nJzawvuxvByIIO680skLi5OCQkJcnNzkyT9+eefql+/vurVq6fFixcrOjpa8fHxatGihRISErRu3Trrvr///rt8fHxUuHBhu50LgIxt3rx5ioqKUteuXSXdnndi7ty5qlWrlnr27GmdIVi63btUu3ZtOTo62rRzAPAoYmJi5Orqan0/ePBghYSE6IsvvlDBggXVpk0beXh4aPPmzcqRI4dWr15tnWTW29tbP//8s5ydnSXdvq/bMAzlzp3bXqeDpxyzlwMZ0J0XouPGjdOOHTv0119/qWfPnqpbt67Kly+vWbNmqXPnzipatKiyZs2qxMRExcbGateuXXJwcLDOVF6lShU7nw2AjOzKlStasWKFwsLClClTJrVv3149e/ZUXFyc9ZncvXr1UsGCBSVJL7/8siTxNAUAj+2dd97Rq6++qjZt2kiSzp49qw0bNmjBggVq0KCBVq9erfDwcA0YMEA5cuSQYRhq3LixSpUqpbi4OBUqVEgODg7W+79z5cpl5zPC046ebiADGzRokGbNmqV+/fopOjpac+fOVc2aNfXRRx/phRde0L///qvp06fLMAxlzZpVnTt3lpOT0z0zcwJAakmud3r//v0aP368jh8/rg4dOqhjx46SpC+++EKLFy9WyZIlFRwcTC8SgCf23nvvaevWrTp+/Lh12aFDh/Tyyy/rwoUL+umnn/TWW29p3Lhx+vDDD3Xz5k3NmTNHgYGBcnFxse7DSBs8Cq6qgQxq+fLlWrJkidasWaOKFStq586dGjZsmCwWi6KjozVgwACVLVvWZgZz6XbvEYEbgBnuvEj9559/lClTJmXNmlVlypRR79699cUXX2jOnDmSpI4dO+qjjz5SZGSkTp8+LV9fX3uWDiADuHnzpq5fv67AwEBJ0qxZs1SrVi0999xzKlWqlPr27auZM2dq/Pjxev/99yXd7gVfu3atypQpo5o1a1qPReDGo+DKGsgg7ryYjYmJUbZs2dS5c2dVrFhRP/zwg9q2bat58+bJzc1Nbdq0kbOzsz788ENVrVrV5jgM1wRglqQ2avDgwVqwYIE8PDxUsGBBff311ypbtqw++ugjffHFF5o7d64cHBzUvn17DR8+3PpoHnqWADyJzJkzy9PTUxMnTtT+/fv19ddf6/Tp03Jzc1OOHDk0efJkde7c2Rq4b926pb59+8rR0VHVq1e3c/VIzxheDmQwgwYNUpEiRfTKK6/IyclJjo6Oatq0qV577TX169dPCQkJKl68uMLDw9WjRw99/PHH9i4ZQAZ3Z1j+4Ycf9P7772vatGk6deqUli1bpnPnzmnPnj3Kli2b9u3bpwkTJmjHjh364osv1LhxY0m2z8QFgEd1Zzvk4+OjmzdvKiQkRK1bt5YkXbhwQW+++aYSEhJUsmRJFSxYUL/88ouuX7+uP//8U87Ozvzwh8dGTzeQzt35BfDLL79oypQp+vnnn633Pp46dUphYWHWZ9eGhYWpevXqqlOnjlq2bGm3ugE8O5LaqAULFujWrVv69NNP1axZM0lS3bp19eGHH+rFF1/Unj17VLZsWXXt2lX+/v42jxMjcAN4Eg4ODjIMQ7t375aTk5NKlCihoUOHyt/fXxUrVlSePHn07bffaubMmdq8ebNu3Lih8uXLa8yYMcx3gydGTzeQQYSEhCghIUE3b95Uv379rMuPHDmit99+Ww0aNFBAQIBmz56t+Ph4rVu3ThaLhRmAAaSJU6dOqX79+jp+/LgmTpyoHj16WNcdPHhQgYGBunjxonbs2CEfHx/rOtooAE/i7lEyUVFRMgxDmTNnVu3atXXy5EktWbJE5cuXv2+oph3CkyJ0A+nUnV8i169fV82aNXXo0CF17txZU6dOtVk/efJkhYSEKCYmRnny5LE+W5LhmgDMcnf7EhcXp59//llDhw5VdHS0/vzzT5uZgA8dOqRmzZqpVKlSWr58Oe0TgCd252jAM2fOKFOmTHJycpK3t7d1/csvv6wTJ05oyZIleumll2h3YApCN5DOJf36evToUfXp00f79+/Xli1b5Ofnp7i4ODk7O0uSTp8+LYvForx589o8WxIAUtvd9z1GR0fLzc1NCQkJ+u2339S1a1d5e3tr06ZNNsH7xIkTKlCgAD1KAJ7Yne3QyJEjtXz5ct26dUuenp6aMWOGypQpY92uXr16On36tObOncuEaTAFoRtIx4KDg3X58mWNGjVK7u7uOn78uNq0aaMrV65o27Zt8vHxsQneSZgIBIBZ7mxfJk6cqJ07d+rEiRN688039cYbb8jf31+bNm1Sjx49lCVLFm3cuNEmeEsM5QSQeoYMGaKQkBBNnTpVPj4+Gjx4sP766y+tWrXK+gSXxMRElS1bVs8//7y+++47O1eMjIirbiAdy5EjhyZNmqTg4GDdunVLhQsX1oIFC5Q9e3ZVq1ZNly9ftg4jvxOBG4BZktqXgQMH6rPPPlPu3LlVsWJFjR07VgMGDND27dtVq1YtTZgwQdHR0XrhhRcUHx9vcwwCN4DUsGXLFq1fv17ffvut3nzzTYWHh+vgwYPKnz+/6tevr99//13S7XZr//79WrJkiZ0rRkbFlTeQTiQmJt6z7P3331doaKg+++wzjRw50hq8Fy5cqJw5c6pw4cK6fv069ycBSFP79u3T0qVLtXz5co0fP15TpkzRihUrdPbsWU2ePFk3b95UjRo1NGLECFWpUoU2CkCquLuTIXPmzGrcuLFq1Kih9evXq1OnTho5cqRWr16t/Pnz6/XXX9evv/4q6fYTEhwdHZWQkGCP0pHBEbqBdCKp92jfvn02y1u3bq358+dr1KhRGjVqlP777z8VLlxYs2fP1jvvvCNPT087VAvgWebg4KDY2FhlypRJ0u0fDatWrapx48Zp+fLl2rJli5ydndWoUSPNmzePC10ATywxMdH6A97x48clSeXKlVOXLl0kSTNmzFDbtm3VpUsX5cqVS88//7wcHR316aef2hyHkTYwA6EbSEe2bt2qF198UdOnT7dZ3qZNG02bNk3BwcGaMmWKIiMjVaxYMYWEhHAxC8BUd47CSeplMgxDkZGROnPmjCQpPj5ehmGoevXqKlasmI4cOSLJ9lYXLnQBPK4755L49NNP1b9/f61bt06SlD17dl27dk0HDx5U8eLFJUm3bt2Ss7OzvvvuO2tPN2Ampi4GnmJ3fokYhqFq1app6NCh6tWrlxwcHPTBBx9Yt3355Zfl7e2tgQMHytvb22YdF7MAzHBnGxUSEqLw8HD16tVLZcqUUadOndS2bVvly5dPFStWlCRFRkYqPj5e2bJls2fZADKYpHZowIABmjNnjubNm2ednVySsmXLpjJlymjgwIEKDw/XsmXLFBcXp8qVK8tisTDBLExH6AaeUnd+AcyYMUPXrl1Tv379NHz4cLm4uFiHSyWFazc3N33wwQeqUqWKXnnlFbvVDeDZkdRG9evXT4sWLdLAgQN14cIFFShQQL169dL58+dVpUoVDRo0SO7u7tq0aZMcHR3VunVrO1cOIKP55Zdf9O233+qnn37Siy++qNjYWF26dEm7du1SgwYNNGHCBPXr109LlixR3rx5tWjRIjk6OhK4kSYI3cBT6u6L2T59+ujcuXMqWLCgBg0aJMMwFBgYqGPHjql06dJaunSp4uLiNGrUKEniOdwA0sSMGTMUGhqq1atXW3u0JSlv3ryaN2+eKlSooMWLF8vDw0N58+bVDz/8ICcnJx4LBiBVxcfHy2KxKF++fDp69KgWLFigb775RpGRkcqbN6/27t2rRYsW6fr16/L29pbFYuFaCWmG53QDT7ElS5aoV69eWrFihSpXrnzP+tmzZ+uzzz6Th4eHcubMqfXr11sfEcZswADMZhiGPvjgA2XKlEmTJk3S33//re3bt2v69OkyDEPjxo1TjRo1FB4erixZslh/TORCF0Bq27lzp3r16qWYmBidO3dOr732mipVqqSAgABVrVpVs2fP1ptvvmndnmslpCW+8YCn2KFDhxQQEKDKlStbvxzuHAbVsWNHNWjQQC4uLsqRI4ccHBy4mAWQZiwWi3Lnzq25c+fKx8dHP/zwg3x9fVW7dm0dOXJE7777rv73v//Jy8vLuo9hGLRRAFJdpUqVNGLECB08eFBFihRR9erVlTVrVl26dElFihRRjhw5bLYncCMt8a0HPCWSu6coMjJSV69eVVxcnJydnSXdHnYeFxentWvXqlGjRsqbN6/NMbiYBWCG+9332LRpU924cUNz5sxRYGCgXnnlFZUqVUpr1qzR+PHjFRsbK3d3d+v2XOgCSG1J7VP9+vVVv359SVJcXJzCwsL0/vvvy8XFRdWrV7dzlXiWcXUOPAXuvJjdtm2bihQpIh8fHxUrVkyhoaHatm2batasab1YjYqKUkhIiOLj49W8eXPrcZgIBIAZ7myjFi1apAsXLigyMlJdu3ZV+fLlVb58eX3yySfy9vaWdLs3+8svv5S3t7c8PT3tWDmAZ8Hd1z8xMTEKDQ3Vd999p+vXr2vbtm3WR6gylwTsgSt0wM4Mw7B+WQwaNEjvvfeeNmzYoISEBAUGBqpq1apq2bKlVqxYob///lvHjh1Ty5YtdfXqVb3++uv2LR7AMyGpjRo4cKB69eql3377TaGhoXr11Ve1cuVKxcbGytvbW5GRkfrhhx/08ssv6+LFi1q8eLEsFouYPgZAaomPj3/oNq6urvLx8dGrr76q33//Xc7OzoqPjydww26YSA14SgQHB2vixIn67rvvVLJkSZvn2LZq1Urbt2/XlStXVLhwYbm5uem3336Ts7Mzv9oCSBNTpkzRmDFj9P3336tcuXJau3atGjdurBdffFFBQUFq2rSpjh07pvnz5yssLEyzZs2Sk5MT80wAeCLbt29X7ty5VbBgQQ0ZMkQVKlRQ06ZN77t9chOk0Q7B3gjdwFMgMjJSjRs3VosWLdStWzfr8ju/JPbt26dLly4pU6ZMqlq1KpOmAUgzN2/e1JgxY/Tcc8/pww8/1LJly9SpUyd98sknWrJkiS5duqSxY8da7+9OehwPPwoCeBInTpxQq1at5Ofnp8yZM2v27Nk6cOCAXnjhhQfud2fbc+nSJfn6+qZFucB9EbqBp8CFCxf0wgsvaO7cuWratKnN/ZO3bt3SzZs3lTNnTpt97jepEQA8qbt7igzD0K5du1SgQAFdv35dzZo1U2BgoHr27Klt27apTp06yp8/v2bOnKlatWolewwAeBzffPON+vbtq2vXrmn58uVq1KjRA3/Qu7PtCQkJ0dKlS/Xtt98qa9asaVk2YIMrdsCOkn7zypMnj0qUKKEVK1YoJibG2ostSbt379asWbN08+ZNm30J3ADMkJiYaBOWo6OjZbFY9NJLL8nX11f79u1TlixZrJM4Xr9+Xe+++64aN25sMzswgRvAk0hMTJQk5c2bV97e3ipRooQWLVqk48ePy9HR0br+7n2S2p4ZM2aoT58+6tKlC4EbdsdVO5CG7v6CSArdCQkJeuWVV3To0CFNmjRJkuTk5KSYmBiNHj1a27dvl4eHR5rXC+DZcucImkmTJundd99V9erVNXbsWB0/flySdO3aNV2/fl1nz57V5cuXFRISogIFCmjChAnW2YEB4HElXSsltUVly5bVzp071bNnT50+fVqDBw/WP//8Y9P5EBcXZ7PPjBkz1L9/f4WGhuqNN95I4zMA7sXwciCN3HkxGxISoj/++EORkZF666231Lx5c0VFRWnAgAHatm2bnJycVLx4cR05ckTR0dHas2ePnJ2dGa4JIE0EBQUpNDRUnTt3Vp48edSpUye1b99eU6dOVUxMjCpXrqwbN27IyclJ2bNn165du+Ts7GzvsgGkc3deK/34449KTExU5syZVbNmTUm3w/TXX3+t/Pnza8SIEfL391ebNm3UqlUrNWzY0LrNgAEDNHv2bJvHqgL2ROgG0tjAgQO1cOFCNWzYUJkzZ9akSZM0fvx49erVS9HR0frpp5+0du1axcTEKH/+/Bo6dCgzAANIM3/88Ydat26t+fPnKyAgQH/++acqVaqkOXPmqG3btpKkiIgIrV27Vg4ODmrevLkcHR1powA8kTs7Fvr27au5c+cqc+bMSkxM1HvvvadPP/1U0u2Oi0WLFuny5cvKmjWrTp48qVOnTsnZ2VlLlixR69attXjxYgI3nip8OwJpaOHChVq8eLFWrFihihUr6qefftKkSZPUp08fXb9+XSNGjFDTpk3veRRGQkICF7MATHH3pIwxMTHKli2bAgIC9O2336pDhw6aMmWK2rZtq4iICO3evVt16tTRO++8Y92HNgrAk0oK3GfOnNHGjRv166+/ymKxaMuWLerdu7du3bqlcePG6YMPPlCePHm0b98+Xb16VZs2bZKTk5Nu3bqliIgIrVmzRvXr17fz2QC2+IYE0khsbKwiIiI0cOBAVaxYUWvWrFGrVq00c+ZM3bp1Sz179lS2bNkUGBgoV1dXm3155A4AsyQF7qCgINWsWVPe3t66ePGipk6dqo8//lhjxoxRYGCgpNu94BMmTFD+/PlVuHBh6zFoowCkhi+++EK7du1SpUqVVKpUKTk4OKhw4cJycXFR165dZbFYNHbsWDVu3FiNGze27hcfHy93d3d16NCB9ghPJUI3kEZcXFzUpEkTxcfH6/z58/r44481fPhwdezYUfv375ebm5t69+6tLFmyqEOHDvYuF0AGd+dQzuXLl2vmzJmqV6+eihcvrgoVKqhXr14aMGCAOnfuLOn2LOaTJ0+Wh4eHChUqZM/SAWRAUVFRunr1qn788UdVrFjR+oNgpkyZ9O6778pisah79+6KjIzU9OnTbfZNGmlD4MbTitANpKF8+fJJknbt2qXExETrpB/u7u7q1KmT6tevrwYNGtizRADPiKTAvXbtWm3evFkjRoxQnTp1JEmtW7fWlStX9OOPP6pIkSL677//tHLlSl24cEF79+6Vg4PDPcPSAeBR3N2GeHh4qGvXrsqUKZOGDh2qCRMmqHfv3pJuB+9WrVopKipKy5cvZ2JZpDuEbsAOEhMTdejQIW3fvl2xsbEaNGiQHBwc9Oqrr0oSExIBSBN79uzRkCFD9M8//2jkyJHW5c2aNZO7u7tWrFihjz76SKVLl1b+/Pm1evVqJnYE8MTuDNyHDx/W1atX9fzzz8vHx0f9+/dXXFychg4dKgcHB/Xs2VPS7eAdGBioHj16yGKxELyRrjB7OZBK/vvvP2XKlCnFXwLDhw/XJ598okKFCsnLy0s7duzgsWAA0tysWbM0fvx4ubu767vvvpOfn5/N+itXrihHjhzW9wRuAE/izuucQYMGacWKFYqMjJSvr6/KlSunTz75RO7u7vryyy81fvx4ffrpp+revft9jwGkB4RuIBX069dPDg4OGjRokLy8vFL8ZXDgwAFFR0erQoUKcnBw4GIWQJq5s6dp7ty5CgkJUaFChTRq1CgVKFBAiYmJ1t6kpO240AWQWiZMmKDPP/9cixcvVu3atdW+fXutWrVK33//vapVq6bLly9rxowZGjZsmJYsWaIWLVrYu2TgsXF1D6SCa9eu6eDBg/L09FS3bt1SHLxLly5t/WcCNwAz3K8tuvO+7Pbt2ysuLk4LFy7Uxx9/rFGjRil//vw2gVsSgRvAYzl8+LBKlCgh6XabFB8fr99++02DBw9W7dq1tXbtWi1btkzjxo1TtWrVFBMTo6xZs6pz587KmzevmjVrZuczAJ4MM6AATyBpoMjs2bNVvXp1rVixQl9++aXCw8OtPUT3k5iYaPOewA3ADBaL5Z72JklS8JakDz74QK1bt9a5c+cUGBioS5cuEbIBPLFOnTppwYIF1vdJ10fXrl1T1apVtWHDBr399tsaO3asPvjgA8XGxmrBggXatm2bcuTIofbt21vnkgDSK0I38AQsFosSEhIk3X62ZI0aNbRy5cqHBu87e4++/PJLffPNN2laN4CMr3v37ho2bJgk23B9t7uDd9OmTVWwYEHlzJkzzWoFkHG9++67+uSTTyRJFy5ckHT7Mapubm5q2bKl3nzzTU2ePFkffvihpNujBxctWqT//e9/NsehcwLpGaEbeExJYfrOZ0KOHz9e1apVe2DwvnOo58yZM9WnTx+eKwkgVV25ckWJiYn69ttvNW7cOEkpD969e/fW1KlTH7g9AKSEYRiqXbu2nJ2dNXv2bH3wwQfatm2bpNvXTC4uLsqfP7/at2+v6OhoXb9+XR06dFBMTIw6duxo5+qB1MNPRsBjuHMCooiICFksFnl4eMjBwUETJ05Ur169tHLlSkm3e5uS7vGW/u+eyBkzZqh///5aunQp9yoBSFU5cuTQgAED5OXlpVmzZskwDOuEj/d7vvadkzkmjeLhB0EATyLpmic6OlrPPfecLly4oOnTp8vFxUUVK1bUsGHD1K1bNxUpUkTZs2eXg4ODoqOjtXPnTjk6OtIOIcNg9nLgEd15wRocHKzffvtNhw4dUocOHVS/fn1VrVpVktSrVy9t27ZNzZo1U+fOnZU1a1brMUJCQtSvXz/NmTNHzZs3t8t5AMj4zpw5o2nTpmnFihXq2LGj+vXrJ0nJBu87R+EsXrxYOXPmVJ06dbivG8Aj+/7771W8eHE9//zzGjBggKKiojRlyhStWrVKn332mfz9/dW/f3+VK1dO//77r6ZPny5XV1f5+vqqdevWcnR0ZIJZZCiEbuAxDR48WDNmzNDo0aMVHR2tuXPnytvbW/3791e9evUkSX369NGyZcv0ySefqF27dpKkyZMn6+OPP9b8+fP1xhtv2PMUAGQwScH5zlB98uRJhYSEPDB43xm4Q0JCFBgYqB9//FENGjSwz4kASLeioqLUrFkzbd++XW+++aaWLl2qbdu2qWzZspJuB/KRI0fK399fPXv2VOXKle85Bj3cyGj4+Qh4DKtXr9Z3332nNWvW6KWXXtKWLVu0b98+vfDCCxo1apScnZ1Vq1YtjR8/XgUKFFDr1q0lSeHh4dq1a5dmzpxJ4AaQqu4M0VFRUXJ3d5fFYpGfn586deok6faTFiTZDDW3WCw2t70MGDBA3333HYEbwGPx8PDQypUr5e/vr0WLFmnJkiUqW7asYmNj5eLioqZNm8pisWjkyJGaMmWKYmJiVLNmTZtjELiR0RC6gRS4+zm3uXLlUsuWLfXSSy9pzZo1ateunWbMmKH8+fPrrbfe0ogRIxQREaHXXntNPXv2lHT7gtjLy0vTpk1T5syZ7XUqADKgOwP3hAkTtGHDBsXExKhUqVLWHqWk4D1nzhw5ODjoo48+shlinjTPxJw5c/hREMATuXnzpvLnz6+CBQvqgw8+UJEiRVSiRAnFxcXJ2dlZr732miSpR48e8vf3vyd0AxkNw8uBh7jzYvbcuXPKkSOH3NzcdO3aNbm6uqpp06aqU6eOBg0aJEmqXLmyrly5otdee03jx4+/J7ADgFmCgoI0Z84cBQUFKTY2VqGhofL19dX333+vzJkz659//tGcOXM0bdo0TZ06VS1btpQkTZw4UZ999plmzJjBPBMAHlly80RER0crKipKbdq00e7du7V582YVL17cut4wDO3fv1+lSpWiZxsZHo8MAx7gzi+RESNGqF+/fvrtt9+UmJiobNmyKSoqSidOnNBzzz0nSfr333/l7++vTz/91PqYHgI3gLSwfPlyrVq1SqtWrVKvXr1UtGhRnTp1SkeOHFGtWrV08+ZN+fv7q23btho1apTeeustSVJkZKSmTp2qyZMnE7gBPLI7r5V2796t3bt3a8+ePXJzc1P27NkVEhKiChUqqE6dOtq/f79iY2P19ttva9CgQSpbtqx1lnIgI6OnG0iBQYMGaebMmZoxY4aqVasmHx8fSdKFCxf03nvvKUeOHKpbt66+++473bp1S7/++usDH80DAE/q7lE0y5Yt0+7duxUcHKzVq1frvffe0/Dhw1WgQAG1bNlSlSpV0ooVK+Tp6WndJ2mo53///adMmTLZ4zQApGN3tkNDhgzRokWLZLFYdPnyZQ0bNkw9e/aUo6Ojzp8/ry5dumj16tUqW7asIiIidPjwYTk7O9v5DIC0QegGHuLPP/9Uy5YtFRISolq1at2z/uuvv9bs2bN1/vx5FShQQGvWrJGzszOBG4Bp7mxfzp8/bx1tc/78eXl7e+uVV15RgwYNNHjwYF29elW1atXS4cOH1bp1a82fP5/bXgCkqk8//VRTp07V0qVLVb58eQUFBWnKlCn6+OOPNXz4cOvw8fnz5ys6OlodO3aUk5MTjwXDM4P/yoE79O3bV61atdKLL75oXfbff//p1q1byps37z3bJyYm6t1331XTpk0VFRWlnDlzysHBgS8RAKa5M3AHBwfrr7/+UseOHVW7dm0999xzOnr0qE6dOqWXX35Z0u37KkuWLKnJkydbJysicANILX///bd27typ2bNnq0aNGvr++++1YMECtW3bVsHBwbJYLAoKCpK7u7v18anS7ceCca2EZwX/pQP/36lTp3TixAmVLl3aZnlkZKQuXbqkxMRESf83HFOSNm7cqJiYGNWrV886I3liYiJfIgBMkxS4g4KCNGvWLM2cOVP+/v7W9T4+PsqePbtGjx6t3r1767PPPpODg4Nq1qwpBwcHnn8L4IncPZIve/bsatKkiWrWrKmtW7eqW7du+uyzz9S1a1c5ODjos88+U2RkpMaMGWMznJx2CM8ShpcDkm7cuCFvb2/rF8nixYuVM2dO1a1bV4ZhqE6dOoqKitKqVauUK1cuSbd7j1577TVVrlxZn3zyiZ3PAMCzZPv27WrXrp1mzpx5z6N24uPjtXjxYo0ePVpRUVHKnz+/NmzYwG0vAJ7YnW3I8ePH5e7urhw5csjV1VWS1LNnT12/fl0hISFyc3PTwIEDtWvXLsXHx2vTpk2MssEzi29ePPP69eunYcOG6cqVK3JwcNC///6r3r17a8yYMdq6dat1WJSbm5uqV6+uRYsWadq0aWratKkuXbqkoUOH2vsUAGRg/fr10+HDh22WXb58WdHR0fLz87tneycnJ7Vu3Vo7d+7UmjVr9Ouvv8rZ2Vnx8fEEbgCPzTAMaxsycOBAvfrqqypbtqwaNGigqVOnSpIOHTqkxMREubm5KS4uTn///bc++ugjbd68WRaLRfT14VnFGFg88/777z/t3LlTX375pbp06SJfX1/9/PPPatWqlUaOHKkRI0aofv368vX11bhx4zRgwADlzp1bfn5+Wr16tZycnBiuCcAUmzdvVkREhJ5//nmb5dHR0TYXsImJibJYLLJYLFq2bJk8PT1Vr1496zNxue0FwJO4s4d78eLFCg0N1bRp03Tjxg399ddf6tWrl1xcXNS/f381bNhQEREROn36tAzDUP369SXd+8QF4FnC8HI8s+5s/AcPHqxff/1VderUUffu3eXr66vDhw+rRYsWypcvn4YNG6aAgABJ0sWLF5U1a1a5urrKYrEwaRoAUyW1VUuWLFGBAgVUuXJlXb9+XUWLFlW9evX09ddfW7f977//9M477yggIEBBQUF2rBpARrRp0yZ9/fXXKlGihHr37i3p9tw38+bN08CBAzVnzhw5Ojpq5cqV8vX11ejRo+mcAEToxjPszl9t//rrLw0aNEhHjhxRq1at1KVLF/n4+FiDd8GCBdW/f/977p3kV1sAZrmzfTl69Khat26tHDlyaMSIEXrppZe0bt06tWzZUlWqVFGbNm3k7OysGTNm6OLFi9q7dy8/BgJIVWFhYapWrZouX76sAQMG6OOPP7auu3btmjp27Kh8+fJp8uTJio2NlYuLiyTROQGI0A2oZ8+e2r17t7Jnz65jx47p0qVL6tatm7p06aJcuXLp8OHDeuedd5QpUybNmDFDZcqUsXfJADK45H7QW7JkiebOnStnZ2eNGDFCL774og4cOKCOHTsqIiJCbm5uKlSokJYuXSpnZ2d6lgCkugMHDuiNN96Ql5eXZs2apXLlylnXderUSefOndO6devsWCHwdCJ045n2/fffq0OHDvr5559VokQJubq6qkePHvr111/VvHlzdevWTTlz5tT+/fs1duxYhYaGMhERAFPdOQrnxo0bcnR0VJYsWSTdDt6zZs2Sm5ubhg4dqooVKyomJkbXrl2TxWKRr68vt70AMNWBAwfUtm1blS1bVr169VLZsmUVGRmphg0bqnjx4po5c6a9SwSeOoRuPNMWLFigYcOGaceOHfLx8bEu79Spk5YuXaqPPvpInTp10nPPPWddxyN3AKSFTz/9VCtWrJCnp6eqVq2qkSNHSpKWLl2qmTNnys3NTUOGDNFLL71ksx9tFACz7d27V61bt9bVq1dVsWJFubi46OTJk9qxY4dcXFy4/Q64C9/KeGbc+ftSQkKCpNuP1omPj1dUVJQkKTY2VpI0fPhwubi4aM6cOVqzZo3N/lzMAjBDYmKi9Z+nT5+uyZMnq1WrVipZsqTmzJmjd955R5L01ltv6f3331dcXJx69eqlo0eP2hyHNgqA2cqVK6clS5YoU6ZMCg8PV7169bRnzx65uLgoLi6OwA3chZ5uPBPu7vmJi4uzPre2ZMmSKlCggNasWSNnZ2dJt4dOff7553rxxRfVu3dv7osEYKo726hff/1VJ0+eVI4cOdS0aVNFR0frxx9/VPv27dWgQQMtWbJEkjR//nzt3btX48ePJ2gDsIt9+/YpMDBQpUuXVv/+/VW4cGF7lwQ8lQjdyPDuvJidOnWqfv/9d126dEm1a9dWUFCQDh48qNdee0358uVT79695e3trbFjxypHjhxauHChJDEhEQBTNG/eXNOmTbPe3rJnzx5VrlxZTk5O+vbbb/Xqq69Kuj0KZ82aNerYsaMaNGigRYsW2RyHIeUA7GXv3r0KDAxUoUKFNGzYMBUrVszeJQFPHb6hkeElXYgOHDhQo0aNUqFChdSyZUsNGTJE3bt3l7+/vzZt2iQHBwcNGDBAHTp0UFRUlObOnSvp9rByAjeA1HbhwgV5enrK29vbuixv3ryaMGGCPDw8tHr1autyFxcXvfrqq5o7d66WLFmioUOH2hyLwA3AXsqVK6cpU6bo4sWL8vLysnc5wFOJnm48E/744w+9++67mjt3rqpVq6atW7eqTp06mj59ujp06GDd7uTJk4qPj5e/v78cHByYARhAmvjyyy/12muvqUCBArp69aoWL16sQYMG6YMPPtDYsWOt28XGxmrnzp0KCAigbQLwVImOjpabm5u9ywCeSvw0jmfCjRs3lDNnTlWrVk3Lli1Tw4YN9eWXX6pDhw66ceOGNm7cKEny8/NTkSJF5ODgoMTERC5qAaS6N998UwMHDrROzhgeHq6QkBBVqVJF586dU/bs2fXOO+8oODhYc+fOVf/+/a37uri4qHr16tZJIAHgaUHgBu6P0I0M584ZgJM4OzsrMjJSEydOVIcOHTR27Fh9+OGHkqTdu3dr5MiROnHihM0+DNcEYIZq1arpiy++0Oeffy5J8vLy0vfff6/nn39eVatWtQbvt99+W5988onmz59vba/uxI+CAACkD3xjI0O5czKhdevWKTw8XKVKldILL7ygggULKigoSL1791ZgYKAkKSYmRl9++aVy5MihggUL2rFyAM+CxMRE9erVSx4eHgoMDFR8fLyGDBmiQoUKac6cOWrXrp2qVq2qbdu2KW/evHr77bcVFRWljRs38txbAADSKe7pRoYUFBSkyZMn67nnntOpU6cUEhKi2NhYhYSEKGfOnGrRooUcHBz0zTffKCwsTHv27JGTkxMzAAMwzZ1PQbh165ZWrlyp1q1ba8SIERo8eLCk2/NKtGvXTmfOnNHWrVuVN29eRUREKEuWLLJYLARvAADSIdIFMoSk344Mw9CpU6e0detW/fzzz9qxY4c+++wzvf/++4qPj1dgYKDy5s2rjz76SPPnz5ePj4/+/PNPOTk5KSEhgcANwBSJiYnWwP3FF1/oo48+UoUKFTRr1iwNGzZMn332maTb80rMnz9ffn5+Kly4sP799195enoSuAEASMcYXo50787e6evXrysuLk7VqlXTSy+9JEdHR/Xv31/Ozs7q2bOnxo4dqwkTJmjMmDHy9PS0XgQzSzkAMyW1UQMGDNCcOXM0efJkOTk5qX379tYfBCVp8ODB8vPzU0hIiCZMmKBs2bJZj0HgBgAgfSJlIN1Lupj9+OOPtWHDBh09elQFCxbUe++9p6JFi0qSevfuLYvFon79+unSpUv6+OOPrYHbMAwCNwDT/fzzz/r222+1cuVKVa1a1br8/fffl2EY6tKliywWiz7++GMVKVJEX331lSTbYekAACD9YSwt0q07ZylfvHix5s6dqzZt2qhDhw46fvy4Zs2apdOnT1u36dWrl0aMGKHffvtNHh4e1uX0HgFIC2fOnFGmTJlUsmRJ67KkW2M++OADhYaGasiQIZo3b57NfgRuAADSN7r3kG4l9XBv3rxZW7Zs0eeff662bdtKkooUKaLg4GA5Ojqqc+fOKlCggCRp0KBBCgoK4v5IAGkmqa2Jjo5WQkKCzfKk/122bJlefPFFrVu3TnXq1LFXqQAAwAT0dCNdCwsLU8eOHRUaGqrr169bl3fp0kUDBw7U119/rZCQEJtncBO4AaSlpLamdu3aOnbsmCZOnGhdbrFYFBUVpQULFujnn39W/fr15eTkpPj4eDtWDAAAUhM93UjXcuXKpeXLl6tFixZas2aN6tSpo1KlSkmSunbtKgcHB3Xv3l358uWzTlQkMaQcQNorXry4vvrqK3Xr1k3Xr19X48aN5eLiolGjRiksLMymjWKeCQAAMg6e040MYf/+/Wrfvr0qVKignj172twzuXz5cjVt2pT7IgHYnWEYWrVqlXr06KGEhAR5e3vrueee0+rVq+Xs7MykaQAAZECEbmQYe/fuVadOnVS+fHn16tVLJUqUsFnPxSyAp8WVK1cUHh6uxMRE+fv7y8HBgUcXAgCQQRG6kaHs3btXH374oQoUKKAxY8bIz8/P3iUBwEMlJiZaJ4cEAAAZC9/wyFDKlSunKVOmKEuWLNYZywHgaUfgBgAg46KnGxlS0uzk9B4BAAAAsCdCNzIsHgsGAAAAwN7oAkSGReAGAAAAYG+EbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABM8v8AOyCbG9avztYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from botocore.config import Config\n",
    "\n",
    "with mlflow.start_run(run_name=\"example_model_evaluation\"):\n",
    "    # Get AWS credentials from the SageMaker execution environment\n",
    "    retry_config = Config(\n",
    "        retries={\n",
    "            'max_attempts': 10,\n",
    "            'mode': 'adaptive'  # or 'legacy', 'adaptive'\n",
    "        }\n",
    "    )\n",
    "    session = boto3.Session()\n",
    "    credentials = session.get_credentials()\n",
    "    \n",
    "    # Set as environment variables\n",
    "    os.environ['AWS_ACCESS_KEY_ID'] = credentials.access_key\n",
    "    os.environ['AWS_SECRET_ACCESS_KEY'] = credentials.secret_key\n",
    "    if credentials.token:\n",
    "        os.environ['AWS_SESSION_TOKEN'] = credentials.token\n",
    "    \n",
    "    # Set region - important for Bedrock\n",
    "    region = boto3.session.Session().region_name\n",
    "    os.environ['AWS_REGION'] = region\n",
    "\n",
    "    mlflow.set_tag(\"component\", \"qualitative_model_evaluation\")\n",
    "    \n",
    "    # Initialize the SageMaker client\n",
    "    sm_client = boto3.client('sagemaker-runtime', config=retry_config)\n",
    "    \n",
    "    # Define the model to evaluate\n",
    "    model_to_evaluate = {\n",
    "        \"name\": f\"Example-{model_name_safe}-sft-djl\", \n",
    "        \"endpoint\": f\"Example-{model_name_safe}-sft-djl\"\n",
    "        # \"endpoint\": endpoint_name\n",
    "    }\n",
    "    \n",
    "    # Limit samples for faster execution\n",
    "    num_samples = 10\n",
    "    \n",
    "    # Log evaluation parameters\n",
    "    mlflow.log_param(\"qualitative_evaluation_endpoint\", endpoint_name)\n",
    "    mlflow.log_param(\"qualitative_evaluation_num_samples\", num_samples)\n",
    "    mlflow.log_param(\"qualitative_evaluation_timestamp\", datetime.now().isoformat())\n",
    "    mlflow.log_param(\"llm_judge_model\", judge_llm)\n",
    "    \n",
    "    # Load the test dataset\n",
    "    try:\n",
    "        dataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\", \"en\", split=\"train\")\n",
    "        max_samples = len(dataset)\n",
    "        dataset = dataset.shuffle().select(range(min(num_samples, max_samples)))\n",
    "        print(f\"Loaded medical-o1-reasoning dataset with {len(dataset)} samples for qualitative evaluation\")\n",
    "        \n",
    "        mlflow.log_param(\"qualitative_dataset_name\", \"FreedomIntelligence/medical-o1-reasoning-SFT\") \n",
    "        mlflow.log_param(\"qualitative_dataset_actual_samples\", len(dataset))\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error loading dataset for qualitative evaluation: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        raise\n",
    "    \n",
    "    try:\n",
    "        # Perform qualitative evaluation\n",
    "        qualitative_results = evaluate_model_qualitatively(model_to_evaluate, dataset)\n",
    "        \n",
    "        avg_medical_accuracy = qualitative_results[\"avg_medical_accuracy\"]\n",
    "        \n",
    "        print(f\"\\nQualitative evaluation completed!\")\n",
    "        print(f\"Average Medical Accuracy: {avg_medical_accuracy:.3f}\")\n",
    "        \n",
    "        print(f\"avg_medical_accuracy: {avg_medical_accuracy}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error in qualitative model evaluation: {str(e)}\\n{traceback.format_exc()}\"\n",
    "        print(error_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean-up Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_endpoint_with_retry(endpoint_name, max_retries=3, wait_seconds=10):\n",
    "    \"\"\"\n",
    "    Delete a SageMaker endpoint with retry logic\n",
    "    \n",
    "    Args:\n",
    "        endpoint_name (str): Name of the SageMaker endpoint to delete\n",
    "        max_retries (int): Maximum number of retry attempts\n",
    "        wait_seconds (int): Time to wait between retries in seconds\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if deletion was successful, False otherwise\n",
    "    \"\"\"\n",
    "    sm_client = boto3.client('sagemaker')\n",
    "    \n",
    "    # First check if the endpoint exists\n",
    "    try:\n",
    "        sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "        endpoint_exists = True\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if \"Could not find endpoint\" in str(e):\n",
    "            print(f\"Endpoint {endpoint_name} does not exist, no cleanup needed.\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Error checking endpoint existence: {e}\")\n",
    "            return False\n",
    "    \n",
    "    # If we get here, the endpoint exists and we should delete it\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"Attempting to delete endpoint {endpoint_name} (attempt {attempt + 1}/{max_retries})\")\n",
    "            sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "            sm_client.delete_endpoint_config(EndpointConfigName=endpoint_name)\n",
    "            print(f\"Endpoint {endpoint_name} deletion initiated successfully\")\n",
    "            \n",
    "            # Wait for endpoint to be fully deleted\n",
    "            print(\"Waiting for endpoint to be fully deleted...\")\n",
    "            \n",
    "            # Poll until endpoint is deleted or max wait time is reached\n",
    "            total_wait_time = 0\n",
    "            max_wait_time = 300  # 5 minutes maximum wait\n",
    "            while total_wait_time < max_wait_time:\n",
    "                try:\n",
    "                    sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "                    print(f\"Endpoint still exists, waiting {wait_seconds} seconds...\")\n",
    "                    time.sleep(wait_seconds)\n",
    "                    total_wait_time += wait_seconds\n",
    "                except botocore.exceptions.ClientError:\n",
    "                    print(f\"Endpoint {endpoint_name} successfully deleted\")\n",
    "                    return True\n",
    "            \n",
    "            # If we get here, the endpoint still exists after max_wait_time\n",
    "            print(f\"Warning: Endpoint deletion initiated but still exists after {max_wait_time} seconds\")\n",
    "            return False\n",
    "            \n",
    "        except botocore.exceptions.ClientError as e:\n",
    "            if \"ResourceInUse\" in str(e) or \"ResourceNotFound\" in str(e):\n",
    "                print(f\"Error deleting endpoint: {e}\")\n",
    "                print(f\"Retrying in {wait_seconds} seconds...\")\n",
    "                time.sleep(wait_seconds)\n",
    "            else:\n",
    "                print(f\"Unexpected error deleting endpoint: {e}\")\n",
    "                return False\n",
    "    \n",
    "    print(f\"Failed to delete endpoint {endpoint_name} after {max_retries} attempts\")\n",
    "    return False\n",
    "\n",
    "# Clean up endpoint\n",
    "try:\n",
    "    model_name_safe = model_id.split('/')[-1].replace('.', '-').replace('_', '-')\n",
    "    endpoint_name = f\"Example-{model_name_safe}-sft-djl\"\n",
    "    \n",
    "    print(f\"Cleaning up endpoint: {endpoint_name}\")\n",
    "    if delete_endpoint_with_retry(endpoint_name):\n",
    "        print(\"Cleanup completed successfully\")\n",
    "    else:\n",
    "        print(\"Warning: Endpoint cleanup may have failed, please check the SageMaker console\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error during endpoint cleanup: {str(e)}\")\n",
    "    print(\"You may need to manually delete the endpoint from the SageMaker console\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "In this notebook, we illustrated the building blocks for a fine-tuned LLM-deployment pipeline. We showed:\n",
    "\n",
    "1. How to prepare data for a fine-tuning job\n",
    "2. How to deploy a model to a SageMaker AI Managed Endpoint\n",
    "3. How to evaluate a model's performance\n",
    "4. Creating and applying Guardrails to our model\n",
    "5. Tracing model calls using MLFlow tracing\n",
    "\n",
    "Next, we show how to actually perform fine-tuning on this DeepSeek model to improve the model's performance in this domain. Moreover, we'll orchestrate all of these steps into a fine-tuning pipeline powered by Managed MLFlow and SageMaker AI Pipelines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
