{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e91a4f64-2568-4b90-8fb2-17f5ccde1c4d",
   "metadata": {},
   "source": [
    "# Comparing Model Performance after Fine-Tuning\n",
    "In this example, we will take the pre-existing SageMaker endpoints that you deployed in previous exercises and use them to generate data that can be leveraged for quality comparison. This data can be used to take a quantitative approach to judge the efficacy of fine-tuning your models.\n",
    "\n",
    "This example will run through samples of the medical-o1-reasoning dataset (FreedomIntelligence/medical-o1-reasoning-SFT) on the Hugging Face data hub for medical Q&A and use the [lighteval](https://huggingface.co/docs/lighteval/index) from Hugging Face for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5d5ff2-dda1-450e-a098-976986747f62",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "353628ef-4cf9-4957-85ee-1667ac4de611",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sagemaker==2.235.2 (from -r ./scripts/requirements.txt (line 1))\n",
      "  Downloading sagemaker-2.235.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting datasets==4.1.1 (from -r ./scripts/requirements.txt (line 2))\n",
      "  Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting pandas==2.2.3 (from -r ./scripts/requirements.txt (line 3))\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting matplotlib==3.10.6 (from -r ./scripts/requirements.txt (line 4))\n",
      "  Downloading matplotlib-3.10.6-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy==1.26.4 in /opt/conda/lib/python3.12/site-packages (from -r ./scripts/requirements.txt (line 5)) (1.26.4)\n",
      "Collecting boto3==1.40.47 (from -r ./scripts/requirements.txt (line 6))\n",
      "  Downloading boto3-1.40.47-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm==4.67.1 in /opt/conda/lib/python3.12/site-packages (from -r ./scripts/requirements.txt (line 7)) (4.67.1)\n",
      "Collecting lighteval==0.10.0 (from -r ./scripts/requirements.txt (line 8))\n",
      "  Downloading lighteval-0.10.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting attrs<24,>=23.1.0 (from sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1))\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting cloudpickle==2.2.1 (from sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1))\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: docker in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1)) (7.1.0)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1)) (6.10.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1)) (4.23.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1)) (0.3.2)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1)) (4.5.1)\n",
      "Collecting protobuf<5.0,>=3.12 (from sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1))\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1)) (5.9.8)\n",
      "Requirement already satisfied: pyyaml~=6.0 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1)) (6.0.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1)) (2.32.5)\n",
      "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.15 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1)) (1.0.67)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1)) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1)) (3.2.2)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /opt/conda/lib/python3.12/site-packages (from sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1)) (1.26.20)\n",
      "Collecting botocore<1.41.0,>=1.40.47 (from boto3==1.40.47->-r ./scripts/requirements.txt (line 6))\n",
      "  Downloading botocore-1.40.76-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from boto3==1.40.47->-r ./scripts/requirements.txt (line 6)) (1.1.0)\n",
      "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3==1.40.47->-r ./scripts/requirements.txt (line 6))\n",
      "  Downloading s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from datasets==4.1.1->-r ./scripts/requirements.txt (line 2)) (3.20.3)\n",
      "Collecting pyarrow>=21.0.0 (from datasets==4.1.1->-r ./scripts/requirements.txt (line 2))\n",
      "  Downloading pyarrow-23.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/conda/lib/python3.12/site-packages (from datasets==4.1.1->-r ./scripts/requirements.txt (line 2)) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.12/site-packages (from datasets==4.1.1->-r ./scripts/requirements.txt (line 2)) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.12/site-packages (from datasets==4.1.1->-r ./scripts/requirements.txt (line 2)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.1.1->-r ./scripts/requirements.txt (line 2)) (2024.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/conda/lib/python3.12/site-packages (from datasets==4.1.1->-r ./scripts/requirements.txt (line 2)) (0.33.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas==2.2.3->-r ./scripts/requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas==2.2.3->-r ./scripts/requirements.txt (line 3)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas==2.2.3->-r ./scripts/requirements.txt (line 3)) (2025.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.10.6->-r ./scripts/requirements.txt (line 4)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.10.6->-r ./scripts/requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.10.6->-r ./scripts/requirements.txt (line 4)) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.10.6->-r ./scripts/requirements.txt (line 4)) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.10.6->-r ./scripts/requirements.txt (line 4)) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.10.6->-r ./scripts/requirements.txt (line 4)) (3.3.2)\n",
      "Requirement already satisfied: transformers>=4.51.0 in /opt/conda/lib/python3.12/site-packages (from lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (4.53.0)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.12/site-packages (from lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: torch<3.0,>=2.0 in /opt/conda/lib/python3.12/site-packages (from lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (2.6.0)\n",
      "Requirement already satisfied: GitPython>=3.1.41 in /opt/conda/lib/python3.12/site-packages (from lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (3.1.46)\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.12/site-packages (from lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (2.12.5)\n",
      "Requirement already satisfied: typer in /opt/conda/lib/python3.12/site-packages (from lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (0.21.1)\n",
      "Collecting termcolor==2.3.0 (from lighteval==0.10.0->-r ./scripts/requirements.txt (line 8))\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pytablewriter (from lighteval==0.10.0->-r ./scripts/requirements.txt (line 8))\n",
      "  Downloading pytablewriter-1.2.1-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.12/site-packages (from lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (14.3.1)\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.12/site-packages (from lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (6.10.1)\n",
      "Collecting aenum==3.1.15 (from lighteval==0.10.0->-r ./scripts/requirements.txt (line 8))\n",
      "  Downloading aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting nltk==3.9.1 (from lighteval==0.10.0->-r ./scripts/requirements.txt (line 8))\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (from lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (1.6.1)\n",
      "Collecting sacrebleu (from lighteval==0.10.0->-r ./scripts/requirements.txt (line 8))\n",
      "  Downloading sacrebleu-2.6.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting rouge_score==0.1.2 (from lighteval==0.10.0->-r ./scripts/requirements.txt (line 8))\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: sentencepiece>=0.1.99 in /opt/conda/lib/python3.12/site-packages (from lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (0.2.0)\n",
      "Collecting pycountry (from lighteval==0.10.0->-r ./scripts/requirements.txt (line 8))\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting httpx==0.27.2 (from lighteval==0.10.0->-r ./scripts/requirements.txt (line 8))\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting latex2sympy2_extended==1.0.6 (from lighteval==0.10.0->-r ./scripts/requirements.txt (line 8))\n",
      "  Downloading latex2sympy2_extended-1.0.6-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.12/site-packages (from httpx==0.27.2->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (4.12.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from httpx==0.27.2->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx==0.27.2->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.12/site-packages (from httpx==0.27.2->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (3.11)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.12/site-packages (from httpx==0.27.2->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (1.3.1)\n",
      "Collecting antlr4-python3-runtime==4.13.2 (from latex2sympy2_extended==1.0.6->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8))\n",
      "  Downloading antlr4_python3_runtime-4.13.2-py3-none-any.whl.metadata (304 bytes)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.12/site-packages (from latex2sympy2_extended==1.0.6->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (1.14.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.12/site-packages (from nltk==3.9.1->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (8.3.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.12/site-packages (from nltk==3.9.1->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (1.5.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.12/site-packages (from nltk==3.9.1->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (2026.1.15)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.12/site-packages (from rouge_score==0.1.2->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (2.4.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.12/site-packages (from rouge_score==0.1.2->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (1.17.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.1.1->-r ./scripts/requirements.txt (line 2)) (3.13.3)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx==0.27.2->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (0.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.12/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1)) (3.23.0)\n",
      "Requirement already satisfied: mock<5.0,>4.0 in /opt/conda/lib/python3.12/site-packages (from sagemaker-core<2.0.0,>=1.0.15->sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1)) (4.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.12/site-packages (from jsonschema->sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.12/site-packages (from jsonschema->sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1)) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from jsonschema->sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1)) (0.27.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/conda/lib/python3.12/site-packages (from pydantic->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /opt/conda/lib/python3.12/site-packages (from pydantic->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/conda/lib/python3.12/site-packages (from pydantic->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (0.4.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (2.19.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch<3.0,>=2.0->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (80.10.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch<3.0,>=2.0->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch<3.0,>=2.0->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (3.1.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.1.1->-r ./scripts/requirements.txt (line 2)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.1.1->-r ./scripts/requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.1.1->-r ./scripts/requirements.txt (line 2)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.1.1->-r ./scripts/requirements.txt (line 2)) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.1.1->-r ./scripts/requirements.txt (line 2)) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets==4.1.1->-r ./scripts/requirements.txt (line 2)) (1.22.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.12/site-packages (from GitPython>=3.1.41->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.41->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (5.0.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets==4.1.1->-r ./scripts/requirements.txt (line 2)) (1.2.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (0.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1)) (3.4.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy->latex2sympy2_extended==1.0.6->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.12/site-packages (from transformers>=4.51.0->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from transformers>=4.51.0->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch<3.0,>=2.0->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (3.0.3)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in /opt/conda/lib/python3.12/site-packages (from pathos->sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1)) (1.7.8)\n",
      "Requirement already satisfied: pox>=0.3.4 in /opt/conda/lib/python3.12/site-packages (from pathos->sagemaker==2.235.2->-r ./scripts/requirements.txt (line 1)) (0.3.7)\n",
      "Collecting DataProperty<2,>=1.1.0 (from pytablewriter->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8))\n",
      "  Downloading DataProperty-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8))\n",
      "  Downloading mbstrdecoder-1.1.4-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8))\n",
      "  Downloading pathvalidate-3.3.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8))\n",
      "  Downloading tabledata-1.3.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8))\n",
      "  Downloading tcolorpy-0.1.7-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8))\n",
      "  Downloading typepy-1.3.4-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: chardet<6,>=3.0.4 in /opt/conda/lib/python3.12/site-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (5.2.0)\n",
      "Collecting portalocker (from sacrebleu->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8))\n",
      "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.12/site-packages (from sacrebleu->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (0.9.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.12/site-packages (from sacrebleu->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.12/site-packages (from sacrebleu->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (5.4.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (1.16.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (3.6.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.12/site-packages (from typer->lighteval==0.10.0->-r ./scripts/requirements.txt (line 8)) (1.5.4)\n",
      "Downloading sagemaker-2.235.2-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading boto3-1.40.47-py3-none-any.whl (139 kB)\n",
      "Downloading datasets-4.1.1-py3-none-any.whl (503 kB)\n",
      "Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m210.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.6-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m182.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lighteval-0.10.0-py3-none-any.whl (433 kB)\n",
      "Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
      "Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Downloading latex2sympy2_extended-1.0.6-py3-none-any.whl (82 kB)\n",
      "Downloading antlr4_python3_runtime-4.13.2-py3-none-any.whl (144 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m151.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Downloading botocore-1.40.76-py3-none-any.whl (14.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.2/14.2 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Downloading s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
      "Downloading pyarrow-23.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 MB\u001b[0m \u001b[31m175.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m186.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytablewriter-1.2.1-py3-none-any.whl (91 kB)\n",
      "Downloading DataProperty-1.1.0-py3-none-any.whl (27 kB)\n",
      "Downloading mbstrdecoder-1.1.4-py3-none-any.whl (7.9 kB)\n",
      "Downloading pathvalidate-3.3.1-py3-none-any.whl (24 kB)\n",
      "Downloading tabledata-1.3.4-py3-none-any.whl (11 kB)\n",
      "Downloading tcolorpy-0.1.7-py3-none-any.whl (8.1 kB)\n",
      "Downloading typepy-1.3.4-py3-none-any.whl (31 kB)\n",
      "Downloading sacrebleu-2.6.0-py3-none-any.whl (100 kB)\n",
      "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24987 sha256=2f69b214381626f75472a71df53f21d9922cbb53b2f6074bd9d20ff9e9062502\n",
      "  Stored in directory: /home/sagemaker-user/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: antlr4-python3-runtime, aenum, termcolor, tcolorpy, pycountry, pyarrow, protobuf, portalocker, pathvalidate, nltk, mbstrdecoder, cloudpickle, attrs, typepy, sacrebleu, rouge_score, pandas, matplotlib, latex2sympy2_extended, httpx, botocore, s3transfer, datasets, DataProperty, boto3, tabledata, sagemaker, pytablewriter, lighteval\n",
      "\u001b[2K  Attempting uninstall: antlr4-python3-runtime\n",
      "\u001b[2K    Found existing installation: antlr4-python3-runtime 4.9.3\n",
      "\u001b[2K    Uninstalling antlr4-python3-runtime-4.9.3:\n",
      "\u001b[2K      Successfully uninstalled antlr4-python3-runtime-4.9.3\n",
      "\u001b[2K  Attempting uninstall: termcolor━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/29\u001b[0m [aenum]\n",
      "\u001b[2K    Found existing installation: termcolor 3.3.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/29\u001b[0m [aenum]\n",
      "\u001b[2K    Uninstalling termcolor-3.3.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/29\u001b[0m [aenum]\n",
      "\u001b[2K      Successfully uninstalled termcolor-3.3.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/29\u001b[0m [aenum]\n",
      "\u001b[2K  Attempting uninstall: pyarrowm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/29\u001b[0m [pycountry]\n",
      "\u001b[2K    Found existing installation: pyarrow 19.0.1━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/29\u001b[0m [pycountry]\n",
      "\u001b[2K    Uninstalling pyarrow-19.0.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/29\u001b[0m [pycountry]\n",
      "\u001b[2K      Successfully uninstalled pyarrow-19.0.1━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/29\u001b[0m [pyarrow]\n",
      "\u001b[2K  Attempting uninstall: protobufm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/29\u001b[0m [pyarrow]\n",
      "\u001b[2K    Found existing installation: protobuf 6.31.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/29\u001b[0m [pyarrow]\n",
      "\u001b[2K    Uninstalling protobuf-6.31.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/29\u001b[0m [pyarrow]\n",
      "\u001b[2K      Successfully uninstalled protobuf-6.31.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/29\u001b[0m [pyarrow]\n",
      "\u001b[2K  Attempting uninstall: nltk0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/29\u001b[0m [protobuf]\n",
      "\u001b[2K    Found existing installation: nltk 3.9.2━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/29\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling nltk-3.9.2:90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/29\u001b[0m [protobuf]\n",
      "\u001b[2K      Successfully uninstalled nltk-3.9.2━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/29\u001b[0m [protobuf]\n",
      "\u001b[2K  Attempting uninstall: cloudpickle[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/29\u001b[0m [nltk]\n",
      "\u001b[2K    Found existing installation: cloudpickle 3.1.2━━━━━━━━━━━━\u001b[0m \u001b[32m 9/29\u001b[0m [nltk]\n",
      "\u001b[2K    Uninstalling cloudpickle-3.1.2:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/29\u001b[0m [nltk]\n",
      "\u001b[2K      Successfully uninstalled cloudpickle-3.1.2━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/29\u001b[0m [nltk]\n",
      "\u001b[2K  Attempting uninstall: attrsm\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/29\u001b[0m [nltk]\n",
      "\u001b[2K    Found existing installation: attrs 25.4.0━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/29\u001b[0m [attrs]\n",
      "\u001b[2K    Uninstalling attrs-25.4.0:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/29\u001b[0m [attrs]\n",
      "\u001b[2K      Successfully uninstalled attrs-25.4.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/29\u001b[0m [attrs]\n",
      "\u001b[2K  Attempting uninstall: pandas\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/29\u001b[0m [attrs]\n",
      "\u001b[2K    Found existing installation: pandas 2.3.3[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/29\u001b[0m [pandas]\n",
      "\u001b[2K    Uninstalling pandas-2.3.3:\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/29\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled pandas-2.3.30m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/29\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: matplotlib\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/29\u001b[0m [pandas]\n",
      "\u001b[2K    Found existing installation: matplotlib 3.10.8━━━━━━━━━━━━\u001b[0m \u001b[32m16/29\u001b[0m [pandas]\n",
      "\u001b[2K    Uninstalling matplotlib-3.10.8:╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/29\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled matplotlib-3.10.80m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/29\u001b[0m [matplotlib]\n",
      "\u001b[2K  Attempting uninstall: httpx━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/29\u001b[0m [matplotlib]\n",
      "\u001b[2K    Found existing installation: httpx 0.28.1m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/29\u001b[0m [matplotlib]\n",
      "\u001b[2K    Uninstalling httpx-0.28.1:━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m19/29\u001b[0m [httpx]]\n",
      "\u001b[2K      Successfully uninstalled httpx-0.28.1m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m19/29\u001b[0m [httpx]\n",
      "\u001b[2K  Attempting uninstall: botocore0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m19/29\u001b[0m [httpx]\n",
      "\u001b[2K    Found existing installation: botocore 1.42.46━━━━━━━━━━━━━\u001b[0m \u001b[32m19/29\u001b[0m [httpx]\n",
      "\u001b[2K    Uninstalling botocore-1.42.46:\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m19/29\u001b[0m [httpx]\n",
      "\u001b[2K      Successfully uninstalled botocore-1.42.460m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m20/29\u001b[0m [botocore]\n",
      "\u001b[2K  Attempting uninstall: s3transfer━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m20/29\u001b[0m [botocore]\n",
      "\u001b[2K    Found existing installation: s3transfer 0.16.0━━━━━━━━━━━━\u001b[0m \u001b[32m20/29\u001b[0m [botocore]\n",
      "\u001b[2K    Uninstalling s3transfer-0.16.0:\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m20/29\u001b[0m [botocore]\n",
      "\u001b[2K      Successfully uninstalled s3transfer-0.16.00m━━━━━━━━━━━━\u001b[0m \u001b[32m20/29\u001b[0m [botocore]\n",
      "\u001b[2K  Attempting uninstall: datasets[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m20/29\u001b[0m [botocore]\n",
      "\u001b[2K    Found existing installation: datasets 3.2.090m━━━━━━━━━━━━\u001b[0m \u001b[32m20/29\u001b[0m [botocore]\n",
      "\u001b[2K    Uninstalling datasets-3.2.0:[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m20/29\u001b[0m [botocore]\n",
      "\u001b[2K      Successfully uninstalled datasets-3.2.0\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m20/29\u001b[0m [botocore]\n",
      "\u001b[2K  Attempting uninstall: boto3━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m22/29\u001b[0m [datasets]\n",
      "\u001b[2K    Found existing installation: boto3 1.42.46[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m24/29\u001b[0m [boto3]\n",
      "\u001b[2K    Uninstalling boto3-1.42.46:━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m24/29\u001b[0m [boto3]\n",
      "\u001b[2K      Successfully uninstalled boto3-1.42.460m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m24/29\u001b[0m [boto3]\n",
      "\u001b[2K  Attempting uninstall: sagemaker━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m24/29\u001b[0m [boto3]\n",
      "\u001b[2K    Found existing installation: sagemaker 2.252.0m\u001b[90m━━━━━━\u001b[0m \u001b[32m24/29\u001b[0m [boto3]\n",
      "\u001b[2K    Uninstalling sagemaker-2.252.0:━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m24/29\u001b[0m [boto3]\n",
      "\u001b[2K      Successfully uninstalled sagemaker-2.252.0[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m26/29\u001b[0m [sagemaker]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29/29\u001b[0m [lighteval]29\u001b[0m [lighteval]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.5.0 requires nvidia-ml-py3<8.0,>=7.352.0, which is not installed.\n",
      "autogluon-timeseries 1.5.0 requires chronos-forecasting<2.4,>=2.2.2, which is not installed.\n",
      "autogluon-timeseries 1.5.0 requires einops<1,>=0.7, which is not installed.\n",
      "jupyter-ai 2.31.7 requires faiss-cpu!=1.8.0.post0,<2.0.0,>=1.8.0, which is not installed.\n",
      "aiobotocore 2.22.0 requires botocore<1.37.4,>=1.37.2, but you have botocore 1.40.76 which is incompatible.\n",
      "autogluon-common 1.5.0 requires pyarrow<21.0.0,>=7.0.0, but you have pyarrow 23.0.0 which is incompatible.\n",
      "awswrangler 3.15.0 requires pyarrow<23.0.0,>=8.0.0, but you have pyarrow 23.0.0 which is incompatible.\n",
      "dask 2026.1.1 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\n",
      "distributed 2026.1.1 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\n",
      "grpcio-status 1.67.1 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
      "omegaconf 2.3.0 requires antlr4-python3-runtime==4.9.*, but you have antlr4-python3-runtime 4.13.2 which is incompatible.\n",
      "s3fs 2024.12.0 requires fsspec==2024.12.0.*, but you have fsspec 2024.9.0 which is incompatible.\n",
      "sagemaker-studio 1.1.5 requires pandas>=2.3.2, but you have pandas 2.2.3 which is incompatible.\n",
      "sagemaker-studio-analytics-extension 0.2.4 requires sparkmagic==0.22.0, but you have sparkmagic 0.21.0 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.3 which is incompatible.\n",
      "strands-agents-tools 0.1.9 requires dill<0.5.0,>=0.4.0, but you have dill 0.3.8 which is incompatible.\n",
      "mlflow 2.22.2 requires pyarrow<20,>=4.0.0, but you have pyarrow 23.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed DataProperty-1.1.0 aenum-3.1.15 antlr4-python3-runtime-4.13.2 attrs-23.2.0 boto3-1.40.47 botocore-1.40.76 cloudpickle-2.2.1 datasets-4.1.1 httpx-0.27.2 latex2sympy2_extended-1.0.6 lighteval-0.10.0 matplotlib-3.10.6 mbstrdecoder-1.1.4 nltk-3.9.1 pandas-2.2.3 pathvalidate-3.3.1 portalocker-3.2.0 protobuf-4.25.8 pyarrow-23.0.0 pycountry-24.6.1 pytablewriter-1.2.1 rouge_score-0.1.2 s3transfer-0.14.0 sacrebleu-2.6.0 sagemaker-2.235.2 tabledata-1.3.4 tcolorpy-0.1.7 termcolor-2.3.0 typepy-1.3.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ./scripts/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bae700e-fd5a-4f22-b45f-b50429a5d110",
   "metadata": {},
   "source": [
    "## This cell will restart the kernel. Click \"OK\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27721bb8-d259-4f28-83aa-8847b5e4af8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import get_ipython\n",
    "get_ipython().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c20c83d-2050-494c-acd6-0c9f575eb488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'BASE_ENDPOINT_NAME' (str)\n",
      "Stored 'TUNED_ENDPOINT_NAME' (str)\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "BASE_ENDPOINT_NAME = \"Qwen3-4B-Instruct-2507-endpoint-2026-02-13-13-13-09-563\"\n",
    "TUNED_ENDPOINT_NAME = \"Qwen3-4B-Instruct-2507-sft-2026-02-13-19-22-36-498\"\n",
    "\n",
    "%store BASE_ENDPOINT_NAME\n",
    "%store TUNED_ENDPOINT_NAME\n",
    "\n",
    "# Import libraries\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Import LightEval metrics\n",
    "from lighteval.metrics.metrics_sample import ROUGE, Doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1341fb-a37e-4f9f-9d3f-32233d58427f",
   "metadata": {},
   "source": [
    "#### Fetch the saved endpoint names from previous sections, or set them manually by uncommenting the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d1557b-06dc-4b9b-8a4e-bd543f37a868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Endpoint: Qwen3-4B-Instruct-2507-endpoint-2026-02-13-13-13-09-563\n",
      "Tuned Endpoint: Qwen3-4B-Instruct-2507-sft-2026-02-13-19-22-36-498\n"
     ]
    }
   ],
   "source": [
    "%store -r BASE_ENDPOINT_NAME\n",
    "%store -r TUNED_ENDPOINT_NAME\n",
    "\n",
    "#BASE_ENDPOINT_NAME = \"\"\n",
    "#TUNED_ENDPOINT_NAME = \"\"\n",
    "\n",
    "print(f\"Base Endpoint: {BASE_ENDPOINT_NAME}\")\n",
    "print(f\"Tuned Endpoint: {TUNED_ENDPOINT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "821e1176-f2af-4e7f-9273-48b2d67e22a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model to evaluate\n",
    "model_to_evaluate = {\n",
    "    \"name\": \"Fine-tuned Model\", \n",
    "    \"endpoint\": TUNED_ENDPOINT_NAME\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81de5205-0203-441b-b8d6-e2a8ef6c7fae",
   "metadata": {},
   "source": [
    "Here you will use the the medical-o1-reasoning dataset. The dataset is pre-split into training and test data. We will limit the number of samples to evaluate for the fine-tuned and base models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a89eec7-cac2-4295-a0d6-495bb445d267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549d00eb19cb44bd9df7c8c9ed2d2629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e0ad8900f74dc7b7b61b277b77f9f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "medical_o1_sft.json:   0%|          | 0.00/58.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e9d2d57afd4ea499f64417e250cf81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/19704 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded medical-o1-reasoning dataset with 10 samples out of 19704\n",
      "\n",
      "Question:\n",
      " Which hereditary disorder of bilirubin metabolism is caused by a defect in the MRP2 gene? \n",
      "\n",
      "====\n",
      "\n",
      "Complex_CoT:\n",
      " Alright, let's dive into this. So, the MRP2 gene is really interesting because it codes for a protein that belongs to the ABC transporter family. This protein plays a huge role in the liver by moving stuff around, including something called conjugated bilirubin, from inside liver cells into the bile. \n",
      "\n",
      "Now, why is this important? Well, you see, bilirubin metabolism relies heavily on this process. Without proper transport of conjugated bilirubin, it can't get from the liver to the bile duct, and then ultimately out of the body. This step is crucial; otherwise, you end up with bilirubin building up in the liver and bloodstream. And we definitely don't want that because it leads to elevated levels in the blood.\n",
      "\n",
      "If the MRP2 gene has some defects or mutations, this transport process gets messed up. Imagine what's supposed to be a smooth highway has now got a blockage. What happens then? Conjugated bilirubin can't exit the liver properly, leading to hyperbilirubinemia, which is just a fancy term for saying there's too much bilirubin in the blood.\n",
      "\n",
      "Now, here's where it gets specific. The particular disorder we're actually talking about when the MRP2 gene is faulty is called Dubin-Johnson syndrome. Yup, that's the one where conjugated bilirubin specifically stacks up in the liver because it's not getting excreted into the bile.\n",
      "\n",
      "So, summing things up, if someone has Dubin-Johnson syndrome, it would actually trace back to a problem with the MRP2 gene not functioning correctly. Yeah, so that checks out. It makes sense that Dubin-Johnson syndrome is the hereditary condition linked to defects in this gene. \n",
      "\n",
      "====\n",
      "\n",
      "Response:\n",
      " Dubin-Johnson syndrome is the hereditary disorder of bilirubin metabolism caused by a defect in the MRP2 gene. This gene is responsible for encoding a protein involved in the transport of conjugated bilirubin from liver cells into the bile. Defects or mutations in the MRP2 gene disrupt this transport process, leading to an accumulation of conjugated bilirubin in the liver and elevated levels in the bloodstream. \n",
      "\n",
      "====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Limit the number of samples to evaluate (for faster execution)\n",
    "num_samples = 10\n",
    "\n",
    "# Load the test split of the medical-o1-reasoning dataset\n",
    "dataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\", \"en\", split=\"train\")\n",
    "\n",
    "max_samples = len(dataset)\n",
    "\n",
    "dataset = dataset.shuffle().select(range(min(num_samples, max_samples)))\n",
    "print(f\"Loaded medical-o1-reasoning dataset with {len(dataset)} samples out of {max_samples}\")\n",
    "\n",
    "# Display a sample from the dataset\n",
    "sample = dataset[0]\n",
    "\n",
    "print(\"\\nQuestion:\\n\", sample[\"Question\"], \"\\n\\n====\\n\")\n",
    "print(\"Complex_CoT:\\n\", sample[\"Complex_CoT\"], \"\\n\\n====\\n\")\n",
    "print(\"Response:\\n\", sample[\"Response\"], \"\\n\\n====\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f8dc243-5b54-454e-ab78-47455591a166",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \n",
    "Below is an instruction that describes a task, paired with an input that provides further context. \n",
    "Write a response that appropriately completes the request.\n",
    "Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\"\"\"\n",
    "\n",
    "\n",
    "# template dataset to add prompt to each sample\n",
    "def convert_to_messages(sample, system_prompt=\"\", include_answer=True):\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": sample[\"Question\"]},\n",
    "    ]\n",
    "\n",
    "    if include_answer:\n",
    "        messages.append({\"role\": \"assistant\", \"content\": f\"{sample[\"Complex_CoT\"]}\\n\\n{sample[\"Response\"]}\"})\n",
    "    \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1a5e2c-39e9-4d51-a394-b666ffde44f2",
   "metadata": {},
   "source": [
    "#### Next, we will create functions to interact with the SageMaker endpoints, define metrics we want to calculate (ROUGE), and define how to evaluate the models with the medical-o1-reasoning dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8cd7d2a-ed91-45fa-8f1c-dfe42f9ebc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LightEval metrics calculators\n",
    "rouge_metrics = ROUGE(\n",
    "    methods=[\"rouge1\", \"rouge2\", \"rougeL\"],\n",
    "    multiple_golds=False,\n",
    "    bootstrap=False,\n",
    "    normalize_gold=None,\n",
    "    normalize_pred=None\n",
    ")\n",
    "\n",
    "def calculate_metrics(predictions, references):\n",
    "    \"\"\"\n",
    "    Calculate all evaluation metrics for summarization using LightEval.\n",
    "    \n",
    "    Args:\n",
    "        predictions (list): List of generated summaries\n",
    "        references (list): List of reference summaries\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing all metric scores\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Create Doc objects for the Rouge and BertScore metrics\n",
    "    docs = []\n",
    "    for reference in references:\n",
    "        docs.append(Doc(\n",
    "            {\"target\": reference},\n",
    "            choices=[reference],  # Dummy choices\n",
    "            gold_index=0  # Dummy gold_index\n",
    "        ))\n",
    "    \n",
    "    # Calculate ROUGE scores for each prediction-reference pair\n",
    "    rouge_scores = {'rouge1_f': [], 'rouge2_f': [], 'rougeL_f': []}\n",
    "    \n",
    "    for pred, ref in zip(predictions, references):\n",
    "        # For ROUGE calculation\n",
    "        rouge_result = rouge_metrics.compute(golds=[ref], predictions=[pred])\n",
    "        rouge_scores['rouge1_f'].append(rouge_result['rouge1'])\n",
    "        rouge_scores['rouge2_f'].append(rouge_result['rouge2'])\n",
    "        rouge_scores['rougeL_f'].append(rouge_result['rougeL'])\n",
    "    \n",
    "    # Average ROUGE scores\n",
    "    for key in rouge_scores:\n",
    "        metrics[key] = sum(rouge_scores[key]) / len(rouge_scores[key])\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccac55f4-463b-4a25-bbbd-529f76fbc157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summaries_with_model(predictor, dataset):\n",
    "    \"\"\"\n",
    "    Generate summaries using a model deployed on SageMaker.\n",
    "    \n",
    "    Args:\n",
    "        endpoint_name (str): SageMaker endpoint name\n",
    "        dataset: Dataset containing dialogues\n",
    "        \n",
    "    Returns:\n",
    "        list: Generated summaries\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for example in tqdm(dataset, desc=\"Generating Responses\"):\n",
    "\n",
    "        messages = convert_to_messages(example, system_prompt=SYSTEM_PROMPT, include_answer=False)\n",
    "        \n",
    "        # Payload for SageMaker endpoint\n",
    "        payload = {\n",
    "            \"messages\": messages,\n",
    "            \"parameters\": {\n",
    "                \"max_new_tokens\": 512,\n",
    "                \"top_p\": 0.9,\n",
    "                \"temperature\": 0.6,\n",
    "                \"return_full_text\": False\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Call the model endpoint\n",
    "        try:\n",
    "            response = predictor.predict(payload)\n",
    "            \n",
    "            # Extract the generated text\n",
    "            if isinstance(response, list):\n",
    "                prediction = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            elif isinstance(response, dict):\n",
    "                prediction = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            else:\n",
    "                prediction = str(response).strip\n",
    "\n",
    "\n",
    "            #prediction = prediction.split(\"<|eot_id|>\")[0]\n",
    "            # Clean up the generated text\n",
    "            #if \"Summary:\" in prediction:\n",
    "            #    prediction = prediction.split(\"Summary:\", 1)[1].strip()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error invoking SageMaker endpoint {endpoint_name}: {e}\")\n",
    "            prediction = \"Error generating summary.\"\n",
    "        \n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a872572-5d5d-4a0e-98f6-e656f26ba29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_dataset(model_config, dataset):\n",
    "    \"\"\"\n",
    "    Evaluate a fine-tuned model on the medical-o1-reasoning dataset using both automated and human metrics.\n",
    "    \n",
    "    Args:\n",
    "        model_config (dict): Model configuration with name and endpoint\n",
    "        dataset: medical-o1-reasoning dataset for evaluation\n",
    "        \n",
    "    Returns:\n",
    "        dict: Evaluation results\n",
    "    \"\"\"\n",
    "    model_name = model_config[\"name\"]\n",
    "    endpoint_name = model_config[\"endpoint\"]\n",
    "\n",
    "    predictor = sagemaker.Predictor(\n",
    "        endpoint_name=endpoint_name,\n",
    "        sagemaker_session=sagemaker.Session(),\n",
    "        serializer=sagemaker.serializers.JSONSerializer(),\n",
    "        deserializer=sagemaker.deserializers.JSONDeserializer(),\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nEvaluating model: {model_name} on endpoint: {endpoint_name}\")\n",
    "    \n",
    "    # Get references\n",
    "    references = [\"\\n\".join([example[\"Complex_CoT\"], example[\"Response\"]]) for example in dataset]\n",
    "    \n",
    "    # Generate summaries\n",
    "    print(\"\\nGenerating Responses...\")\n",
    "    predictions = generate_summaries_with_model(predictor, dataset)\n",
    "    \n",
    "    # Calculate automated metrics using LightEval\n",
    "    print(\"\\nCalculating evaluation metrics with LightEval...\")\n",
    "    metrics = calculate_metrics(predictions, references)\n",
    "    \n",
    "    # Format results\n",
    "    results = {\n",
    "        \"model_name\": model_name,\n",
    "        \"endpoint_name\": endpoint_name,\n",
    "        \"num_samples\": len(dataset),\n",
    "        \"metrics\": metrics,\n",
    "        \"predictions\": predictions[:5],  # First 5 predictions\n",
    "        \"references\": references[:5]     # First 5 references\n",
    "    }\n",
    "    \n",
    "    # Print key results\n",
    "    print(f\"\\nResults for {model_name}:\")\n",
    "    print(f\"ROUGE-1 F1: {metrics['rouge1_f']:.4f}\")\n",
    "    print(f\"ROUGE-2 F1: {metrics['rouge2_f']:.4f}\")\n",
    "    print(f\"ROUGE-L F1: {metrics['rougeL_f']:.4f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080aa020-0aaf-438d-b0cb-dd503d248feb",
   "metadata": {},
   "source": [
    "#### In this section, we evaluate the performance of both our base model (Qwen3-4B-Instruct-2507) and our fine-tuned model on the medical-o1-reasoning dataset using ROUGE metrics, which are standard for evaluating text summarization quality.\n",
    "\n",
    "The evaluation process:\n",
    "\n",
    "We first evaluate the base model against the medical-o1-reasoning test set to establish a baseline performance. Then, we evaluate our fine-tuned model on the same dataset to measure improvements. Both evaluations calculate ROUGE-1, ROUGE-2, and ROUGE-L scores, which respectively measure:\n",
    "\n",
    "ROUGE-1: Unigram overlap between generated and reference summaries\n",
    "ROUGE-2: Bigram overlap (captures more fluency and coherence)\n",
    "ROUGE-L: Longest common subsequence (measures sentence structure similarity)\n",
    "\n",
    "The results are saved to JSON files for later analysis and comparison. These metrics will help us quantify how much our fine-tuning process has improved the model's summarization capabilities compared to the original base model.\n",
    "\n",
    "**Note: Since the model you trained in this example was only exposed to a small amount of training data and the testing sample is small, you may see varied results. There are evaluation examples at the end of this section on a larger training and testing set for comparison.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02db13a7-81a3-4279-bde5-afbc75ca2b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model: Base Model on endpoint: Qwen3-4B-Instruct-2507-endpoint-2026-02-13-13-13-09-563\n",
      "\n",
      "Generating Responses...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0141b0ec2c7640a5891e5292a485d755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Responses:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating evaluation metrics with LightEval...\n",
      "\n",
      "Results for Base Model:\n",
      "ROUGE-1 F1: 0.4154\n",
      "ROUGE-2 F1: 0.1407\n",
      "ROUGE-L F1: 0.1893\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the base and fine-tuned models using LightEval metrics\n",
    "start_time = time.time()\n",
    "\n",
    "# Evaluate both models for comparison\n",
    "base_model_config = {\n",
    "    \"name\": \"Base Model\",\n",
    "    \"endpoint\": BASE_ENDPOINT_NAME\n",
    "}\n",
    "\n",
    "# Evaluate base model\n",
    "base_model_results = evaluate_model_on_dataset(base_model_config, dataset)\n",
    "base_model_results[\"evaluation_time\"] = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49cf903b-6605-4e22-a56e-f5c916e10e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model: Fine-tuned Model on endpoint: Qwen3-4B-Instruct-2507-sft-2026-02-13-19-22-36-498\n",
      "\n",
      "Generating Responses...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04877b8196546fe874b01fcbb7c32d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Responses:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating evaluation metrics with LightEval...\n",
      "\n",
      "Results for Fine-tuned Model:\n",
      "ROUGE-1 F1: 0.4609\n",
      "ROUGE-2 F1: 0.1670\n",
      "ROUGE-L F1: 0.2258\n"
     ]
    }
   ],
   "source": [
    "# Start timing fine-tuned model\n",
    "start_time = time.time()\n",
    "\n",
    "# Evaluate fine-tuned model\n",
    "finetuned_model_results = evaluate_model_on_dataset(model_to_evaluate, dataset)\n",
    "finetuned_model_results[\"evaluation_time\"] = time.time() - start_time\n",
    "\n",
    "# Save results\n",
    "base_file_name = base_model_config[\"name\"].replace(' ', '_').lower()\n",
    "finetuned_file_name = model_to_evaluate[\"name\"].replace(' ', '_').lower()\n",
    "\n",
    "with open(f\"{base_file_name}_results.json\", \"w\") as f:\n",
    "    json.dump(base_model_results, f)\n",
    "    \n",
    "with open(f\"{finetuned_file_name}_results.json\", \"w\") as f:\n",
    "    json.dump(finetuned_model_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b4944d-ad64-448d-91aa-e7222d7ebe8a",
   "metadata": {},
   "source": [
    "Create a tablular view to compare the base model and fine-tuned model performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "336396df-7175-4069-9794-b425501aee1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>ROUGE-1 F1</th>\n",
       "      <th>ROUGE-2 F1</th>\n",
       "      <th>ROUGE-L F1</th>\n",
       "      <th>Evaluation Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base Model</td>\n",
       "      <td>0.415407</td>\n",
       "      <td>0.140741</td>\n",
       "      <td>0.189347</td>\n",
       "      <td>78.721371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fine-tuned Model</td>\n",
       "      <td>0.460939</td>\n",
       "      <td>0.166952</td>\n",
       "      <td>0.225820</td>\n",
       "      <td>45.630357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model  ROUGE-1 F1  ROUGE-2 F1  ROUGE-L F1  Evaluation Time (s)\n",
       "0        Base Model    0.415407    0.140741    0.189347            78.721371\n",
       "1  Fine-tuned Model    0.460939    0.166952    0.225820            45.630357"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a comparison DataFrame\n",
    "comparison_data = []\n",
    "\n",
    "# Add base model metrics\n",
    "comparison_data.append({\n",
    "    \"Model\": base_model_config[\"name\"],\n",
    "    \"ROUGE-1 F1\": base_model_results[\"metrics\"][\"rouge1_f\"],\n",
    "    \"ROUGE-2 F1\": base_model_results[\"metrics\"][\"rouge2_f\"],\n",
    "    \"ROUGE-L F1\": base_model_results[\"metrics\"][\"rougeL_f\"],\n",
    "    \"Evaluation Time (s)\": base_model_results[\"evaluation_time\"]\n",
    "})\n",
    "\n",
    "# Add fine-tuned model metrics\n",
    "comparison_data.append({\n",
    "    \"Model\": model_to_evaluate[\"name\"],\n",
    "    \"ROUGE-1 F1\": finetuned_model_results[\"metrics\"][\"rouge1_f\"],\n",
    "    \"ROUGE-2 F1\": finetuned_model_results[\"metrics\"][\"rouge2_f\"],\n",
    "    \"ROUGE-L F1\": finetuned_model_results[\"metrics\"][\"rougeL_f\"],\n",
    "    \"Evaluation Time (s)\": finetuned_model_results[\"evaluation_time\"]\n",
    "})\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"Model Comparison:\")\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a07ee65-270a-41ce-bdff-620318c673f6",
   "metadata": {},
   "source": [
    "Show a bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "310fa953-173a-433b-ac83-7f75a45907eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROUGE and BERTScore metrics for both models\n",
    "metrics_to_plot = [\"ROUGE-1 F1\", \"ROUGE-2 F1\", \"ROUGE-L F1\"]\n",
    "models = comparison_df[\"Model\"].tolist()\n",
    "\n",
    "# Create a grouped bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.2\n",
    "index = np.arange(len(metrics_to_plot))\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    values = [comparison_df.loc[i, metric] for metric in metrics_to_plot]\n",
    "    plt.bar(index + i*bar_width, values, bar_width, label=model)\n",
    "\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Summarization Performance Comparison')\n",
    "plt.xticks(index + bar_width/2, metrics_to_plot)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eabf665-2e81-4b17-8ce2-3b7aec06e010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement Analysis:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Base Score</th>\n",
       "      <th>Fine-tuned Score</th>\n",
       "      <th>Absolute Improvement</th>\n",
       "      <th>% Improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROUGE-1 F1</td>\n",
       "      <td>0.415407</td>\n",
       "      <td>0.460939</td>\n",
       "      <td>0.045532</td>\n",
       "      <td>10.96%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROUGE-2 F1</td>\n",
       "      <td>0.140741</td>\n",
       "      <td>0.166952</td>\n",
       "      <td>0.026210</td>\n",
       "      <td>18.62%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROUGE-L F1</td>\n",
       "      <td>0.189347</td>\n",
       "      <td>0.225820</td>\n",
       "      <td>0.036473</td>\n",
       "      <td>19.26%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Metric  Base Score  Fine-tuned Score  Absolute Improvement  \\\n",
       "0  ROUGE-1 F1    0.415407          0.460939              0.045532   \n",
       "1  ROUGE-2 F1    0.140741          0.166952              0.026210   \n",
       "2  ROUGE-L F1    0.189347          0.225820              0.036473   \n",
       "\n",
       "  % Improvement  \n",
       "0        10.96%  \n",
       "1        18.62%  \n",
       "2        19.26%  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate improvement from base to fine-tuned model\n",
    "improvement_data = {}\n",
    "\n",
    "for metric in [\"ROUGE-1 F1\", \"ROUGE-2 F1\", \"ROUGE-L F1\"]:\n",
    "    base_value = comparison_df.loc[0, metric]\n",
    "    finetuned_value = comparison_df.loc[1, metric]\n",
    "    \n",
    "    if not pd.isna(base_value) and not pd.isna(finetuned_value):\n",
    "        abs_improvement = finetuned_value - base_value\n",
    "        pct_improvement = (abs_improvement / base_value) * 100 if base_value > 0 else float('inf')\n",
    "        \n",
    "        improvement_data[metric] = {\n",
    "            \"Base Model\": base_value,\n",
    "            \"Fine-tuned Model\": finetuned_value,\n",
    "            \"Absolute Improvement\": abs_improvement,\n",
    "            \"% Improvement\": pct_improvement\n",
    "        }\n",
    "\n",
    "# Create DataFrame for improvement metrics\n",
    "improvement_df = pd.DataFrame({\n",
    "    \"Metric\": list(improvement_data.keys()),\n",
    "    \"Base Score\": [improvement_data[m][\"Base Model\"] for m in improvement_data],\n",
    "    \"Fine-tuned Score\": [improvement_data[m][\"Fine-tuned Model\"] for m in improvement_data],\n",
    "    \"Absolute Improvement\": [improvement_data[m][\"Absolute Improvement\"] for m in improvement_data],\n",
    "    \"% Improvement\": [f\"{improvement_data[m]['% Improvement']:.2f}%\" for m in improvement_data]\n",
    "})\n",
    "\n",
    "print(\"Improvement Analysis:\")\n",
    "improvement_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf04e3d5-c865-45c1-93a4-54457b207db7",
   "metadata": {},
   "source": [
    "## Larger Training/Evaluation Results\n",
    "\n",
    "If you were to train **Qwen3-4B-Instruct-2507** on **5000** samples and evaluate on **100** test items (total training time 32 mins on an ml.g5.12xlarge instance), you would see the following results:\n",
    "\n",
    "![](./images/sft_5000_train_100_test_scores.png)\n",
    "\n",
    "![](images/sft_5000_train_100_test_bars.png)\n",
    "\n",
    "![](images/sft_5000_train_100_test_compare.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8213dea-cfac-42c2-acca-1e9bcb32dd86",
   "metadata": {},
   "source": [
    "## Detailed Comparison Between Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c6fd3c6-19a9-41c7-97e2-c03ab2023ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 1:\n",
      "Question: Which hereditary disorder of bilirubin metabolism is caused by a defect in the MRP2 gene?\n",
      "\n",
      "Reference CoT+Answer: Alright, let's dive into this. So, the MRP2 gene is really interesting because it codes for a protein that belongs to the ABC transporter family. This protein plays a huge role in the liver by moving stuff around, including something called conjugated bilirubin, from inside liver cells into the bile. \n",
      "\n",
      "Now, why is this important? Well, you see, bilirubin metabolism relies heavily on this process. Without proper transport of conjugated bilirubin, it can't get from the liver to the bile duct, and then ultimately out of the body. This step is crucial; otherwise, you end up with bilirubin building up in the liver and bloodstream. And we definitely don't want that because it leads to elevated levels in the blood.\n",
      "\n",
      "If the MRP2 gene has some defects or mutations, this transport process gets messed up. Imagine what's supposed to be a smooth highway has now got a blockage. What happens then? Conjugated bilirubin can't exit the liver properly, leading to hyperbilirubinemia, which is just a fancy term for saying there's too much bilirubin in the blood.\n",
      "\n",
      "Now, here's where it gets specific. The particular disorder we're actually talking about when the MRP2 gene is faulty is called Dubin-Johnson syndrome. Yup, that's the one where conjugated bilirubin specifically stacks up in the liver because it's not getting excreted into the bile.\n",
      "\n",
      "So, summing things up, if someone has Dubin-Johnson syndrome, it would actually trace back to a problem with the MRP2 gene not functioning correctly. Yeah, so that checks out. It makes sense that Dubin-Johnson syndrome is the hereditary condition linked to defects in this gene.\n",
      "Dubin-Johnson syndrome is the hereditary disorder of bilirubin metabolism caused by a defect in the MRP2 gene. This gene is responsible for encoding a protein involved in the transport of conjugated bilirubin from liver cells into the bile. Defects or mutations in the MRP2 gene disrupt this transport process, leading to an accumulation of conjugated bilirubin in the liver and elevated levels in the bloodstream.\n",
      "\n",
      "Base Model Summary: The hereditary disorder of bilirubin metabolism caused by a defect in the **MRP2 gene** is **Gilbert's syndrome**.\n",
      "\n",
      "However, this requires clarification:\n",
      "\n",
      "Actually, **Gilbert's syndrome** is **not** caused by a defect in the MRP2 gene.\n",
      "\n",
      "Let’s correct and clarify:\n",
      "\n",
      "- **MRP2** (Multidrug Resistance-Associated Protein 2), also known as **ABCC2**, is a transporter protein located on the canalicular membrane of hepatocytes.\n",
      "- It is responsible for the **excretion of conjugated bilirubin** into the bile.\n",
      "- A **mutation in the MRP2 gene** leads to **reduced bile excretion of conjugated bilirubin**, resulting in **elevated serum conjugated bilirubin**.\n",
      "\n",
      "The disorder caused by a defect in the MRP2 gene is **progressive familial intrahepatic cholestasis type 2 (PFIC2)**.\n",
      "\n",
      "✅ Therefore, the correct answer is:\n",
      "\n",
      "**Progressive familial intrahepatic cholestasis type 2 (PFIC2)**.\n",
      "\n",
      "**Final Answer: Progressive familial intrahepatic cholestasis type 2 (PFIC2)**.\n",
      "\n",
      "Fine-tuned Model Summary: Alright, let's tackle this question about a hereditary disorder related to bilirubin metabolism caused by a defect in the MRP2 gene. I'm going to break it down step by step to make sure I get it right.\n",
      "\n",
      "First, I need to recall what bilirubin is and its role in the body. Bilirubin is a yellow pigment that's produced when old red blood cells break down. It's usually processed by the liver and excreted in bile, which is then eliminated from the body through feces. If something goes wrong with this process, bilirubin can build up in the blood, leading to jaundice and other health issues.\n",
      "\n",
      "Now, focusing on the MRP2 gene. MRP2 stands for Multidrug Resistance-associated Protein 2. This gene encodes a protein that's crucial for transporting substances out of liver cells into bile. Specifically, MRP2 helps move bilirubin conjugates—bilirubin molecules that have been modified by the liver—out of the liver cells and into the bile ducts. Without MRP2, these conjugated bilirubin molecules can't be effectively excreted, leading to their accumulation in the bloodstream.\n",
      "\n",
      "Given this information, I need to identify the disorder that results from a defect in the MRP2 gene. This disorder is known as Gilbert's syndrome. It's a common condition that primarily affects males and is characterized by mild jaundice, often triggered by fasting, illness, or stress. In Gilbert's syndrome, the MRP2 gene mutation leads to a reduced ability to excrete conjugated bilirubin, causing it to build up in the blood. This accumulation can lead to the yellowish discoloration of the skin and eyes, commonly known as jaundice.\n",
      "\n",
      "So, putting it all together, the hereditary disorder of bilirubin metabolism caused by a defect in the MRP2 gene is Gilbert's syndrome. This disorder results in the inability to efficiently excrete conjugated bilirubin from the liver, leading to its accumulation in the bloodstream and the characteristic symptoms of jaundice.\n",
      "\n",
      "ROUGE Scores (LightEval):\n",
      "Base Model - ROUGE-1: 0.3229, ROUGE-2: 0.1516, ROUGE-L: 0.1845\n",
      "Fine-tuned - ROUGE-1: 0.5547, ROUGE-2: 0.2226, ROUGE-L: 0.2639\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Example 2:\n",
      "Question: In transposition of great vessels, all are true except –a) Aorta arises from the right ventricleb) Mitral valve is continuous with the aortic valvec) Causes jaundice immediately after birthd) None of the above\n",
      "A. bc\n",
      "B. c\n",
      "C. ac\n",
      "D. ad\n",
      "\n",
      "Reference CoT+Answer: Let's think about this condition called transposition of the great vessels. It's when the two major arteries in the heart, the aorta and the pulmonary artery, are switched. So, if the aorta comes from the right ventricle, that sounds right. Okay, point (a) must be true.\n",
      "\n",
      "Now, what about this part with the mitral valve? Usually, it's connected to the left ventricular outflow, which leads to the aortic valve in a normal heart. But if we're talking about transposition of the great vessels, this setup changes a bit, doesn't it? Without other defects like a VSD mixing stuff up, the mitral valve might not be traditionally linked to the aortic valve. So I'm thinking point (b) might actually be false here.\n",
      "\n",
      "When it comes to jaundice, that's usually about liver issues or blood problems, not heart defects. People with transposition often have cyanosis since the blood's not getting properly oxygenated. So, jaundice right after birth doesn't fit with this heart condition. That makes (c) wrong for this context.\n",
      "\n",
      "I guess I should go back over these options. We have that the aorta does arise from the right ventricle, so (a) checks out. Then about the mitral valve and aortic valve being buddies in this situation… it seems they might be not so friendly here, so I was right thinking (b) is more likely false. And finally, jaundice just isn't part of the symptoms mix for transposition, making (c) also false.\n",
      "\n",
      "Alright, let's piece this together. So, option (A) has both bc, which fits since (b) and (c) are the ones to pick out as exceptions here. Yep, this makes sense. The final answer looks like it's (A) bc, considering how the heart anatomy plays out in this condition.\n",
      "In the condition known as transposition of the great vessels, certain anatomical switches take place in the heart. Here's the evaluation of the statements provided:\n",
      "\n",
      "a) **Aorta arises from the right ventricle** - This statement is true in the context of transposition of the great vessels. In this condition, the aorta is indeed connected to the right ventricle instead of the left.\n",
      "\n",
      "b) **Mitral valve is continuous with the aortic valve** - In a heart with transposition of the great vessels, the typical continuity between the mitral valve and the aortic valve is not present as it would be in normal heart anatomy. Therefore, this statement is false in this context.\n",
      "\n",
      "c) **Causes jaundice immediately after birth** - Jaundice is typically related to liver function or blood issues and is not a direct result of heart defects like transposition of the great vessels. The primary concern in this heart condition is cyanosis due to mixing issues with oxygenated and deoxygenated blood, not jaundice. Hence, this statement is also false.\n",
      "\n",
      "Given the analysis, statements (b) and (c) are not true for the condition of transposition of the great vessels. Therefore, the correct answer is:\n",
      "\n",
      "A. bc\n",
      "\n",
      "Base Model Summary: Let's carefully analyze the question:\n",
      "\n",
      "**Question:** In transposition of great vessels, all are true except –  \n",
      "Options:  \n",
      "a) Aorta arises from the right ventricle  \n",
      "b) Mitral valve is continuous with the aortic valve  \n",
      "c) Causes jaundice immediately after birth  \n",
      "d) None of the above  \n",
      "\n",
      "We are to choose the **one that is NOT true** (i.e., the exception).\n",
      "\n",
      "---\n",
      "\n",
      "### Step 1: Understand Transposition of Great Vessels (TGV)\n",
      "\n",
      "Transposition of the great vessels (also known as d-transposition of the great arteries) is a congenital heart defect in which the aorta and pulmonary artery are transposed:\n",
      "\n",
      "- The **aorta arises from the right ventricle** (instead of the left).\n",
      "- The **pulmonary artery arises from the left ventricle** (instead of the right).\n",
      "\n",
      "This results in **separation of oxygenated and deoxygenated blood** — the systemic and pulmonary circulations are not connected, leading to **cyanosis**.\n",
      "\n",
      "---\n",
      "\n",
      "### Evaluate each option:\n",
      "\n",
      "#### a) Aorta arises from the right ventricle  \n",
      "✅ True. This is a defining feature of transposition of great vessels.\n",
      "\n",
      "#### b) Mitral valve is continuous with the aortic valve  \n",
      "❌ This is **not true** in transposition of great vessels.\n",
      "\n",
      "In normal anatomy, the **mitral valve** (bicuspid) is located between the left atrium and left ventricle, and the **aortic valve** is between the left ventricle and aorta. They are **adjacent** and **connected** (the left ventricle is common).\n",
      "\n",
      "In transposition of great vessels, the **left ventricle** is connected to the **pulmonary artery**, and the **right ventricle** to the **aorta**. So, the **mitral valve is still attached to the left ventricle**, and the **aortic valve is attached to the right ventricle**.\n",
      "\n",
      "So, **the mitral valve is NOT continuous with the aortic valve** — they are on opposite sides of the heart and not directly connected.\n",
      "\n",
      "👉 Therefore, **statement b is false**.\n",
      "\n",
      "#### c) Causes jaundice immediately after birth  \n",
      "❌ This is **not accurate**.\n",
      "\n",
      "Jaundice in newborns is often due to **physiological jaundice**, or in some cases, **hemolysis** (e.g., in Rh disease). In transposition of great vessels, **cyanosis** (blue discoloration) occurs due to **de-oxygenated blood** being pumped to the body.\n",
      "\n",
      "But **jaundice** (elevated bilirubin) is **not a hallmark or immediate feature** of TGV.\n",
      "\n",
      "In fact, **jaundice is not typically caused immediately after birth** in TGV. It may occur in other conditions (e.g., hemolytic disease), but **not as a direct result** of transposition.\n",
      "\n",
      "Therefore, **statement c is false**.\n",
      "\n",
      "#### d) None of the above  \n",
      "This would mean **all statements are true**, which is **false** because both **b and c** are false.\n",
      "\n",
      "---\n",
      "\n",
      "So, which one is **not true**?\n",
      "\n",
      "We are to pick the option that says **\"all are true except\"** — i.e., identify the **false** statement(s).\n",
      "\n",
      "Now look at the **answer choices**:\n",
      "\n",
      "> A. bc  \n",
      "> B. c  \n",
      "> C. ac  \n",
      "> D. ad\n",
      "\n",
      "We are to select which **pair (or single)** is the correct exception.\n",
      "\n",
      "We have:\n",
      "\n",
      "- a → true  \n",
      "- b → false  \n",
      "- c → false  \n",
      "- d → false (since \"none of the above\" is incorrect)\n",
      "\n",
      "So, the **false statements** are **b and c**.\n",
      "\n",
      "Therefore, the correct answer should be: **b and c** are false → so the answer is **A. bc**\n",
      "\n",
      "---\n",
      "\n",
      "✅ Final Answer: **A. bc**\n",
      "\n",
      "--- \n",
      "\n",
      "### ✅ Correct Answer: **A**\n",
      "\n",
      "Fine-tuned Model Summary: Alright, let's dive into this question about transposition of great vessels.\n",
      "\n",
      "First, transposition of great vessels is a congenital heart defect where the aorta and pulmonary artery are switched in position. This means the aorta arises from the right ventricle instead of the left, and the pulmonary artery arises from the left ventricle instead of the right.\n",
      "\n",
      "Now, let's break down the options:\n",
      "\n",
      "a) Aorta arises from the right ventricle - This is true in transposition of great vessels. The aorta is connected to the right ventricle, which is a key characteristic of this condition.\n",
      "\n",
      "b) Mitral valve is continuous with the aortic valve - This is also true. In transposition of great vessels, the mitral valve is continuous with the aortic valve, forming a single valve complex.\n",
      "\n",
      "c) Causes jaundice immediately after birth - This is false. Transposition of great vessels doesn't typically cause jaundice immediately after birth. Jaundice is usually associated with other conditions like hemolysis or liver dysfunction.\n",
      "\n",
      "d) None of the above - This is false because option c is false.\n",
      "\n",
      "So, the correct answer is c) Causes jaundice immediately after birth.\n",
      "\n",
      "ROUGE Scores (LightEval):\n",
      "Base Model - ROUGE-1: 0.5915, ROUGE-2: 0.2601, ROUGE-L: 0.2616\n",
      "Fine-tuned - ROUGE-1: 0.4366, ROUGE-2: 0.2396, ROUGE-L: 0.2861\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display example predictions from both models\n",
    "num_examples = min(2, len(dataset))\n",
    "\n",
    "for i in range(num_examples):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Question: {dataset[i]['Question']}\")\n",
    "\n",
    "    ref_cot_answer = '\\n'.join([dataset[i]['Complex_CoT'],dataset[i]['Response']])\n",
    "    print(f\"\\nReference CoT+Answer: {ref_cot_answer}\")\n",
    "    \n",
    "    # Show predictions from both models\n",
    "    print(f\"\\nBase Model Summary: {base_model_results['predictions'][i]}\")\n",
    "    print(f\"\\nFine-tuned Model Summary: {finetuned_model_results['predictions'][i]}\")\n",
    "    \n",
    "    # Calculate ROUGE scores for this example using LightEval\n",
    "    base_rouge = rouge_metrics.compute(golds=[ref_cot_answer], predictions=[base_model_results['predictions'][i]])\n",
    "    finetuned_rouge = rouge_metrics.compute(golds=[ref_cot_answer], predictions=[finetuned_model_results['predictions'][i]])\n",
    "    \n",
    "    print(\"\\nROUGE Scores (LightEval):\")\n",
    "    print(f\"Base Model - ROUGE-1: {base_rouge['rouge1']:.4f}, ROUGE-2: {base_rouge['rouge2']:.4f}, ROUGE-L: {base_rouge['rougeL']:.4f}\")\n",
    "    print(f\"Fine-tuned - ROUGE-1: {finetuned_rouge['rouge1']:.4f}, ROUGE-2: {finetuned_rouge['rouge2']:.4f}, ROUGE-L: {finetuned_rouge['rougeL']:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636dd59d-2ac8-4260-9f38-b84dc06360eb",
   "metadata": {},
   "source": [
    "# Clean Up Endpoints\n",
    "\n",
    "Run the following code to clean up your base endpoint. It is no longer needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7c0442-9a3d-4e2e-ba5c-23e2f3ab5953",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "delete_base_response = sagemaker_client.delete_endpoint(\n",
    "    EndpointName=BASE_ENDPOINT_NAME\n",
    ")\n",
    "\n",
    "print(delete_base_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dadd677-aa8f-494e-9db6-df5d8c25eabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_basecfg_response = sagemaker_client.delete_endpoint_config(\n",
    "    EndpointConfigName=BASE_ENDPOINT_NAME\n",
    ")\n",
    "print(delete_basecfg_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc5ebf7-d70c-4537-808a-9478a3eb88c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
