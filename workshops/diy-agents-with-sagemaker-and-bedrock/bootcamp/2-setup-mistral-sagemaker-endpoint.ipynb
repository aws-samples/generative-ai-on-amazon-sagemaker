{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "586f2662-a568-4c29-af10-7bcb2eadbf30",
   "metadata": {},
   "source": [
    "# Deploying an LLM to Amazon SageMaker AI real-time endpoint\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "To use SageMaker AI endpoints in these examples, you will need to first deploy a managed endpoint. In this example you will deploy an endpoint through SageMaker Jumpstart, a feature that helps machine learning practitioners quickly get started with hundreds of production-ready models in SageMaker AI.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "⚠️ <b>Important:</b> Make sure you've run the <code>1-required-dependencies-strands.ipynb</code> notebook in this folder before proceeding. If you haven't, close this notebook, run the previous one first, then come back to this.\n",
    "</div>\n",
    "\n",
    "## Create Sagemaker Endpoint\n",
    "\n",
    "In this notebook, we first create an endpoint config that defines parameters for the endpoint. Then we specify an inference component that will field our requests. This component will create and kick-off the Sagemaker endpoint after some delay.\n",
    "\n",
    "**NOTE**: In order to deploy a Sagemaker Endpoint on a larger instance type, such as `ml.g5.48xlarge`, you may have to request a quota increase for your account. Please refer to AWS documentation on how to [increase quotas](https://docs.aws.amazon.com/general/latest/gr/sagemaker.html). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f49d687-9592-4d6d-98e6-0e3a191f9fa1",
   "metadata": {},
   "source": [
    "### Run this cell to make sure the Strands Agent libraries are installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2ce612f-74cb-4c44-9483-a019bfa006d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T18:57:12.027566Z",
     "iopub.status.busy": "2025-10-23T18:57:12.027229Z",
     "iopub.status.idle": "2025-10-23T18:57:13.471878Z",
     "shell.execute_reply": "2025-10-23T18:57:13.471110Z",
     "shell.execute_reply.started": "2025-10-23T18:57:12.027543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: strands-agents\n",
      "Version: 1.4.0\n",
      "Summary: A model-driven approach to building AI agents in just a few lines of code\n",
      "Home-page: https://github.com/strands-agents/sdk-python\n",
      "Author: \n",
      "Author-email: AWS <opensource@amazon.com>\n",
      "License: Apache-2.0\n",
      "Location: /opt/conda/lib/python3.12/site-packages\n",
      "Requires: boto3, botocore, docstring-parser, mcp, opentelemetry-api, opentelemetry-instrumentation-threading, opentelemetry-sdk, pydantic, typing-extensions, watchdog\n",
      "Required-by: strands-agents-builder, strands-agents-tools\n",
      "---\n",
      "Name: strands-agents-tools\n",
      "Version: 0.2.12\n",
      "Summary: A collection of specialized tools for Strands Agents\n",
      "Home-page: https://github.com/strands-agents/tools\n",
      "Author: \n",
      "Author-email: AWS <opensource@amazon.com>\n",
      "License: Apache-2.0\n",
      "Location: /opt/conda/lib/python3.12/site-packages\n",
      "Requires: aiohttp, aws-requests-auth, botocore, dill, markdownify, pillow, prompt-toolkit, pyjwt, requests, rich, slack-bolt, strands-agents, sympy, tenacity, typing-extensions, watchdog\n",
      "Required-by: strands-agents-builder\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show strands-agents strands-agents-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35c2bba-157b-49f5-9cf0-aaacf8f6347a",
   "metadata": {},
   "source": [
    "### If Strands Agents libraries do not show above, then install them by running this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3530b42-c71f-4d70-8856-60f8e24603e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T18:57:13.473416Z",
     "iopub.status.busy": "2025-10-23T18:57:13.473098Z",
     "iopub.status.idle": "2025-10-23T18:57:13.476502Z",
     "shell.execute_reply": "2025-10-23T18:57:13.475865Z",
     "shell.execute_reply.started": "2025-10-23T18:57:13.473393Z"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment line below to run pip install\n",
    "# %pip install 'strands-agents[sagemaker]' strands-agents-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e8e0da6-0c35-484b-85dc-0510d0742b8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T18:57:13.477542Z",
     "iopub.status.busy": "2025-10-23T18:57:13.477255Z",
     "iopub.status.idle": "2025-10-23T18:57:15.551862Z",
     "shell.execute_reply": "2025-10-23T18:57:15.551207Z",
     "shell.execute_reply.started": "2025-10-23T18:57:13.477526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "# Setup role and sagemaker session\n",
    "iam_role = get_execution_role()\n",
    "boto_session = boto3.Session(region_name='us-west-2')\n",
    "sagemaker_client = boto_session.client('sagemaker')\n",
    "sagemaker_runtime = boto3.client(\"sagemaker-runtime\") \n",
    "\n",
    "# Names for endpoint config and endpoint\n",
    "endpointName='strands-endpoint-001'\n",
    "endpointConfigName='strands-endpoint-config'\n",
    "inferenceComponentName='mistral-24b-instruct-2501-ic'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bdb040-cb4d-464c-9c58-58c938e5e283",
   "metadata": {},
   "source": [
    "## Delete Resources if they already exist\n",
    "\n",
    "**Note**: If you re-run this notebook, or see failures to create resources, run the next 3 cells to delete previously created resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24591a94-1ff5-4d12-a5ad-f32f75ad84df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code to delete inference component (if exists)\n",
    "sagemaker_client.delete_inference_component(InferenceComponentName=inferenceComponentName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f59cb0-e525-4d3b-b2f7-faa551fa967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this line if the endpoint already exists\n",
    "sagemaker_client.delete_endpoint(EndpointName=endpointName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9185be4a-8252-4951-a0c0-de9de0505112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this line if the endpoint config already exists\n",
    "sagemaker_client.delete_endpoint_config(EndpointConfigName=endpointConfigName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b8cfd4-b13a-4e4b-8dc3-48150f783536",
   "metadata": {},
   "source": [
    "## Create Endpoint Config, Endpoint, and Inference Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d0587aa-3647-44b0-a29b-9ce65239c05b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T18:57:51.765826Z",
     "iopub.status.busy": "2025-10-23T18:57:51.765154Z",
     "iopub.status.idle": "2025-10-23T18:57:52.135235Z",
     "shell.execute_reply": "2025-10-23T18:57:52.134651Z",
     "shell.execute_reply.started": "2025-10-23T18:57:51.765801Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create endpoint config\n",
    "\n",
    "endpoint_config = sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpointConfigName,\n",
    "    EnableNetworkIsolation=False,\n",
    "    ExecutionRoleArn=iam_role,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": 'AllTraffic',\n",
    "            \"InstanceType\": 'ml.g5.48xlarge',\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelDataDownloadTimeoutInSeconds\": 3600,\n",
    "            \"ContainerStartupHealthCheckTimeoutInSeconds\": 3600,\n",
    "            \"ManagedInstanceScaling\": {\n",
    "                \"Status\": \"ENABLED\",\n",
    "                \"MinInstanceCount\": 0,\n",
    "                \"MaxInstanceCount\": 2,\n",
    "            },\n",
    "            \"RoutingConfig\": {\"RoutingStrategy\": \"LEAST_OUTSTANDING_REQUESTS\"},\n",
    "        }\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65f574c2-6b35-4dc1-aeab-b35cf7214794",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T18:57:58.123249Z",
     "iopub.status.busy": "2025-10-23T18:57:58.122746Z",
     "iopub.status.idle": "2025-10-23T18:57:58.634838Z",
     "shell.execute_reply": "2025-10-23T18:57:58.634214Z",
     "shell.execute_reply.started": "2025-10-23T18:57:58.123226Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create endpoint\n",
    "endpoint = sagemaker_client.create_endpoint(\n",
    "    EndpointName=endpointName,\n",
    "    EndpointConfigName=endpointConfigName\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e9a7f7c-429b-47e4-9cdc-b2b57821a7c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T18:58:05.686983Z",
     "iopub.status.busy": "2025-10-23T18:58:05.686464Z",
     "iopub.status.idle": "2025-10-23T18:58:07.044029Z",
     "shell.execute_reply": "2025-10-23T18:58:07.043228Z",
     "shell.execute_reply.started": "2025-10-23T18:58:05.686961Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'huggingface-llm-mistral-small-24B-Instruct-2501' with wildcard version identifier '*'. You can pin to version '3.0.1' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    }
   ],
   "source": [
    "env = {\n",
    "    'ENDPOINT_SERVER_TIMEOUT': '600',\n",
    "    'SM_NUM_GPUS': json.dumps(4),\n",
    "    'MESSAGES_API_ENABLED': 'true'\n",
    "}\n",
    "\n",
    "model = JumpStartModel(\n",
    "    model_id=\"huggingface-llm-mistral-small-24B-Instruct-2501\",\n",
    "    enable_network_isolation=False,\n",
    "    env=env,\n",
    "    role=iam_role\n",
    ")\n",
    "\n",
    "model.create()\n",
    "model_name = model.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cca4816-91d8-4ce0-874a-96ba082585fa",
   "metadata": {},
   "source": [
    "### WAIT up to 5 minutes before creating Inference Component\n",
    "\n",
    "Typically, we need to wait up to 5 minutes for Endpoint creation before creating an Inference Component\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f43aae8f-502f-4ab0-a4fc-fe8fbcbcdd54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T19:08:58.723395Z",
     "iopub.status.busy": "2025-10-23T19:08:58.722664Z",
     "iopub.status.idle": "2025-10-23T19:08:59.327823Z",
     "shell.execute_reply": "2025-10-23T19:08:59.327222Z",
     "shell.execute_reply.started": "2025-10-23T19:08:58.723357Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create inference component\n",
    "\n",
    "mistral_7Bv03_ic = sagemaker_client.create_inference_component(\n",
    "    EndpointName=endpointName,\n",
    "    InferenceComponentName=inferenceComponentName,\n",
    "    RuntimeConfig={\n",
    "        'CopyCount': 1\n",
    "    },\n",
    "    Specification={\n",
    "        'ModelName': model_name,\n",
    "        'StartupParameters': {\n",
    "            'ModelDataDownloadTimeoutInSeconds': 3600,\n",
    "            'ContainerStartupHealthCheckTimeoutInSeconds': 3600\n",
    "        },\n",
    "        'ComputeResourceRequirements': {\n",
    "            'MinMemoryRequiredInMb': 1024,\n",
    "            'NumberOfAcceleratorDevicesRequired': 4,\n",
    "        }\n",
    "    },\n",
    "    Tags=[{\n",
    "        'Key': 'Usage',\n",
    "        'Value': 'Strands Agents'\n",
    "    }],\n",
    "    VariantName=\"AllTraffic\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7440010-016b-4d22-9532-a35426ce2c86",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "⚠️ <b>Note:</b> Deployment of the Sagemaker Endpoint Inference Component can take 5~10 minutes. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1af96d-c8ff-4956-8272-c2bd9b6914cd",
   "metadata": {},
   "source": [
    "## Must WAIT up to 10 minutes for Endpoint AutoScaling to complete\n",
    "\n",
    "**Notice**: If you get this error message below, you must WAIT for the endpoint to complete it's auto-scaling\n",
    "\n",
    "`ValidationError: An error occurred (ValidationError) when calling the InvokeEndpoint operation: Inference Component\n",
    "has no capacity to process this request. ApplicationAutoScaling may be in-progress (if configured) or try to \n",
    "increase the capacity by invoking UpdateInferenceComponentRuntimeConfig API.`\n",
    "\n",
    "If the cell below fails, you can simply retry after waiting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd08268e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T19:17:30.026103Z",
     "iopub.status.busy": "2025-10-23T19:17:30.025372Z",
     "iopub.status.idle": "2025-10-23T19:17:32.901765Z",
     "shell.execute_reply": "2025-10-23T19:17:32.901217Z",
     "shell.execute_reply.started": "2025-10-23T19:17:30.026075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-cfd4211fdae847d7ab0a21cb09e8d295', 'object': 'chat.completion', 'created': 1761247050, 'model': 'lmi', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'reasoning_content': None, 'content': 'The square root of 81 is 9.\\n\\nThe significance of this result is that 9 is the number that, when multiplied by itself, gives 81. In mathematical terms, if \\\\( x^2 = 81 \\\\), then \\\\( x = \\\\sqrt{81} = 9 \\\\). This is a fundamental concept in algebra and arithmetic, demonstrating the relationship between a number and its square root.', 'tool_calls': []}, 'logprobs': None, 'finish_reason': 'stop', 'stop_reason': None}], 'usage': {'prompt_tokens': 33, 'total_tokens': 120, 'completion_tokens': 87, 'prompt_tokens_details': None}, 'prompt_logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant capable of performing math calculations.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Calculate the square root of 81. Briefly explain the significance of the result.\"}\n",
    "]\n",
    "\n",
    "payload = {\n",
    "    \"messages\": messages,\n",
    "    \"max_tokens\": 4000,\n",
    "    \"temperature\": 0.1,\n",
    "    \"top_p\": 0.9,\n",
    "}\n",
    "\n",
    "response_model = sagemaker_runtime.invoke_endpoint(\n",
    "    InferenceComponentName=inferenceComponentName,\n",
    "    EndpointName=endpointName,\n",
    "    Body=json.dumps({\n",
    "      \"messages\": messages,\n",
    "      \"parameters\": {\n",
    "        \"do_sample\": True,\n",
    "        \"max_new_tokens\": 256,\n",
    "      }\n",
    "    }),\n",
    "    ContentType=\"application/json\"\n",
    ")\n",
    "\n",
    "response = json.loads(response_model['Body'].read().decode('utf-8'))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a39f67-2169-4251-abca-49a9c17614fa",
   "metadata": {},
   "source": [
    "### Save names of Endpoint, Endpoint Config, and Inference Component\n",
    "\n",
    "We save various attributes like endpoint name and inference component name using `store` magic command, as they will be needed in later notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18e6de49-11f7-4e36-b7bb-322282a51e53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T19:17:39.004479Z",
     "iopub.status.busy": "2025-10-23T19:17:39.003837Z",
     "iopub.status.idle": "2025-10-23T19:17:39.009923Z",
     "shell.execute_reply": "2025-10-23T19:17:39.009369Z",
     "shell.execute_reply.started": "2025-10-23T19:17:39.004457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name: strands-endpoint-001\n",
      "Endpoint Config Name: strands-endpoint-config\n",
      "Inference Component Name: mistral-24b-instruct-2501-ic\n",
      "Stored 'MISTRAL_ENDPOINT_NAME' (str)\n",
      "Stored 'MISTRAL_ENDPOINT_CONFIG_NAME' (str)\n",
      "Stored 'MISTRAL_INFERENCE_COMPONENT_NAME' (str)\n"
     ]
    }
   ],
   "source": [
    "MISTRAL_ENDPOINT_NAME = endpointName\n",
    "MISTRAL_ENDPOINT_CONFIG_NAME = endpointConfigName\n",
    "MISTRAL_INFERENCE_COMPONENT_NAME = inferenceComponentName\n",
    "\n",
    "print(f\"Endpoint name: {MISTRAL_ENDPOINT_NAME}\")\n",
    "print(f\"Endpoint Config Name: {MISTRAL_ENDPOINT_CONFIG_NAME}\")\n",
    "print(f\"Inference Component Name: {MISTRAL_INFERENCE_COMPONENT_NAME}\")\n",
    "\n",
    "%store MISTRAL_ENDPOINT_NAME\n",
    "%store MISTRAL_ENDPOINT_CONFIG_NAME\n",
    "%store MISTRAL_INFERENCE_COMPONENT_NAME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cf1157-7f7e-4926-aa35-f78f66b1f03b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
