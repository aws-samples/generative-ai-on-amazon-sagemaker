{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "082aa845",
   "metadata": {},
   "source": [
    "# Lab 3: Rag with Amazon SageMaker AI endpoint and Amazon OpenSearch and evaluate RAG with Ragas and Langfuse\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c50906",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook demonstrates how to implement a Retrieval Augmented Generation (RAG) solution using:\n",
    "- Amazon SageMaker for hosting embedding and LLM models\n",
    "- Amazon OpenSearch for vector search\n",
    "- LangChain for orchestrating the RAG pipeline\n",
    "- we'll explore ways to evaluate the quality of Retrieval-Augmented Generation (RAG) pipelines with the opensource tools like [RAGAS](https://docs.ragas.io/en/v0.1.21/index.html) and leverage the features in [Langfuse](https://langfuse.com/) to manage and trace the RAG pipelines with traces and spans. We will create a OpenSearch Vector Database and the RAG results generation to show offline evaluation and scoring.\n",
    "\n",
    "In this notebook, Question Answering solution with Large Language Models (LLMs) and Amazon OpenSearch Service. An application using the RAG(Retrieval Augmented Generation) approach retrieves information most relevant to the user’s request from the enterprise knowledge base or content, bundles it as context along with the user’s request as a prompt, and then sends it to the LLM to get a GenAI response.\n",
    "\n",
    "LLMs have limitations around the maximum word count for the input prompt, therefore choosing the right passages among thousands or millions of documents in the enterprise, has a direct impact on the LLM’s accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d37f81",
   "metadata": {},
   "source": [
    "<H2>Part 1: Build conversational search with OpenSearch Service</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c7b731",
   "metadata": {},
   "source": [
    "The vector dataset used in this part of the lab is comprised of a predefined content resource from the [PubMedQA](https://pubmedqa.github.io/) dataset.\n",
    "\n",
    "You will use OpenSearch ingest pipeline with embedding processor to generate text embeddings for the dataset. Using the neural plugin in OpenSearch will allow you to generate the embeddings of the search query as well.\n",
    "You will then use the large language model (LLM) hosted on Amazon SageMaker endpoints with the RAG processor in the search pipeline to generate text. The RAG processor will combine the retrieved search results from OpenSearch with the generated answer from the LLM to send back to the end user.\n",
    "\n",
    "Follow step 1 to step 5 to complete part 1 of the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853ae065",
   "metadata": {},
   "source": [
    "### The key steps in part 1 of this lab are as follow:\n",
    "\n",
    "1. Get pre-requisites installed and libraries imported.\n",
    "1. Deploy the embedding model to a SageMaker endpoint, create a KNN-enabled index and ingest the catalog items into the index.\n",
    "1. Build the end-to-end pipeline with LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8be245f",
   "metadata": {},
   "source": [
    "# 1. Lab Pre-requisites\n",
    "This notebook is designed to be run as part of the larger workshop [placeholder for workshop].\n",
    "Before proceeding with this notebook, you should complete all of the steps.\n",
    "\n",
    "## Prerequisites\n",
    "- Required Python libraries: opensearch-py, langchain, boto3, requests_aws4auth\n",
    "- Access to Amazon SageMaker and OpenSearch\n",
    "- Appropriate IAM roles and permissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df92a75",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1. Import libraries & initialize resources\n",
    "The code blocks below will install and import all the relevant libraries and modules used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd35fc57",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installs completed.\n"
     ]
    }
   ],
   "source": [
    "!pip install opensearch-py -q\n",
    "!pip install opensearch_py_ml -q\n",
    "!pip install deprecated -q\n",
    "!pip install requests_aws4auth -q\n",
    "!pip install langchain boto3 -q\n",
    "!pip install transformers -q\n",
    "print(\"Installs completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c772362-75ae-47c0-b5f5-be04a2b46f10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install langfuse datasets ragas python-dotenv sagemaker langchain-aws opensearch-py requests_aws4auth boto3 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6689f-68c3-4c39-9b22-52a4c243bd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall packaging -y -q\n",
    "!pip install packaging==24.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fdd173",
   "metadata": {},
   "source": [
    "Import the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d38375",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Python libraries\n",
    "from typing import Any, Dict, List, Optional\n",
    "import boto3\n",
    "import json\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "import os\n",
    "from os import path\n",
    "import urllib.request\n",
    "import tarfile\n",
    "from requests_aws4auth import AWS4Auth\n",
    "from ruamel.yaml import YAML\n",
    "from PIL import Image\n",
    "import base64\n",
    "import re\n",
    "import time as t\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import sys\n",
    "import requests\n",
    "from typing import Dict, List\n",
    "from botocore.response import StreamingBody\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from random import sample\n",
    "from datasets import Dataset\n",
    "\n",
    "# Langchain\n",
    "from langchain_aws.chat_models.sagemaker_endpoint import ChatSagemakerEndpoint, ChatModelContentHandler\n",
    "from langchain_core.messages import HumanMessage, AIMessageChunk, SystemMessage\n",
    "from langchain_aws.embeddings import BedrockEmbeddings\n",
    "from langchain_community.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain_community.embeddings.sagemaker_endpoint import EmbeddingsContentHandler\n",
    "from langchain_community.vectorstores import OpenSearchVectorSearch\n",
    "from langchain_community.llms import SagemakerEndpoint\n",
    "from langchain_community.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler, SagemakerEndpoint\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import Tokenizer\n",
    "\n",
    "# Langfuse\n",
    "import langfuse  # assuming you're using the SDK\n",
    "from langfuse import Langfuse\n",
    "from langfuse.api.resources.commons.types.trace_with_details import TraceWithDetails\n",
    "from langfuse.decorators import observe, langfuse_context\n",
    "\n",
    "# Sagemaker\n",
    "import sagemaker\n",
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# RAGAS\n",
    "import ragas\n",
    "from ragas.run_config import RunConfig\n",
    "from ragas.metrics.base import MetricWithLLM, MetricWithEmbeddings\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import Faithfulness, ResponseRelevancy\n",
    "from ragas.metrics import answer_relevancy, faithfulness, context_precision\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.dataset_schema import SingleTurnSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "314a9721-d612-4701-a4ba-f8b4447a6f46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/20/25 22:29:05] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/20/25 22:29:05]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=862920;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=959883;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=610948;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=37648;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/20/25 22:29:06] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/20/25 22:29:06]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=38999;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=395553;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::626836212174:role/service-role/AmazonSageMaker-ExecutionRole-20220824T222021\n",
      "sagemaker bucket: sagemaker-us-east-1-626836212174\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "    \n",
    "sm_runtime_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed452d3d-d89e-48ad-bdcf-a2c9acacc820",
   "metadata": {},
   "source": [
    "# 2. Deploy the embedding model to a SageMaker endpoint & build retrieval integration with OpenSearch\n",
    "\n",
    "We have taken the PubMedQA dataset and prepared it to include the contexts in the `extracted_context.json` file.\n",
    "\n",
    "The following cells will perform the steps to generate embeddings with the dataset and ingest into the OpenSearch vector database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61449be0-4aae-49e4-81b9-f7cf0ec8379f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.1 Establish a connection to the OpenSearch Service domain\n",
    "\n",
    "### OpenSearch Configuration\n",
    "- Establish connection to OpenSearch domain\n",
    "- Create index with KNN vector search capabilities\n",
    "- Define mapping for document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81c32082-19b3-4f24-8260-d51118f409d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the Amazon OpenSearch Service domain endpoint info from DynamoDB\n",
    "session = boto3.Session()\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = session.region_name\n",
    "\n",
    "aos_host = \"search-opensearchservi-gtmmdbjee3lt-43vqrfek2ekx4ah6sdk3iw3eli.us-east-1.es.amazonaws.com\" # replace with the output opensearch cluster name, you can find it from the cloudformation output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797317a5-f6df-4c08-9a98-b81df5e1a456",
   "metadata": {},
   "source": [
    "### 🚨 Authentication cell below 🚨 \n",
    "The below cell establishes an authenticated connection to our OpenSearch Service domain. The connection will periodically expire.\n",
    "If you see an `AuthorizationException` error later in this notebook it means that the connection has expired and you just need to re-run the cell to get a new security tokken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10616439-4ed6-4faf-8157-da56df28d69a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/20/25 23:25:25] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/20/25 23:25:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=761276;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=729704;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection details: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<OpenSearch([{'host': 'search-opensearchservi-gtmmdbjee3lt-43vqrfek2ekx4ah6sdk3iw3eli.us-east-1.es.amazonaws.com', 'port': 443, 'use_ssl': True}])>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to OpenSearch using the IAM Role of this notebook\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWS4Auth(\n",
    "    credentials.access_key,\n",
    "    credentials.secret_key,\n",
    "    region,\n",
    "    'es',\n",
    "    session_token=credentials.token\n",
    ")\n",
    "\n",
    "# Create OpenSearch client\n",
    "aos_client = OpenSearch(\n",
    "    hosts=[f'https://{aos_host}'],\n",
    "    http_auth=awsauth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    timeout=60\n",
    ")\n",
    "print(\"Connection details: \")\n",
    "aos_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ec7693-3a0b-41c7-b154-fed58a7502ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.2 Create the index with defined mappings.\n",
    "\n",
    "It is important to define the 'knn_vector' fields as without the propper definitions dynamic mapping would type these as simple float fields.\n",
    "\n",
    "A **k-NN (k-Nearest Neighbors)** enabled index is created in OpenSearch to store vector embeddings. The index schema defines:\n",
    "\n",
    "A **knn_vector** field (`context_vector`) for storing embeddings.\n",
    "\n",
    "To learn more about OpenSearch service, you can refer to the [document](https://aws.amazon.com/opensearch-service/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aa795f-c62c-4fb3-9207-af0ffce9029f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Create the k-NN index\n",
    "# Check if the index exists. Delete and recreate if it does. \n",
    "if aos_client.indices.exists(index='opensearch-rag-index'):\n",
    "    print(\"The index exists. Deleting...\")\n",
    "    response = aos_client.indices.delete(index='opensearch-rag-index')\n",
    "    \n",
    "payload = { \n",
    "  \"settings\": {\n",
    "    \"index\": {\n",
    "      \"knn\": True\n",
    "    }\n",
    "  },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"context_vector\": {\n",
    "              \"type\": \"knn_vector\",\n",
    "              \"dimension\": 384,\n",
    "              \"method\": {\n",
    "                \"engine\": \"faiss\",\n",
    "                \"space_type\": \"l2\",\n",
    "                \"name\": \"hnsw\",\n",
    "                \"parameters\": {}\n",
    "              }\n",
    "            },\n",
    "            \"template\": {\n",
    "              \"type\": \"keyword\"\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "}\n",
    "\n",
    "print(\"Creating index...\")\n",
    "response = aos_client.indices.create(index='opensearch-rag-index',body=payload)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7145ba-f124-4294-a518-b2dfa03d2fa9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.3 Create SageMaker Embedding Endpoint\n",
    "A **Hugging Face text embedding model (all-MiniLM-L6-v2)** is deployed via SageMaker JumpStart to a SageMaker real-time endpoint. This model converts text into 384-dimensional vectors for semantic search.\n",
    "### Embedding Model Deployment\n",
    "- Deploy Hugging Face embedding model (all-MiniLM-L6-v2) on SageMaker\n",
    "- Create embedding endpoint for text vectorization\n",
    "- Configure content handlers for model input/output processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e36c86e-8789-44e3-8f30-13e2638bbeb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieve the image uri based on instance type\n",
    "def get_image_uri(instance_type):\n",
    "    key = \"huggingface-tei\" if instance_type.startswith(\"ml.g\") or instance_type.startswith(\"ml.p\") else \"huggingface-tei-cpu\"\n",
    "    return get_huggingface_llm_image_uri(key, version=\"1.4.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6aa8cc50-c774-43c6-8782-ea3c14b1bf06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id, model_version = \"huggingface-textembedding-all-MiniLM-L6-v2\", \"*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b22e77e-24ef-4756-8c1f-59532311dce7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'huggingface-textembedding-all-MiniLM-L6-v2' with wildcard version identifier '*'. You can pin to version '2.0.7' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/18/25 07:26:08] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> Using model <span style=\"color: #008700; text-decoration-color: #008700\">'huggingface-textembedding-all-MiniLM-L6-v2'</span> with wildcard    <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/cache.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cache.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/cache.py#630\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">630</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         version identifier <span style=\"color: #008700; text-decoration-color: #008700\">'*'</span>. You can pin to version <span style=\"color: #008700; text-decoration-color: #008700\">'2.0.7'</span> for more stable    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         results. Note that models may have different input/output signatures      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         after a major version upgrade.                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/18/25 07:26:08]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m Using model \u001b[38;2;0;135;0m'huggingface-textembedding-all-MiniLM-L6-v2'\u001b[0m with wildcard    \u001b]8;id=398885;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/cache.py\u001b\\\u001b[2mcache.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=335168;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/cache.py#630\u001b\\\u001b[2m630\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         version identifier \u001b[38;2;0;135;0m'*'\u001b[0m. You can pin to version \u001b[38;2;0;135;0m'2.0.7'\u001b[0m for more stable    \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         results. Note that models may have different input/output signatures      \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         after a major version upgrade.                                            \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No instance type selected for inference hosting endpoint. Defaulting to ml.g5.xlarge.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/18/25 07:26:09] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> No instance type selected for inference hosting endpoint. Defaulting to   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/factory/model.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/factory/model.py#238\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">238</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         ml.g5.xlarge.                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/18/25 07:26:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m No instance type selected for inference hosting endpoint. Defaulting to   \u001b]8;id=989030;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/factory/model.py\u001b\\\u001b[2mmodel.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=941091;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/factory/model.py#238\u001b\\\u001b[2m238\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         ml.g5.xlarge.                                                             \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = JumpStartModel(model_id=model_id, model_version=model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2168a02-c548-4d83-b83b-f236586c2c75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/18/25 07:26:10] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Defaulting to only available Python version: py310                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/image_uris.py#610\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">610</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/18/25 07:26:10]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Defaulting to only available Python version: py310                   \u001b]8;id=297577;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=509450;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/image_uris.py#610\u001b\\\u001b[2m610\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Defaulting to only supported image scope: gpu.                       <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/image_uris.py#534\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">534</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Defaulting to only supported image scope: gpu.                       \u001b]8;id=329877;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=318688;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/image_uris.py#534\u001b\\\u001b[2m534\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sagemaker config\n",
    "instance_type = \"ml.g5.xlarge\"\n",
    " \n",
    "# create HuggingFaceModel with the image uri\n",
    "emb_model = HuggingFaceModel(\n",
    "  role=role,\n",
    "  image_uri=get_image_uri(instance_type),\n",
    "  model_data=model.model_data['S3DataSource']['S3Uri'],\n",
    "  env={'HF_MODEL_ID': \"/opt/ml/model\"}     # Path to the model in the container\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d5e698-8eb4-4125-8058-98b196f92841",
   "metadata": {
    "tags": []
   },
   "source": [
    "Deploy the model onto a SageMaker endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36119bab-9e34-4283-b904-1e46566009e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/18/25 07:26:15] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name:                                              <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         hf-textembedding-all-minilm-l6-v2-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-04-18-07-26-09-022              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/18/25 07:26:15]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name:                                              \u001b]8;id=467634;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=413933;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         hf-textembedding-all-minilm-l6-v2-\u001b[1;36m2025\u001b[0m-04-18-07-26-09-022              \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#6019\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6019</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         hf-textembedding-all-minilm-l6-v2-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-04-18-07-26-15-099              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=370020;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=772916;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#6019\u001b\\\u001b[2m6019\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         hf-textembedding-all-minilm-l6-v2-\u001b[1;36m2025\u001b[0m-04-18-07-26-15-099              \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/18/25 07:26:16] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name                                            <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4841\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4841</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         hf-textembedding-all-minilm-l6-v2-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-04-18-07-26-15-099              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/18/25 07:26:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name                                            \u001b]8;id=734506;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=987502;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4841\u001b\\\u001b[2m4841\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         hf-textembedding-all-minilm-l6-v2-\u001b[1;36m2025\u001b[0m-04-18-07-26-15-099              \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0aa4299f-c79a-41bc-bf1f-911783db1ec2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully deployed embedding model to the SageMaker endpoint: hf-textembedding-all-minilm-l6-v2-2025-04-18-07-26-15-099\n"
     ]
    }
   ],
   "source": [
    "embed_endpoint_name = predictor.endpoint_name\n",
    "print(f\"Successfully deployed embedding model to the SageMaker endpoint: {embed_endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a0974ac-ab63-4804-84b1-acd8a54960e0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.096046135,0.05919965,0.0036651383,0.08261194,0.04320125,0.06315744,-0.07904435,-0.0029822798,-0.007873776,-0.033055924,-0.0019092165,0.017405923,-0.025697775,0.041194484,0.03704159,-0.014242477,0.035062693,0.075476766,0.0358431,0.033390384,0.052482553,0.008863225,0.12598042,0.019705344,-0.0038323689,-0.02158669,0.0053444128,-0.05546483,0.007539315,-0.022757303,-0.041222353,0.095767416,0.004786977,-0.032721464,0.004104119,-0.06678077,0.0029822798,0.013991631,-0.02232529,0.034365896,0.09654783,-0.03896474,-0.0053862203,-0.053346574,-0.11828781,-0.022617945,-0.016709128,-0.023231125,-0.09838736,0.09409511,0.035118435,-0.029794928,0.010577339,0.060091544,0.011329876,-0.013796528,-0.014897464,0.03503482,0.059422623,0.11550064,-0.03517418,0.08751737,-0.0016514027,-0.02622734,0.09515424,0.13712913,-0.043479968,-0.07893287,0.005225958,0.022590073,-0.055855036,0.00005574355,0.016068079,-0.0049925316,0.015998399,0.0132948365,-0.0063617327,0.009469436,0.08879948,-0.01758709,0.010633082,0.09186537,0.034449514,-0.018172396,0.09041604,-0.07425041,0.034449514,0.015120437,-0.045765452,-0.010040807,0.07291256,-0.024889495,-0.017489538,0.031690206,0.018311756,-0.023314739,-0.04871986,0.000247362,0.02937685,-0.03297231,0.033696976,0.0017454699,0.027356146,0.019022485,-0.031941053,-0.021307971,0.0075880904,-0.056133755,-0.09476403,-0.026004365,0.01761496,0.07207641,0.05320722,0.03798923,0.044148892,-0.022492522,-0.00249104,0.1433724,0.03032449,0.035062693,0.024081213,-0.03372485,0.093649164,-0.017461667,0.011483171,0.051451296,-0.109368846,0.0,0.016207436,-0.0026739484,-0.014075246,0.02920962,-0.0071247225,0.0012472619,-0.09833162,-0.035731614,0.0911407,-0.020917766,-0.047382016,0.055074625,0.028958773,-0.039410688,0.013406323,0.06889903,-0.08328086,0.13445345,-0.039800894,0.041361712,-0.015608193,-0.043396354,0.020443946,0.02639457,-0.04637863,-0.0028150491,-0.022381036,0.008027071,-0.058809444,-0.017475603,0.032777205,-0.019454498,0.03185744,-0.0709058,0.032888696,0.042281482,0.052677654,0.019997997,-0.059924316,-0.0053235088,-0.04693607,0.083894044,-0.0048914966,-0.031272132,0.05214809,0.051757883,0.031160643,-0.036707126,-0.08328086,-0.050280683,-0.04866412,0.027202852,-0.05624524,-0.11048371,-0.0026164628,-0.007901648,0.01084212,-0.06795139,0.027857838,0.027579121,0.051925115,-0.027202852,0.00009755121,-0.053012114,0.004445548,0.03015726,0.026673287,-0.02622734,-0.046768837,-0.030686824,0.014939271,-0.053959753,-0.010263781,0.103237055,-0.022255613,-0.040637046,0.0023725848,-0.0018046974,-0.023245059,-0.07179769,0.08121835,0.020248843,-0.0074626678,-0.06884328,-0.01680668,-0.06276724,-0.04225361,0.09799716,-0.038686022,0.022659753,0.02002587,-0.08211025,0.053959753,-0.003477004,-0.06577739,0.0,-0.11304792,-0.07207641,0.0016548866,-0.13690616,0.044009533,0.023370482,0.07179769,-0.11851078,0.046155658,0.041751917,0.035898846,-0.050224937,-0.035285667,-0.040497687,0.0074835713,-0.052426808,-0.05546483,-0.037599023,-0.021168612,0.01562213,0.07207641,-0.03784987,0.03015726,0.002961376,0.045626096,0.05340232,0.012584106,0.085510604,-0.014995014,-0.05493527,-0.0117061455,-0.035118435,-0.071240254,-0.012723465,0.083503835,-0.03221977,0.0011497107,0.027049556,-0.0034212603,-0.014911399,0.0050099515,0.03578736,-0.074027434,0.032387003,0.07436189,0.03550864,-0.022185933,-0.08673696,0.02622734,-0.04476207,-0.019426627,0.049890477,0.003233126,-0.01992832,-0.10451915,-0.01335058,-0.05705352,-0.06906626,-0.0773163,0.07831968,-0.04102725,0.011747953,-0.079211585,-0.012862824,0.035006948,-0.0017141141,0.026185531,-0.104742125,0.1286561,-0.07993625,0.025572352,-0.1322237,-0.02246465,-0.012848888,0.02009555,-0.047159042,0.04760499,0.021043189,-0.040441945,-0.018395372,-0.03971728,-0.08328086,0.06889903,-0.01548277,-0.093649164,-0.047995195,0.08679271,-0.013796528,0.055241857,0.03171808,-0.06287872,0.016667321,-0.11650401,-0.05139555,0.022966342,-1.3609265e-8,-0.015022886,-0.05011345,0.049751118,0.09615762,-0.053987626,-0.034616742,-0.071351744,-0.01304399,-0.05359742,0.07324702,-0.006588191,-0.06360339,0.06678077,-0.05387614,0.04258807,-0.079490304,-0.010744569,0.113828324,-0.0148417195,0.010235909,0.0025363315,0.050224937,-0.029181749,-0.019677473,0.06159662,0.00043201252,0.0072605973,0.04526376,-0.05579929,-0.069122,0.066557795,0.02480588,0.056468215,0.054461446,-0.031160643,-0.06717098,0.057638828,0.024109084,0.028178364,0.0019022486,-0.02151701,0.018214205,0.022171997,0.07118451,-0.018451115,-0.037292436,-0.007831968,-0.028150491,0.016750935,-0.03249849,0.03798923,-0.021377651,0.028025068,-0.003090283,-0.00058530725,0.06967944,0.0068216166,-0.060203034,-0.036651384,-0.048441146,0.06410508,-0.03235913,-0.06014729,-0.07335851]]\n"
     ]
    }
   ],
   "source": [
    "query_text = \"Is adjustment for reporting heterogeneity necessary in sleep disorders?\"\n",
    "# invoke the embedding model\n",
    "input_str = {\"inputs\": query_text}\n",
    "output = sm_runtime_client.invoke_endpoint(\n",
    "    EndpointName=embed_endpoint_name,\n",
    "    Body=json.dumps(input_str),\n",
    "    ContentType=\"application/json\"\n",
    ")\n",
    "embeddings = output[\"Body\"].read().decode(\"utf-8\")\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dda04dc-9ae0-41b2-b002-99a56ca7ee37",
   "metadata": {},
   "source": [
    "We can wrap up our SageMaker endpoints for embedding model into `langchain.embeddings.SagemakerEndpointEmbeddings` class to make it compatible with SageMaker embedding model and can be use with other LangChain functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0257c6fb-19a1-4add-84f5-f5b78f113f96",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/18/25 07:33:25] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/18/25 07:33:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=927053;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=104658;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      " [0.096046135, 0.05919965, 0.0036651383, 0.08261194, 0.04320125, 0.06315744, -0.07904435, -0.0029822798, -0.007873776, -0.033055924, -0.0019092165, 0.017405923, -0.025697775, 0.041194484, 0.03704159, -0.014242477, 0.035062693, 0.075476766, 0.0358431, 0.033390384, 0.052482553, 0.008863225, 0.12598042, 0.019705344, -0.0038323689, -0.02158669, 0.0053444128, -0.05546483, 0.007539315, -0.022757303, -0.041222353, 0.095767416, 0.004786977, -0.032721464, 0.004104119, -0.06678077, 0.0029822798, 0.013991631, -0.02232529, 0.034365896, 0.09654783, -0.03896474, -0.0053862203, -0.053346574, -0.11828781, -0.022617945, -0.016709128, -0.023231125, -0.09838736, 0.09409511, 0.035118435, -0.029794928, 0.010577339, 0.060091544, 0.011329876, -0.013796528, -0.014897464, 0.03503482, 0.059422623, 0.11550064, -0.03517418, 0.08751737, -0.0016514027, -0.02622734, 0.09515424, 0.13712913, -0.043479968, -0.07893287, 0.005225958, 0.022590073, -0.055855036, 5.574355e-05, 0.016068079, -0.0049925316, 0.015998399, 0.0132948365, -0.0063617327, 0.009469436, 0.08879948, -0.01758709, 0.010633082, 0.09186537, 0.034449514, -0.018172396, 0.09041604, -0.07425041, 0.034449514, 0.015120437, -0.045765452, -0.010040807, 0.07291256, -0.024889495, -0.017489538, 0.031690206, 0.018311756, -0.023314739, -0.04871986, 0.000247362, 0.02937685, -0.03297231, 0.033696976, 0.0017454699, 0.027356146, 0.019022485, -0.031941053, -0.021307971, 0.0075880904, -0.056133755, -0.09476403, -0.026004365, 0.01761496, 0.07207641, 0.05320722, 0.03798923, 0.044148892, -0.022492522, -0.00249104, 0.1433724, 0.03032449, 0.035062693, 0.024081213, -0.03372485, 0.093649164, -0.017461667, 0.011483171, 0.051451296, -0.109368846, 0.0, 0.016207436, -0.0026739484, -0.014075246, 0.02920962, -0.0071247225, 0.0012472619, -0.09833162, -0.035731614, 0.0911407, -0.020917766, -0.047382016, 0.055074625, 0.028958773, -0.039410688, 0.013406323, 0.06889903, -0.08328086, 0.13445345, -0.039800894, 0.041361712, -0.015608193, -0.043396354, 0.020443946, 0.02639457, -0.04637863, -0.0028150491, -0.022381036, 0.008027071, -0.058809444, -0.017475603, 0.032777205, -0.019454498, 0.03185744, -0.0709058, 0.032888696, 0.042281482, 0.052677654, 0.019997997, -0.059924316, -0.0053235088, -0.04693607, 0.083894044, -0.0048914966, -0.031272132, 0.05214809, 0.051757883, 0.031160643, -0.036707126, -0.08328086, -0.050280683, -0.04866412, 0.027202852, -0.05624524, -0.11048371, -0.0026164628, -0.007901648, 0.01084212, -0.06795139, 0.027857838, 0.027579121, 0.051925115, -0.027202852, 9.755121e-05, -0.053012114, 0.004445548, 0.03015726, 0.026673287, -0.02622734, -0.046768837, -0.030686824, 0.014939271, -0.053959753, -0.010263781, 0.103237055, -0.022255613, -0.040637046, 0.0023725848, -0.0018046974, -0.023245059, -0.07179769, 0.08121835, 0.020248843, -0.0074626678, -0.06884328, -0.01680668, -0.06276724, -0.04225361, 0.09799716, -0.038686022, 0.022659753, 0.02002587, -0.08211025, 0.053959753, -0.003477004, -0.06577739, 0.0, -0.11304792, -0.07207641, 0.0016548866, -0.13690616, 0.044009533, 0.023370482, 0.07179769, -0.11851078, 0.046155658, 0.041751917, 0.035898846, -0.050224937, -0.035285667, -0.040497687, 0.0074835713, -0.052426808, -0.05546483, -0.037599023, -0.021168612, 0.01562213, 0.07207641, -0.03784987, 0.03015726, 0.002961376, 0.045626096, 0.05340232, 0.012584106, 0.085510604, -0.014995014, -0.05493527, -0.0117061455, -0.035118435, -0.071240254, -0.012723465, 0.083503835, -0.03221977, 0.0011497107, 0.027049556, -0.0034212603, -0.014911399, 0.0050099515, 0.03578736, -0.074027434, 0.032387003, 0.07436189, 0.03550864, -0.022185933, -0.08673696, 0.02622734, -0.04476207, -0.019426627, 0.049890477, 0.003233126, -0.01992832, -0.10451915, -0.01335058, -0.05705352, -0.06906626, -0.0773163, 0.07831968, -0.04102725, 0.011747953, -0.079211585, -0.012862824, 0.035006948, -0.0017141141, 0.026185531, -0.104742125, 0.1286561, -0.07993625, 0.025572352, -0.1322237, -0.02246465, -0.012848888, 0.02009555, -0.047159042, 0.04760499, 0.021043189, -0.040441945, -0.018395372, -0.03971728, -0.08328086, 0.06889903, -0.01548277, -0.093649164, -0.047995195, 0.08679271, -0.013796528, 0.055241857, 0.03171808, -0.06287872, 0.016667321, -0.11650401, -0.05139555, 0.022966342, -1.3609265e-08, -0.015022886, -0.05011345, 0.049751118, 0.09615762, -0.053987626, -0.034616742, -0.071351744, -0.01304399, -0.05359742, 0.07324702, -0.006588191, -0.06360339, 0.06678077, -0.05387614, 0.04258807, -0.079490304, -0.010744569, 0.113828324, -0.0148417195, 0.010235909, 0.0025363315, 0.050224937, -0.029181749, -0.019677473, 0.06159662, 0.00043201252, 0.0072605973, 0.04526376, -0.05579929, -0.069122, 0.066557795, 0.02480588, 0.056468215, 0.054461446, -0.031160643, -0.06717098, 0.057638828, 0.024109084, 0.028178364, 0.0019022486, -0.02151701, 0.018214205, 0.022171997, 0.07118451, -0.018451115, -0.037292436, -0.007831968, -0.028150491, 0.016750935, -0.03249849, 0.03798923, -0.021377651, 0.028025068, -0.003090283, -0.00058530725, 0.06967944, 0.0068216166, -0.060203034, -0.036651384, -0.048441146, 0.06410508, -0.03235913, -0.06014729, -0.07335851]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ContentHandler(EmbeddingsContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, inputs: list[str], model_kwargs: Dict) -> bytes:\n",
    "        \"\"\"\n",
    "        Transforms the input into bytes that can be consumed by SageMaker endpoint.\n",
    "        Args:\n",
    "            inputs: List of input strings.\n",
    "            model_kwargs: Additional keyword arguments to be passed to the endpoint.\n",
    "        Returns:\n",
    "            The transformed bytes input.\n",
    "        \"\"\"\n",
    "        # Example: inference.py expects a JSON string with a \"inputs\" key:\n",
    "        input_str = json.dumps({\"inputs\": inputs, **model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        Transforms the bytes output from the endpoint into a list of embeddings.\n",
    "        Args:\n",
    "            output: The bytes output from SageMaker endpoint.\n",
    "        Returns:\n",
    "            The transformed output - list of embeddings\n",
    "        Note:\n",
    "            The length of the outer list is the number of input strings.\n",
    "            The length of the inner lists is the embedding dimension.\n",
    "        \"\"\"\n",
    "        # Example: inference.py returns a JSON string with the list of\n",
    "        # embeddings in a \"vectors\" key:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        # print(len(response_json))\n",
    "        return response_json\n",
    "\n",
    "\n",
    "content_handler = ContentHandler()\n",
    "\n",
    "\n",
    "embeddings_function = SagemakerEndpointEmbeddings(\n",
    "    endpoint_name=embed_endpoint_name,\n",
    "    region_name=region,\n",
    "    content_handler=content_handler,\n",
    ")\n",
    "\n",
    "query_result = embeddings_function.embed_query(query_text)\n",
    "print(\"Output:\\n\", query_result, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fc8991-83b2-4ee4-a8e2-fb3fb2dcc9b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.4 Load data into the new index\n",
    "\n",
    "### Data Processing\n",
    "- Load and process input data\n",
    "- Generate embeddings for documents\n",
    "- Index documents with their embeddings in OpenSearch\n",
    "\n",
    "We will use the [bulk API](https://opensearch.org/docs/latest/api-reference/document-apis/bulk/) to load all of the products into our newly created index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83d374d4-4453-4ba9-88fc-45e0b9945071",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/18/25 07:33:29] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/18/25 07:33:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=909935;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=493923;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.096046135,\n",
       " 0.05919965,\n",
       " 0.0036651383,\n",
       " 0.08261194,\n",
       " 0.04320125,\n",
       " 0.06315744,\n",
       " -0.07904435,\n",
       " -0.0029822798,\n",
       " -0.007873776,\n",
       " -0.033055924,\n",
       " -0.0019092165,\n",
       " 0.017405923,\n",
       " -0.025697775,\n",
       " 0.041194484,\n",
       " 0.03704159,\n",
       " -0.014242477,\n",
       " 0.035062693,\n",
       " 0.075476766,\n",
       " 0.0358431,\n",
       " 0.033390384,\n",
       " 0.052482553,\n",
       " 0.008863225,\n",
       " 0.12598042,\n",
       " 0.019705344,\n",
       " -0.0038323689,\n",
       " -0.02158669,\n",
       " 0.0053444128,\n",
       " -0.05546483,\n",
       " 0.007539315,\n",
       " -0.022757303,\n",
       " -0.041222353,\n",
       " 0.095767416,\n",
       " 0.004786977,\n",
       " -0.032721464,\n",
       " 0.004104119,\n",
       " -0.06678077,\n",
       " 0.0029822798,\n",
       " 0.013991631,\n",
       " -0.02232529,\n",
       " 0.034365896,\n",
       " 0.09654783,\n",
       " -0.03896474,\n",
       " -0.0053862203,\n",
       " -0.053346574,\n",
       " -0.11828781,\n",
       " -0.022617945,\n",
       " -0.016709128,\n",
       " -0.023231125,\n",
       " -0.09838736,\n",
       " 0.09409511,\n",
       " 0.035118435,\n",
       " -0.029794928,\n",
       " 0.010577339,\n",
       " 0.060091544,\n",
       " 0.011329876,\n",
       " -0.013796528,\n",
       " -0.014897464,\n",
       " 0.03503482,\n",
       " 0.059422623,\n",
       " 0.11550064,\n",
       " -0.03517418,\n",
       " 0.08751737,\n",
       " -0.0016514027,\n",
       " -0.02622734,\n",
       " 0.09515424,\n",
       " 0.13712913,\n",
       " -0.043479968,\n",
       " -0.07893287,\n",
       " 0.005225958,\n",
       " 0.022590073,\n",
       " -0.055855036,\n",
       " 5.574355e-05,\n",
       " 0.016068079,\n",
       " -0.0049925316,\n",
       " 0.015998399,\n",
       " 0.0132948365,\n",
       " -0.0063617327,\n",
       " 0.009469436,\n",
       " 0.08879948,\n",
       " -0.01758709,\n",
       " 0.010633082,\n",
       " 0.09186537,\n",
       " 0.034449514,\n",
       " -0.018172396,\n",
       " 0.09041604,\n",
       " -0.07425041,\n",
       " 0.034449514,\n",
       " 0.015120437,\n",
       " -0.045765452,\n",
       " -0.010040807,\n",
       " 0.07291256,\n",
       " -0.024889495,\n",
       " -0.017489538,\n",
       " 0.031690206,\n",
       " 0.018311756,\n",
       " -0.023314739,\n",
       " -0.04871986,\n",
       " 0.000247362,\n",
       " 0.02937685,\n",
       " -0.03297231,\n",
       " 0.033696976,\n",
       " 0.0017454699,\n",
       " 0.027356146,\n",
       " 0.019022485,\n",
       " -0.031941053,\n",
       " -0.021307971,\n",
       " 0.0075880904,\n",
       " -0.056133755,\n",
       " -0.09476403,\n",
       " -0.026004365,\n",
       " 0.01761496,\n",
       " 0.07207641,\n",
       " 0.05320722,\n",
       " 0.03798923,\n",
       " 0.044148892,\n",
       " -0.022492522,\n",
       " -0.00249104,\n",
       " 0.1433724,\n",
       " 0.03032449,\n",
       " 0.035062693,\n",
       " 0.024081213,\n",
       " -0.03372485,\n",
       " 0.093649164,\n",
       " -0.017461667,\n",
       " 0.011483171,\n",
       " 0.051451296,\n",
       " -0.109368846,\n",
       " 0.0,\n",
       " 0.016207436,\n",
       " -0.0026739484,\n",
       " -0.014075246,\n",
       " 0.02920962,\n",
       " -0.0071247225,\n",
       " 0.0012472619,\n",
       " -0.09833162,\n",
       " -0.035731614,\n",
       " 0.0911407,\n",
       " -0.020917766,\n",
       " -0.047382016,\n",
       " 0.055074625,\n",
       " 0.028958773,\n",
       " -0.039410688,\n",
       " 0.013406323,\n",
       " 0.06889903,\n",
       " -0.08328086,\n",
       " 0.13445345,\n",
       " -0.039800894,\n",
       " 0.041361712,\n",
       " -0.015608193,\n",
       " -0.043396354,\n",
       " 0.020443946,\n",
       " 0.02639457,\n",
       " -0.04637863,\n",
       " -0.0028150491,\n",
       " -0.022381036,\n",
       " 0.008027071,\n",
       " -0.058809444,\n",
       " -0.017475603,\n",
       " 0.032777205,\n",
       " -0.019454498,\n",
       " 0.03185744,\n",
       " -0.0709058,\n",
       " 0.032888696,\n",
       " 0.042281482,\n",
       " 0.052677654,\n",
       " 0.019997997,\n",
       " -0.059924316,\n",
       " -0.0053235088,\n",
       " -0.04693607,\n",
       " 0.083894044,\n",
       " -0.0048914966,\n",
       " -0.031272132,\n",
       " 0.05214809,\n",
       " 0.051757883,\n",
       " 0.031160643,\n",
       " -0.036707126,\n",
       " -0.08328086,\n",
       " -0.050280683,\n",
       " -0.04866412,\n",
       " 0.027202852,\n",
       " -0.05624524,\n",
       " -0.11048371,\n",
       " -0.0026164628,\n",
       " -0.007901648,\n",
       " 0.01084212,\n",
       " -0.06795139,\n",
       " 0.027857838,\n",
       " 0.027579121,\n",
       " 0.051925115,\n",
       " -0.027202852,\n",
       " 9.755121e-05,\n",
       " -0.053012114,\n",
       " 0.004445548,\n",
       " 0.03015726,\n",
       " 0.026673287,\n",
       " -0.02622734,\n",
       " -0.046768837,\n",
       " -0.030686824,\n",
       " 0.014939271,\n",
       " -0.053959753,\n",
       " -0.010263781,\n",
       " 0.103237055,\n",
       " -0.022255613,\n",
       " -0.040637046,\n",
       " 0.0023725848,\n",
       " -0.0018046974,\n",
       " -0.023245059,\n",
       " -0.07179769,\n",
       " 0.08121835,\n",
       " 0.020248843,\n",
       " -0.0074626678,\n",
       " -0.06884328,\n",
       " -0.01680668,\n",
       " -0.06276724,\n",
       " -0.04225361,\n",
       " 0.09799716,\n",
       " -0.038686022,\n",
       " 0.022659753,\n",
       " 0.02002587,\n",
       " -0.08211025,\n",
       " 0.053959753,\n",
       " -0.003477004,\n",
       " -0.06577739,\n",
       " 0.0,\n",
       " -0.11304792,\n",
       " -0.07207641,\n",
       " 0.0016548866,\n",
       " -0.13690616,\n",
       " 0.044009533,\n",
       " 0.023370482,\n",
       " 0.07179769,\n",
       " -0.11851078,\n",
       " 0.046155658,\n",
       " 0.041751917,\n",
       " 0.035898846,\n",
       " -0.050224937,\n",
       " -0.035285667,\n",
       " -0.040497687,\n",
       " 0.0074835713,\n",
       " -0.052426808,\n",
       " -0.05546483,\n",
       " -0.037599023,\n",
       " -0.021168612,\n",
       " 0.01562213,\n",
       " 0.07207641,\n",
       " -0.03784987,\n",
       " 0.03015726,\n",
       " 0.002961376,\n",
       " 0.045626096,\n",
       " 0.05340232,\n",
       " 0.012584106,\n",
       " 0.085510604,\n",
       " -0.014995014,\n",
       " -0.05493527,\n",
       " -0.0117061455,\n",
       " -0.035118435,\n",
       " -0.071240254,\n",
       " -0.012723465,\n",
       " 0.083503835,\n",
       " -0.03221977,\n",
       " 0.0011497107,\n",
       " 0.027049556,\n",
       " -0.0034212603,\n",
       " -0.014911399,\n",
       " 0.0050099515,\n",
       " 0.03578736,\n",
       " -0.074027434,\n",
       " 0.032387003,\n",
       " 0.07436189,\n",
       " 0.03550864,\n",
       " -0.022185933,\n",
       " -0.08673696,\n",
       " 0.02622734,\n",
       " -0.04476207,\n",
       " -0.019426627,\n",
       " 0.049890477,\n",
       " 0.003233126,\n",
       " -0.01992832,\n",
       " -0.10451915,\n",
       " -0.01335058,\n",
       " -0.05705352,\n",
       " -0.06906626,\n",
       " -0.0773163,\n",
       " 0.07831968,\n",
       " -0.04102725,\n",
       " 0.011747953,\n",
       " -0.079211585,\n",
       " -0.012862824,\n",
       " 0.035006948,\n",
       " -0.0017141141,\n",
       " 0.026185531,\n",
       " -0.104742125,\n",
       " 0.1286561,\n",
       " -0.07993625,\n",
       " 0.025572352,\n",
       " -0.1322237,\n",
       " -0.02246465,\n",
       " -0.012848888,\n",
       " 0.02009555,\n",
       " -0.047159042,\n",
       " 0.04760499,\n",
       " 0.021043189,\n",
       " -0.040441945,\n",
       " -0.018395372,\n",
       " -0.03971728,\n",
       " -0.08328086,\n",
       " 0.06889903,\n",
       " -0.01548277,\n",
       " -0.093649164,\n",
       " -0.047995195,\n",
       " 0.08679271,\n",
       " -0.013796528,\n",
       " 0.055241857,\n",
       " 0.03171808,\n",
       " -0.06287872,\n",
       " 0.016667321,\n",
       " -0.11650401,\n",
       " -0.05139555,\n",
       " 0.022966342,\n",
       " -1.3609265e-08,\n",
       " -0.015022886,\n",
       " -0.05011345,\n",
       " 0.049751118,\n",
       " 0.09615762,\n",
       " -0.053987626,\n",
       " -0.034616742,\n",
       " -0.071351744,\n",
       " -0.01304399,\n",
       " -0.05359742,\n",
       " 0.07324702,\n",
       " -0.006588191,\n",
       " -0.06360339,\n",
       " 0.06678077,\n",
       " -0.05387614,\n",
       " 0.04258807,\n",
       " -0.079490304,\n",
       " -0.010744569,\n",
       " 0.113828324,\n",
       " -0.0148417195,\n",
       " 0.010235909,\n",
       " 0.0025363315,\n",
       " 0.050224937,\n",
       " -0.029181749,\n",
       " -0.019677473,\n",
       " 0.06159662,\n",
       " 0.00043201252,\n",
       " 0.0072605973,\n",
       " 0.04526376,\n",
       " -0.05579929,\n",
       " -0.069122,\n",
       " 0.066557795,\n",
       " 0.02480588,\n",
       " 0.056468215,\n",
       " 0.054461446,\n",
       " -0.031160643,\n",
       " -0.06717098,\n",
       " 0.057638828,\n",
       " 0.024109084,\n",
       " 0.028178364,\n",
       " 0.0019022486,\n",
       " -0.02151701,\n",
       " 0.018214205,\n",
       " 0.022171997,\n",
       " 0.07118451,\n",
       " -0.018451115,\n",
       " -0.037292436,\n",
       " -0.007831968,\n",
       " -0.028150491,\n",
       " 0.016750935,\n",
       " -0.03249849,\n",
       " 0.03798923,\n",
       " -0.021377651,\n",
       " 0.028025068,\n",
       " -0.003090283,\n",
       " -0.00058530725,\n",
       " 0.06967944,\n",
       " 0.0068216166,\n",
       " -0.060203034,\n",
       " -0.036651384,\n",
       " -0.048441146,\n",
       " 0.06410508,\n",
       " -0.03235913,\n",
       " -0.06014729,\n",
       " -0.07335851]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_embedding(text, embed_endpoint_name, model_kwargs=None):\n",
    "    \"\"\"\n",
    "    Call the SageMaker embedding model to embed the given text.\n",
    "    Adjust the payload and response parsing according to your model's API.\n",
    "    \"\"\"\n",
    "    embeddings = SagemakerEndpointEmbeddings(\n",
    "        endpoint_name=embed_endpoint_name,\n",
    "        region_name=region,\n",
    "        content_handler=content_handler,\n",
    "    )\n",
    "\n",
    "    return embeddings.embed_query(text)\n",
    "\n",
    "get_embedding(query_text, embed_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f920811c-b15e-4b58-8699-598cf9992e8e",
   "metadata": {},
   "source": [
    "- **Chunking**: Long documents are split into smaller passages (max 256 tokens) using LangChain's `RecursiveCharacterTextSplitter`.\n",
    "\n",
    "- **Embedding Generation**: Each chunk is converted into a vector using the SageMaker embedding endpoint.\n",
    "\n",
    "- **Bulk Ingestion**: The embeddings and text are indexed into OpenSearch for efficient retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7077fed-8c54-4162-bde5-974713781a75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize tokenizer matching your embedding model (e.g., \"sentence-transformers/all-mpnet-base-v2\")\n",
    "embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(embedding_model_name)\n",
    "\n",
    "# Configure splitter with model-aware tokenization\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=tokenizer,\n",
    "    chunk_size=250,  # 256 - safety buffer\n",
    "    chunk_overlap=10,\n",
    "    separators=[\"\\n\\n\", \"\\n\"],  # FIRST try splitting at paragraphs, then lines\n",
    "    keep_separator=True,  # Preserve paragraph/line breaks in chunks\n",
    "    is_separator_regex=False\n",
    ")\n",
    "\n",
    "def validate_chunk(chunk: str) -> bool:\n",
    "    \"\"\"Ensure chunk doesn't exceed token limit with model's actual tokenization\"\"\"\n",
    "    tokens = tokenizer.encode(chunk, add_special_tokens=True)\n",
    "    return len(tokens) <= 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25960198-b021-4717-80ac-8066c36f67ea",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_filename = \"extracted_context.json\"\n",
    "output_filename = \"output_embedded.jsonl\"  # Line-delimited JSON\n",
    "\n",
    "\n",
    "# Load the input JSON file (mapping IDs to lists of context strings)\n",
    "with open(input_filename, \"r\", encoding=\"utf-8\") as infile:\n",
    "    data = json.load(infile)\n",
    "\n",
    "# Open the output file for writing line-delimited JSON objects\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for key, contexts in data.items():\n",
    "        embeddings = []\n",
    "        all_chunks = []\n",
    "        for ctx_idx, context in enumerate(contexts):\n",
    "                # First attempt: split at paragraphs/lines only\n",
    "                chunks = text_splitter.split_text(context)\n",
    "\n",
    "                # Second pass: check and fix any chunks that still exceed limits\n",
    "                final_chunks = []\n",
    "                for chunk in chunks:\n",
    "                    if validate_chunk(chunk):\n",
    "                        final_chunks.append(chunk)\n",
    "                    else:\n",
    "                        # Force split at sentences ONLY if absolutely necessary\n",
    "                        emergency_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "                            tokenizer=tokenizer,\n",
    "                            chunk_size=250,\n",
    "                            chunk_overlap=50,\n",
    "                            separators=[\". \"],  # Only split sentences when forced\n",
    "                            keep_separator=True\n",
    "                        )\n",
    "                        final_chunks.extend(emergency_splitter.split_text(chunk))\n",
    "\n",
    "                # Embed validated chunks\n",
    "                for chunk_idx, chunk in enumerate(final_chunks):\n",
    "                    if not validate_chunk(chunk):\n",
    "                        continue  # Skip invalid chunks or handle differently\n",
    "\n",
    "                    embedding = get_embedding(chunk, embed_endpoint_name)\n",
    "                    output_obj = {\n",
    "                        \"id\": f\"{key}-{ctx_idx}-{chunk_idx}\",\n",
    "                        \"contexts\": chunk,\n",
    "                        \"context_vector\": embedding\n",
    "                    }\n",
    "                    outfile.write(json.dumps(output_obj) + \"\\n\")\n",
    "\n",
    "print(f\"Embeddings saved to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "365fdfb9-dadb-4635-9624-4ff715508e07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged JSON objects have been saved to merged_output.txt\n"
     ]
    }
   ],
   "source": [
    "# Read all JSON objects from the JSONL file\n",
    "with open(\"output_embedded.jsonl\", \"r\", encoding=\"utf-8\") as infile:\n",
    "    json_objects = [json.loads(line) for line in infile]\n",
    "\n",
    "# Write the objects as a JSON array into a new .txt file\n",
    "with open(\"merged_output.txt\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "    json.dump(json_objects, outfile, indent=4)\n",
    "\n",
    "print(\"Merged JSON objects have been saved to merged_output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64b9818c-929a-418d-970b-3fcb48ac4852",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation complete. Check final_output.txt\n"
     ]
    }
   ],
   "source": [
    "def transform_file(input_filename, output_filename):\n",
    "    # Load the merged file, which is expected to be a JSON array\n",
    "    with open(input_filename, 'r', encoding='utf-8') as infile:\n",
    "        records = json.load(infile)\n",
    "    \n",
    "    with open(output_filename, 'w', encoding='utf-8') as outfile:\n",
    "        # Process each record in the array\n",
    "        for record in records:\n",
    "            contexts = record.get(\"contexts\", [])\n",
    "            vectors = record.get(\"context_vector\", [])\n",
    "            # For each pair of context string and corresponding embedding vector:\n",
    "            # Create a new object without the \"id\" field.\n",
    "            new_obj = {\n",
    "                \"contexts\": contexts,\n",
    "                \"context_vector\": vectors\n",
    "            }\n",
    "            # Write the JSON object as a single line\n",
    "            outfile.write(json.dumps(new_obj) + \"\\n\")\n",
    "\n",
    "transform_file(\"merged_output.txt\", \"final_output_oneline.txt\")\n",
    "print(\"Transformation complete. Check final_output.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8332f3-8a4b-4036-b548-3181e8be0233",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Index TEXT file into index: opensearch-rag-index\n",
    "batch = 0\n",
    "count = 0\n",
    "batch_size = 5\n",
    "body_ = ''\n",
    "action = json.dumps({ 'index': { '_index': 'opensearch-rag-index' } })\n",
    "errors = []\n",
    "with open('final_output_oneline.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        if count > 5000:\n",
    "            break # Use this to run a limited number of items.\n",
    "        body_ = body_ + action + \"\\n\" + line + \"\\n\"\n",
    "        # print(f\"body: {body_}\")\n",
    "        if count % batch_size == 0 and count != 0:\n",
    "            batch+=1\n",
    "            if count % (batch_size*30) == 0:\n",
    "                print(\"Batch: \" + str(batch) + \", count: \" + str(count)+ \", errors: \" + str(len(errors)))\n",
    "            response = aos_client.bulk(\n",
    "                index = 'opensearch-rag-index',\n",
    "                body = body_\n",
    "            )\n",
    "            body_ = ''\n",
    "            if response['errors'] == True:\n",
    "                for item in response['items']:\n",
    "                    if item['index']['status'] != 201:\n",
    "                        errors.append(item['index']['error']) \n",
    "        # print(response)\n",
    "        # break \n",
    "        count += 1\n",
    "if body_ !=\"\":\n",
    "    response = aos_client.bulk(\n",
    "        index = 'opensearch-rag-index',\n",
    "        body = body_\n",
    "    )\n",
    "if response['errors'] == True:\n",
    "    for item in response['items']:\n",
    "        if item['index']['status'] != 201:\n",
    "            errors.append(item['index']['error'])\n",
    "print(\"Last batch: \" + str(batch) + \", documet count: \" + str(count)+ \", errors: \" + str(len(errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7dfdad-d5ec-48f2-8a71-16bfc7700c00",
   "metadata": {},
   "source": [
    "## 2.5 Query OpenSearch Database\n",
    "\n",
    "Once the vectors are ingested into the database, we can run queries to retrieve relevant contexts based on the input query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cb85e3e-5197-448a-b9f6-3aa5100b35c5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/18/25 07:47:05] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/18/25 07:47:05]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=368652;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=70706;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/18/25 07:47:06] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> <span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">POST</span>                                                                       <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py#258\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">258</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://search-opensearchservi-gtmmdbjee3lt-43vqrfek2ekx4ah6sdk3iw3eli.us-</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">east-1.es.amazonaws.com:443/opensearch-rag-index/_search</span>                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/18/25 07:47:06]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m \u001b[1;38;2;215;175;0mPOST\u001b[0m                                                                       \u001b]8;id=407067;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=802312;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py#258\u001b\\\u001b[2m258\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://search-opensearchservi-gtmmdbjee3lt-43vqrfek2ekx4ah6sdk3iw3eli.us-\u001b[0m \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255meast-1.es.amazonaws.com:443/opensearch-rag-index/_search\u001b[0m                   \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Query Results:\n",
      "{'contexts': 'The prevalence of self-reported problems with sleep and energy was 53 %. Without correction of cut-point shifts, age, sex, and the number of comorbidities were significantly associated with a greater severity of sleep-related problems. After correction, age, the number of comorbidities, and regular exercise were significantly associated with a greater severity of sleep-related problems; sex was no longer a significant factor. Compared to the ordered probit model, the CHOPIT model provided two changes with a subtle difference in the magnitude of regression coefficients after correction for reporting heterogeneity.', 'context_vector': [0.088420495, 0.04165407, 0.015496825, 0.1216508, 0.032155547, 0.10311852, -0.011321251, 0.016789436, 0.02392059, 0.025271298, -0.027566047, 0.025067966, -0.039969318, 0.014705281, 0.072386295, -0.0453431, 0.058821123, -0.004709321, -0.001998829, 0.04484929, 0.062510155, 0.034072682, 0.10503565, 0.056148756, 0.06361396, -0.022424646, -0.007330855, -0.034246966, -0.029425086, 0.006561097, -0.028088903, 0.0872586, 0.024283685, -0.050774977, 0.013746715, -0.045052625, -0.01870657, 0.037325997, -0.07651103, 0.023513926, 0.020943224, -0.092254765, 0.0042409305, -0.043687392, -0.04810261, -0.0023473985, -0.0295558, 0.014480163, -0.041363597, 0.09626331, -0.0579497, -0.014255045, -0.023513926, 0.0918481, 0.040956933, -0.05301163, 0.0020405848, -0.013274693, 0.028364854, 0.11752606, -0.07058535, 0.05001974, 0.008953882, 0.0038560515, 0.065705374, 0.11642226, -0.06942345, -0.031138888, -0.021640364, -0.008307576, -0.07081773, -0.103002325, -0.049671173, -0.031313173, -0.0032805486, -0.031138888, 0.056758754, -0.03352078, 0.076162465, -0.02617177, -0.020391323, 0.013085885, -0.009745426, -0.0005405552, 0.07645294, -0.035089344, 0.10602326, 0.06739013, -0.07877674, 0.02014442, 0.02710129, 0.0012109163, 0.023092737, 0.050833073, 0.059314933, 0.0077484124, -0.06419491, -0.02862628, -0.04731833, -0.0077992454, -0.0056206854, 0.051210687, 0.019984659, 0.037006475, -0.010377209, 0.02897485, 0.0051559256, -0.03320126, 0.035786483, 0.00657199, 0.005362889, 0.05449305, 0.0010302775, 0.016542533, 0.02431273, -0.023746306, 0.011829582, 0.11491179, 0.060476832, 0.045168813, -0.004545929, -0.009767211, 0.09370714, -0.08203005, -0.020638227, 0.032446023, -0.056962088, 0.0, 0.056613516, -0.066692986, 0.016949197, 0.045895003, 0.0011001729, -0.03410173, -0.1090442, 0.019432757, 0.081913866, 0.007922697, -0.030441748, -0.040695503, 0.051007356, -0.0069604996, 0.053447343, 0.00073117926, -0.053854007, 0.057455894, -0.021015843, 0.082320526, -0.054347813, -0.039039798, 0.03718076, 0.059721597, -0.0043680132, 0.020318704, -0.0040085507, -0.019011568, -0.07215391, 0.0075741275, -0.03142936, -0.009796259, 0.024864633, -0.07529104, -0.010776611, 0.023455832, 0.065298714, 0.05028117, -0.046127383, -0.057630178, -0.061929204, 0.06105778, 0.026927004, -0.018416096, 0.034769822, -0.07738246, 0.044035964, 0.0119385095, -0.012766363, 0.025343917, -0.0952757, 0.043745488, -0.013652311, -0.061232064, -0.11566702, 0.011205061, 0.042089783, -0.006114492, -0.034798868, 0.032910783, 0.034479346, -0.007908174, 0.006332348, -0.08847859, 0.00018279481, 0.045517385, -0.01590349, -0.06256825, -0.057223514, -0.023789877, -0.021625841, -0.0063287173, 0.037355047, 0.021088462, -0.0073490096, 0.03796504, -0.03967884, -0.04763785, -0.07697579, -0.104048036, 0.1537192, 0.039185036, 0.041131217, -0.09388142, 0.034537442, 0.036309335, -0.06797108, 0.069481544, -0.02500987, 0.0040267054, -0.0175011, -0.05118164, 0.10433851, 0.060651116, 0.015075636, 0.0, -0.13722025, -0.014763376, -0.03142936, -0.048131656, 0.09951663, -0.043542158, 0.04304835, -0.09998139, -0.005675149, -0.012316127, 0.05153021, -0.024472492, -0.025953913, 0.024864633, 0.09661188, -0.011916724, -0.03325935, -0.058559697, -0.03203936, 0.052227348, 0.02454511, -0.02477749, 0.0238044, -0.03029651, 0.0119675575, 0.09434618, 0.033143163, 0.049409743, 0.043774538, -0.046127383, 0.034130774, 0.012228984, -0.083133854, 0.030703174, 0.074651994, -0.04923546, -0.07715008, 0.002741355, -0.014342188, -0.031400315, 0.072328195, 0.061173968, -0.062161583, -0.0071420465, 0.081913866, -0.022511788, -0.032649357, -0.06378824, -0.0072981766, 0.0005845803, 0.015729204, 0.020856082, -0.08214624, 0.008576266, -0.05440591, -0.06413681, -0.048131656, -0.063846335, -0.09475284, 0.0005178619, -0.031022698, 0.059779692, 0.015845394, 0.020623703, 0.062916815, -0.015337064, -0.034072682, -0.11160038, 0.037355047, -0.04386168, 0.02072537, -0.10991562, 0.0304127, 0.03177793, -0.027638666, -0.015961584, 0.027595095, 0.05141402, -0.052459728, 0.03535077, -0.034973152, -0.078892924, 0.07784722, -0.048509274, -0.16336296, -0.040346935, 0.046301667, -0.016469914, 0.014574568, 0.0049961647, -0.07308343, 0.0012227169, -0.08481861, 0.021015843, 0.017544672, -2.8366669e-08, 0.047957372, -0.06378824, 0.039097894, 0.060012072, -0.0067172274, -0.061232064, -0.020507513, -0.05129783, -0.014843257, 0.0044152155, 0.018677523, -0.014690758, 0.024399875, -0.05370877, -0.017791575, -0.101201385, 0.03636743, 0.1411707, -0.006938714, -0.05443496, 0.030935554, -0.03947551, -0.016731342, -0.049903553, 0.022410123, 0.02065275, -0.0049417005, 0.08772336, -0.018285383, -0.03270745, 0.012860767, 0.0304127, 0.089814775, 0.0119239865, -0.03270745, -0.054115433, 0.08743288, 0.016934674, 0.009454952, 0.03270745, 0.016963722, -0.0487707, -0.0014088022, 0.038749322, -0.014654448, -0.023005595, 0.01520635, -0.060476832, 0.05039736, 0.028379377, 0.016324678, 0.02392059, 0.005893005, 0.029149136, -0.02107394, 0.115783215, -0.017515624, -0.022482742, -0.048741654, -0.0963795, 0.07215391, -0.10311852, -0.06878441, -0.030906508]}\n",
      "{'contexts': 'Anchoring vignettes are brief texts describing a hypothetical character who illustrates a certain fixed level of a trait under evaluation. This research uses vignettes to elucidate factors associated with sleep disorders in adult Japanese before and after adjustment for reporting heterogeneity in self-reports. This study also evaluates the need for adjusting for reporting heterogeneity in the management of sleep and energy related problems in Japan.', 'context_vector': [0.05448677, 0.06539357, 0.017162861, 0.11275079, 0.053400815, 0.07563935, 0.044429854, 0.017103842, -0.019016072, -0.018166192, 0.05217321, -0.03989716, -0.0048130373, 0.026535152, 0.05897225, 0.0010483332, 0.03007632, 0.07436453, -0.036615677, 0.028943146, 0.004742214, -0.021542106, 0.13635857, 0.027479464, 0.005347164, 0.015227023, 0.002385862, 0.0041431664, 0.019972188, -0.0040634903, -0.094997734, 0.087632105, -0.0025555429, -0.0039041378, 0.018815406, 0.0028122775, -0.009413605, 0.054203477, -0.06303279, 0.03531725, -0.02474096, -0.033239763, 0.09060668, -0.036072697, -0.042281546, -0.018201604, -0.025449194, -0.0018768191, -0.10151348, 0.078425065, -0.057744645, -0.009277861, -0.006433122, 0.041101158, 0.056564257, 0.03484509, 0.019358385, 0.0017248439, -0.008304039, 0.10585731, -0.0006174912, 0.013090517, -0.0009590663, -0.015238826, 0.084988035, 0.06732941, -0.084610306, 0.01979513, -0.037040617, -0.004783528, -0.05075674, -0.063929886, 0.03231906, 0.027479464, -0.037701637, 0.029981889, -0.008138784, -0.036332384, 0.10595175, -0.030760946, -0.0049458314, 0.056705903, 0.056894764, -0.0026278417, 0.04190382, 0.0212234, 0.07710303, -0.0143181225, -0.013633497, 0.10151348, 0.08380764, -0.009118508, -0.014164672, 0.009077194, 0.015569336, -0.017882898, -0.040180452, -0.024292413, -0.03807936, -0.017587801, 0.067187764, 0.0013190851, 0.091267705, 0.07804734, -0.034986738, -0.03680454, -0.012039972, -0.013680712, -0.040983118, 0.0031752472, -0.06133303, 0.017068429, -0.019322973, 0.006781337, 0.030642908, -0.020208266, 0.028872322, 0.113506235, 0.069123596, 0.042517625, 0.08300498, -0.008540117, 0.1191721, -0.09726408, -0.043131426, -0.007164963, -0.066573955, 0.0, 0.023690414, 0.032130197, -0.021518497, 0.058688957, -0.04853761, -0.032130197, -0.14627385, -0.0050255074, 0.021601126, 0.017198272, -0.06265507, 0.04615322, 0.014625024, -0.03234267, 0.0030572084, 0.029840242, -0.09849168, 0.07389237, -0.04029849, 0.02261626, 0.029061185, 0.004568107, 0.06048315, 0.024717353, -0.09386456, -0.03222463, 0.02180179, -0.060199857, -0.1324869, 0.021813596, 0.020066619, 0.045633852, 0.0209165, -0.09263696, 0.029745812, -0.029344479, 0.07918052, 0.0012312937, -0.041573312, -0.008008942, -0.06303279, 0.042824525, -0.005975721, -0.023938296, 0.026700407, -0.010375623, 0.1006636, -0.010511367, -0.063080005, 0.017387135, -0.10680163, 0.019016072, 0.011018935, -0.08777375, -0.022510024, 0.024504883, 0.06619623, -0.0058193193, -0.05354246, 0.00049760786, 0.011361247, 0.0060111326, -0.05439234, -0.10283552, 0.0013670383, -0.036544856, 0.0066691996, -0.13465881, -0.05014294, -0.017847486, 0.0400152, -0.009932976, -0.011207797, 0.044783972, -0.048773687, -0.06633788, -0.080974706, -0.020408932, -0.057839077, -0.071531594, 0.029580556, 0.016112315, -0.031303924, -0.10774594, 0.03104424, -0.014554201, -0.018319642, 0.029911065, -0.020208266, 0.032012157, 0.06846258, -0.016171334, 0.10670719, -0.037701637, -0.052550934, 0.0, -0.089331865, -0.047404435, -0.018166192, -0.056280963, 0.07729189, -0.025236724, -0.015994275, -0.09953043, -0.012736401, -0.027809972, -0.039661083, -0.09650863, -0.00058355497, -0.007401041, 0.017280899, -0.02495343, -0.0009214414, -0.019747913, -0.03980273, 0.04754608, 0.06473255, -0.06907638, 0.005839976, 0.028022442, 0.019322973, 0.046648987, 0.11237306, 0.01088319, -0.04492562, -0.016761528, 0.0029140862, -0.018779995, -0.035246424, -0.018591132, 0.06860423, -0.02064501, -0.0065629645, -0.039283358, -0.013845967, -0.014943729, 0.0037831478, 0.043768838, 0.014872906, -0.016950391, 0.016560862, -0.021660144, -0.10604618, -0.027432248, -0.03272039, -0.051795483, -0.006173436, -0.01973611, -0.020184658, -0.033900782, -0.13078713, -0.044288207, -0.034325723, -0.07563935, -0.08503525, 0.06921803, 0.021565713, -0.04756969, 0.028022442, -0.029887458, 0.03368831, -0.037961323, 0.076630875, -0.10850139, 0.049670782, -0.028423775, 0.021247009, -0.091739856, -0.018661955, 0.007164963, 0.0068993755, -0.04553942, 0.03146918, -0.008392568, -0.04277731, -0.045374166, -0.030595692, -0.08890692, 0.047333613, -0.059491623, -0.07894444, -0.014412554, 0.04360358, 0.038882025, 0.03477427, 0.017151058, -0.031091455, 0.03484509, -0.17847487, 0.018213408, 0.014601416, -2.305448e-08, 0.004296617, -0.11237306, 0.046908673, 0.031728864, -0.031941336, 0.009136214, -0.012783617, -0.013043302, 0.039401397, 0.060388718, 0.05321195, 0.016820548, 0.041974645, -0.006433122, 0.054628417, -0.07360908, 0.04072343, 0.18640709, -0.03316894, 0.010682523, 0.07342022, 0.032201022, -0.030973416, -0.07346743, -0.00012735295, 0.052645363, -0.03586023, 0.04492562, -0.019913169, -0.023300886, 0.075167194, 0.050520662, 0.077952914, -0.02943891, -0.07903887, -0.01994858, 0.092212014, 0.012169814, -0.009915271, 0.054345123, 0.03125671, -0.020361716, -0.02740864, 0.069737405, -0.038787592, -0.03890563, 0.005536026, 0.014436161, 0.0024670137, -0.010647112, 0.06600737, -0.019334778, 0.028258521, 0.04530334, -0.022380183, 0.07733911, 0.11407282, 0.018579328, -0.033216156, -0.013019694, 0.06067201, -0.002095191, -0.041124765, -0.020444343]}\n",
      "{'contexts': 'Overall, no first night effects were found for most sleep variables. However, total sleep time, sleep efficiency, and stage transitions showed significant time and group interactions (repeated measures ANOVAs, p ≤ 0.05). The RMMA episode index did not differ between the 2 nights, whereas the second night showed significantly higher burst index, bruxism time index, and mean burst duration (repeated measure ANOVAs, p ≤ 0.05). Five patients of 8 in the low frequency group were classified into the moderate-high frequency group on the second night, whereas only one patient in the moderate-high frequency group moved to the low frequency group.', 'context_vector': [0.06937097, -0.034834735, 0.00580952, 0.083698876, 0.015372654, 0.018223312, -0.053849064, 0.023655977, 0.05178943, -0.09420601, -0.047431353, 0.0048244763, 0.013477191, 0.03256615, 0.065311395, -0.0020223248, 0.07516183, 0.032357197, 0.07683342, 0.03226765, 0.05802804, -0.036267523, 0.09145983, 0.008469885, 0.012253349, 0.040148, 0.04504337, -0.0031808708, 0.04035695, -0.07402754, -0.07092316, 0.07301264, 0.034476537, 0.0051528243, -0.020491898, -0.003999875, 0.04035695, 0.051192433, -0.07540063, 0.13718975, 0.044088177, -0.0069624693, 0.03050651, -0.09963868, -0.078146815, -0.040148, 0.010783246, -0.013469729, -0.06716208, 0.07110226, 0.048625346, 0.010656384, 0.0021062775, 0.07820652, 0.07528123, 0.020790396, -0.09080314, 0.019506853, 0.0648935, 0.03910326, -0.07605733, 0.069490366, 0.08160939, -0.02086502, 0.113190494, 0.04331208, -0.08351978, -0.047998503, 0.094325416, 0.025446966, -0.07713192, -0.044506073, 0.02004415, -0.023775376, -0.07749012, -0.013021981, 0.07092316, -0.03384969, 0.041580793, 0.006746058, 0.026387235, -0.04065545, 0.025566366, -0.05740119, 0.00839526, -0.016014425, 0.060117528, 0.070027664, -0.14339851, 0.06113242, 0.07271415, 0.053938616, -0.05164018, 0.006432635, 0.02573054, -0.010357886, -0.06769938, -0.019327754, 0.043521028, -0.027237955, -0.011671278, -0.04167034, 0.045729917, 0.019074032, -0.050893933, -0.026834983, 0.011827989, -0.13241377, -0.052475974, 0.026984232, -0.016417397, 0.10334006, 0.030984107, 0.014111499, 0.050595436, 0.033282544, 0.02889462, 0.11922016, 0.04528217, 0.029491616, 0.07928111, -0.070326164, 0.09247472, -0.14984606, 0.018685983, 0.036566023, -0.08829575, 0.0, -0.0023879851, -0.047610454, -0.087280855, -0.01998445, -0.00041043494, -0.043938927, -0.028790146, 0.05190883, 0.02083517, 0.0069139632, -0.050804384, 0.02977519, 0.0651323, -0.010783246, 0.006313236, 0.079818405, -0.020327725, -0.005675196, -0.09002704, -0.047341805, -0.03650632, 0.05937128, 0.048953697, 0.045700066, -0.026476786, -0.014380148, 0.0040297247, -0.027715553, 0.017954662, -0.006350548, 0.0050744684, -0.01673082, -0.022073938, 0.0033207918, 0.031670652, 0.05310282, 0.050595436, 0.05307297, -0.057042994, -0.039252505, -0.04346133, 0.06931127, -0.063998, -0.02825285, -0.027073782, -0.05468486, -0.03674512, 0.020148626, 0.042386737, 0.014693571, -0.042237487, 0.015626378, -0.035043683, -0.08232579, 0.016536796, 0.03244675, -0.018715834, -0.00041043494, -0.02673051, 0.11002642, -0.025223093, -0.018715834, 0.03707347, -0.03883461, 0.006399054, -0.06847548, -0.0011128384, -0.017148718, -0.046326913, -0.06656509, 0.08411678, -0.046983607, 0.06757998, -0.0042386735, 0.0064587537, -0.031819902, 0.06262491, 0.039521154, -0.053849064, -0.012880195, 0.043819528, -0.05766984, 0.01690992, -0.10142967, -0.0023282855, 0.04495382, -0.014208511, 0.004063306, -0.10220576, -0.016700972, -0.0154472785, -0.04459562, 0.13599576, 0.0064550224, -0.027745403, 0.0, -0.005544603, -0.035670526, 0.015245792, -0.08626597, 0.067042686, 0.046207514, 0.00064736785, -0.018700909, -0.02235751, 0.02664096, 0.10698173, -0.00836541, -0.04981934, -0.03408849, 0.08775845, -0.113190494, 0.025372343, -0.022342587, -0.030282637, 0.056714647, 0.05125213, -0.028208075, -0.025685765, -0.009992225, -0.0241485, 0.016044276, 0.034267586, 0.005279686, -0.031163206, -0.054416213, -0.0046304525, 0.03522278, -0.016641272, 0.041073345, 0.05444606, 0.05486396, -0.02895432, -0.052267026, -0.049132794, -0.022133637, 0.05316252, 0.06656509, -0.008731071, -0.060505573, 0.019626252, 0.023193305, -0.033521343, -0.044177726, -0.0027275267, -0.025805164, 0.020402348, 0.004656571, -0.044028476, -0.03050651, -0.038028665, -0.0804154, 0.025446966, -0.02904387, -0.03056621, 0.08948974, 0.011917538, -0.022730634, -0.087340556, -0.085609265, 0.04522247, 0.0012173128, -0.031521402, -0.08137059, 0.039222658, 0.0065259156, 0.010201174, -0.070087366, -0.015312955, 0.10686234, -0.01928298, -0.022760484, -0.02089487, 0.013559278, -0.06226671, -0.065012895, -0.04489412, -0.10351916, -0.014096575, -0.013335405, -0.084236175, -0.03713317, 0.04187929, -0.07593793, 0.039670404, 0.048297, -0.04337178, -0.006678896, -0.055550504, 0.045789614, 0.014096575, -2.915021e-08, -0.032804947, -0.10554894, -0.0020484435, 0.05961008, 0.011507103, -0.026849909, 0.004634184, 0.016417397, -0.049162645, 0.0087161455, 0.021521715, 0.02171574, 0.12501103, -0.05316252, 0.026312612, -0.02083517, 0.047282107, 0.070087366, 0.05280432, -0.041103195, 0.030775158, -0.01286527, 0.0027237956, -0.059669778, 0.06543079, 0.06966947, 0.026267836, 0.076415524, 0.005772208, -0.08208699, 0.034207888, -0.017297968, 0.057013147, 0.034386985, -0.051729728, -0.019327754, 0.049282044, 0.035730228, 0.004656571, 0.13241377, 0.007458722, -0.060923472, -0.022014238, -0.014999532, -0.0962955, -0.025282793, -0.014469697, -0.04340163, 0.035192933, -0.0069699315, 0.0039551, -0.036446624, -0.015402504, -0.025835015, -0.035730228, 0.072833546, 0.023103757, 0.025835015, 0.060117528, -0.12381703, 0.030655758, -0.040744998, -0.07044556, -0.013365255]}\n",
      "{'contexts': 'Exploratory study in patients with mild to moderate sleep apnoea, limited treatment duration; concomitant hypnotic treatment (35%); lack of correction for multiplicity of testing.', 'context_vector': [0.09549425, 0.027631052, -0.03261336, 0.0413324, -0.04367824, 0.0016361175, 0.013867425, -0.021631522, 0.05933099, 0.010442088, -0.014448695, 0.028565235, 0.0004378982, 0.04077189, -0.01145931, 0.09200663, 0.100725666, 0.042162783, 0.054307163, 0.02229583, 0.052397277, -0.02605332, 0.14141452, 0.043387603, -0.007660299, 0.00022932891, -0.030205244, -0.04795472, -0.0005533736, -0.047788642, -0.1113546, 0.049823083, 9.0904425e-05, -0.01695023, -0.009315879, 0.05393349, -0.053144623, 0.031326264, -0.015341358, 0.093252204, 0.035229072, -0.053061586, -0.07020903, 0.016462378, -0.068174586, -0.032447282, -0.07083182, 0.014915786, -0.012891723, 0.026966745, 0.03493844, -0.03321539, 0.018974291, -0.030018408, 0.0006020289, -0.030703476, -0.09424867, 0.122730866, 0.012268934, 0.06946168, 0.016680354, 0.018818595, -0.017832512, 0.014054262, 0.074817665, 0.10296771, -0.022461908, -0.10894648, 0.039526314, -0.043346085, -0.055345144, -0.0718698, 0.090428896, -0.058998834, -0.023603687, -0.032281205, 0.0271951, -0.079841495, -0.0079301745, -0.005807503, 0.056881353, 0.056881353, -0.02777637, -0.03547819, 0.05318614, 0.0033163491, 0.08108707, 0.034481727, -0.066555336, 0.023022417, 0.10512671, -0.044882294, -0.11376271, -0.042162783, 0.03155462, -0.0047565475, -0.09225574, 0.027402697, -0.06456241, -0.018278845, -0.008231189, 0.05488843, 0.009347018, -0.016026426, -0.07514982, -0.02074924, 0.071039416, -0.12356125, 0.039339475, 0.008791698, -0.03649541, 0.03282096, -0.03769947, 0.03267564, 0.054722354, 0.07689363, -0.046626102, 0.08361974, 0.0081741, 0.07348905, 0.0759802, -0.02663459, 0.114593096, -0.05434868, 0.030641196, -0.026447754, -0.065974064, 0.0, 0.06360747, -0.050362833, -0.055303622, 0.08195897, 0.016939849, 0.027298898, -0.023624446, 0.002940081, 0.03877897, 0.0017710549, -0.03751263, -0.062444933, 0.043761276, -0.034419447, -0.04131164, 0.01362869, -0.01141779, 0.05048739, 0.008900686, -0.004735788, -0.026406234, 0.026530793, -0.0073229554, 0.05281247, -0.08249872, -0.011355511, -0.00050990813, 0.0070375106, -0.0015206421, -0.005833453, -0.0152168, 0.008999295, -0.012196276, 0.0052625635, -0.019732017, 0.0023250773, 0.0479132, 0.026219398, 0.003321539, -0.026240157, -0.09275398, 0.10089175, 0.047248892, 0.04029442, 0.044384066, -0.04131164, 0.01794669, -0.06364899, 0.005615477, 0.0029504609, -0.027942447, -0.014313757, -0.03653693, -0.0763954, -0.07407032, 0.0304336, -0.014116541, -0.032945514, -0.016140603, 0.04895118, 0.044799257, 0.016804911, -0.009694742, -0.10022744, -0.057628702, 0.040668093, -0.042162783, -0.1217344, -0.017573018, -0.0042142025, 0.007717388, -0.100476556, -0.02391508, 0.090428896, -0.016431239, -0.057960857, 0.10529278, 0.06692901, -0.047581047, -0.07228499, 0.08752255, -0.050985623, 0.029873092, 0.011791463, 0.00078691926, -0.024683187, -0.0304336, 0.024911541, -0.030661957, 0.016223641, 0.047996238, 0.011573487, 0.08627698, -0.09333525, 0.0009802432, 0.0, 0.03250956, -0.07622932, 0.012123617, -0.039775427, 0.013379574, 0.04783016, -0.039048843, -0.017645676, -0.019732017, -0.04131164, 0.036744524, -0.034668565, 0.05605097, -0.05326918, -0.0048733205, 0.023811283, -0.01687757, -0.004689079, -0.049324855, 0.08627698, 0.023250774, 0.026074082, 0.008111821, -0.067095086, 0.018278845, 0.025181416, -0.01249729, 0.0217976, 0.050778028, -0.08876813, -0.001684124, -0.029707015, -0.074693106, 0.012206656, 0.03421185, -0.020873796, 0.041104045, 0.047165852, -0.08644305, -0.042640258, 0.05555274, 0.023645205, 0.024807744, -0.079301745, 0.051400814, -0.01141779, -0.03987923, -0.052065123, -0.030869553, -0.0403567, 0.021122912, -0.019420624, -0.016939849, -0.009186131, -0.026904466, -0.04355368, -0.100725666, -0.022129754, -0.009518285, 0.01799859, 0.0018463086, 0.025679648, -0.0316169, 0.055345144, 0.077807054, 0.07996605, 0.0152168, 0.012445391, 0.05600945, -0.010276011, -0.0039417325, -0.084450126, -0.023998119, 0.111188516, 0.0021512154, 0.010167023, -0.012030199, -0.101556055, 0.029707015, -0.060078338, -0.050404355, -0.01905733, -0.056922875, 0.012175516, -0.06510217, -0.042162783, 0.14938621, -0.041104045, 0.025326734, 0.022108994, 0.019161128, -0.018569479, -0.05542818, 0.006694977, 0.06526824, -2.0273065e-08, 0.006736496, -0.08802078, 0.05434868, 0.094082594, 0.0012948812, -0.05227272, -0.005241804, -0.07108093, -0.07892807, -0.021527724, 0.0016153578, -0.042432662, 0.06335836, -0.008594482, 0.021091772, -0.044342544, 0.003217741, 0.113098405, 0.013981603, 0.002357514, -0.09117624, -0.017552257, -0.0025975474, -0.059746183, 0.065974064, 0.08926636, 0.044384066, 0.08461621, -0.01800897, -0.069959916, 0.079135664, -0.003430527, 0.053144623, -0.0038950234, -0.083495185, -0.0048733205, 0.058002375, -0.010026895, -0.014853507, 0.098151475, -0.03263412, -0.058376048, 0.062237337, 0.07228499, -0.024828503, -0.105874054, 0.011936781, -0.0828724, 0.01900543, 0.025845725, 0.09167448, 0.04301393, 0.032426525, -0.014552493, -0.03661997, 0.0099386675, 0.0770597, -0.056881353, -0.036184017, -0.11110548, 0.05326918, -0.010514746, -0.042370383, -0.051857527]}\n",
      "{'contexts': 'Sleep bruxism (SB) is reported to vary in frequency over time. The aim of this study was to assess the first night effect on SB.', 'context_vector': [0.083615206, -0.059542004, 0.028453385, 0.08881445, 0.027937023, 0.063744135, -0.072789386, -0.005101311, 0.031070814, -0.05826, -0.10469706, -0.007117798, 0.055767212, -0.00077064964, 0.07293183, 0.07905697, 0.045760453, -0.029735392, 0.08097997, -0.018535653, 0.0053594927, -0.023752702, 0.043908667, 0.026761852, -0.018606877, 0.024375899, 0.1009935, -0.07154299, 0.0017649825, -0.03087495, -0.07563829, 0.075851955, -0.013648011, -0.04145149, -0.041878827, -0.029557334, 0.0037859208, 0.03675081, -0.073786505, 0.08603677, -0.015936034, -0.04508384, 0.03625225, -0.06028984, -0.05249098, 0.039350428, -0.0071311523, 0.01000676, -0.051315807, 0.10669129, 0.038887482, -0.034667548, 0.034934632, 0.037854757, -0.008795978, -0.021099664, -0.085823104, 0.08055264, 0.063744135, 0.014680737, -0.062212847, 0.07015415, 0.060717177, -0.013594594, 0.061002064, 0.03502366, -0.122289024, -0.057583388, 0.0015368479, 0.0106655685, -0.04657951, -0.027652133, -0.023093894, -0.021473581, -0.039350428, 0.010549832, 0.034934632, -0.0043334435, 0.030447615, 0.034400463, -0.02355684, 0.07563829, 0.04508384, -0.008399803, -0.01212563, -0.016924245, 0.08432743, 0.07684907, -0.10426973, 0.041237824, 0.07051027, -0.028631443, -0.04960647, -0.020209383, 0.015054654, 0.0153484475, -0.08795978, 0.009160994, 0.03742742, -0.051208973, -0.05626577, -0.0205833, -0.00416429, 0.09009645, -0.03299382, 0.05138703, -0.030732507, -0.059613228, 0.010692277, -0.021081857, 0.018046, 0.05797511, -0.005163631, 0.050069414, 0.08097997, 0.01719133, 0.00731366, 0.12656237, 0.039848987, 0.0402051, 0.026120849, -0.05049675, 0.083615206, -0.12656237, -0.047006845, -0.007950211, -0.10184816, 0.0, 0.024518343, -0.057191662, -0.019479351, -0.017271455, -0.01241052, -0.05704922, -0.02526618, 0.043053996, -0.02925464, 0.02624549, -0.0031293384, 0.027491882, 0.101492055, -0.02482104, -0.01937252, 0.050995305, -0.037961587, 0.012446131, -0.06431391, -0.014084248, -0.024233453, 0.042947162, 0.035985164, 0.057547774, -0.11986746, -0.06815992, 0.049535245, 0.00068217795, -0.051814362, -0.0027710001, -0.0024594017, -0.03653714, 0.007193472, -0.01336312, 0.002637458, 0.018099416, 0.115594104, 0.01273102, -0.13703208, -0.08083753, -0.050959695, 0.034560714, -0.0626758, -0.0414871, -0.007411591, -0.012757729, 0.015295031, -0.04308961, 0.019069823, -0.04711368, 0.0024660788, 0.062426515, -0.042484216, -0.055731602, -0.0017694338, 0.019514963, -0.017538538, 0.030501032, -0.0010872559, 0.082689315, 0.011751711, -0.03042981, 0.060076173, -0.0709376, 0.003343006, -0.03824648, 0.015321739, -0.028168496, -0.081905864, -0.0731455, 0.06260457, -0.032121345, 0.020779163, 0.0111730285, -0.014066443, -0.035664663, 0.0671272, 0.046080954, -0.057725832, -0.029842224, 0.023450006, -0.003311846, 0.03137351, -0.033919714, 0.057654608, 0.047719073, -0.08318787, -0.004593851, -0.045190673, 0.005506389, -0.016505813, -0.038317703, 0.09778848, 0.034899022, -0.058366835, 0.0, -0.032352816, -0.075851955, -0.022310447, -0.03099959, 0.031872068, 0.015054654, 0.0035611247, -0.0016881956, -0.015464184, 0.018482236, 0.10590785, 0.006939742, -0.04743418, -0.03999143, 0.08639289, -0.050389916, 0.029681975, -0.027153576, -0.07154299, 0.06826676, 0.01326519, 0.017271455, 0.024714205, -0.115380436, -0.0063788644, 0.058651723, 0.022951448, 0.019924494, -0.032602098, -0.0116270725, -0.0010360647, -0.0081683295, -0.041237824, -0.044336002, 0.05341687, 0.058153167, -0.043730613, -0.019425936, -0.004008491, -0.04543995, -0.026405739, 0.038673814, 0.047006845, -0.067875035, 0.06196357, -0.010238233, -0.059007835, -0.059506394, 0.01006908, 0.023610257, 0.025301792, 0.060930844, -0.05594527, -0.0046695247, -0.04690001, -0.063566074, -0.0462234, 0.0064990525, -0.029610751, 0.0908799, -0.0034587423, 0.08240443, -0.026138656, -0.030501032, 0.058081944, 0.038638204, -0.09999638, -0.009098673, 0.06392219, 0.016158603, 0.058188777, -0.05886539, -0.025444236, 0.19885321, 0.01839321, -0.02010255, 0.0490723, -0.048182018, -0.08097997, 0.019710826, -0.070403434, -0.072789386, 0.019069823, 0.004625011, -0.025871571, -0.12207536, 0.010843624, -0.063031904, 0.07798863, 0.035504412, -0.045012616, -0.025907181, -0.07485484, -0.0013999671, 0.058758557, -1.7388304e-08, -0.05512621, -0.117303446, -0.018962989, 0.08304543, -0.025853766, -0.065738365, 0.065346636, -0.053345647, -0.06103768, -0.06028984, -0.03714253, -0.0010705631, 0.10134961, -0.04219933, 0.013639107, -0.027812384, 0.062355295, 0.05704922, 0.05626577, -0.047719073, 0.060645953, -0.07407139, 0.035077076, -0.043374497, 0.030055892, 0.0140041225, 0.046472676, 0.052099254, -0.022114584, -0.029735392, 0.07004732, 0.027634328, 0.020654524, 0.00782112, 0.04451406, 0.0051858877, 0.051208973, 0.05249098, -0.00414871, 0.10925531, -0.036163222, -0.03821087, -0.05655066, -0.01637227, -0.059577618, -0.040774878, -0.031391315, -0.016140798, 0.045902897, 0.011297668, 0.021064052, -0.001776111, 0.00937466, 0.04348133, -0.012722118, 0.029592946, 0.047505405, -0.044977006, 0.06424269, -0.13304362, 0.031622786, 0.010202622, 0.016728383, -0.045012616]}\n"
     ]
    }
   ],
   "source": [
    "# Your natural language query\n",
    "query_vector = get_embedding(query_text, embed_endpoint_name)\n",
    "\n",
    "# Now, use the embedding in a k-NN query\n",
    "knn_query = {\n",
    "    \"size\": 5,  # adjust how many results you want to retrieve\n",
    "    \"query\": {\n",
    "        \"knn\": {\n",
    "            \"context_vector\": {\n",
    "                \"vector\": query_vector,\n",
    "                \"k\": 5\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response_knn = aos_client.search(\n",
    "    index=\"opensearch-rag-index\",\n",
    "    body=knn_query\n",
    ")\n",
    "\n",
    "print(\"KNN Query Results:\")\n",
    "for hit in response_knn['hits']['hits']:\n",
    "    print(hit['_source'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2a1587-fb44-417a-a4d5-9ed0ca54c8e9",
   "metadata": {},
   "source": [
    "# 3. Build end-to-end RAG pipeline with LLM models hosted on SageMaker AI and LangChain\n",
    "\n",
    "We plan to use document embeddings to fetch the most relevant documents in our document knowledge library and combine them with the prompt that we provide to LLM.\n",
    "\n",
    "To achieve that, we will do following.\n",
    "\n",
    "1. **Generate embedings for each of document in the knowledge library with SageMaker hosted embedding model.**\n",
    "2. **Identify top K most relevant documents based on user query.**\n",
    "    - 2.1 **For a query of your interest, generate the embedding of the query using the same embedding model.**\n",
    "    - 2.2 **Search the indexes of top K most relevant documents in the embedding space using in-memory Faiss search.**\n",
    "    - 2.3 **Use the indexes to retrieve the corresponded documents.**\n",
    "3. **Combine the retrieved documents with prompt and question and send them into SageMaker LLM.**\n",
    "\n",
    "\n",
    "\n",
    "Note: The retrieved document/text should be large enough to contain enough information to answer a question; but small enough to fit into the LLM prompt -- maximum sequence length of 1024 tokens. \n",
    "\n",
    "---\n",
    "To build a simiplied QA application with LangChain, we need: \n",
    "1. Wrap up our SageMaker endpoints for embedding model and LLM into `langchain.embeddings.SagemakerEndpointEmbeddings` and `langchain.llms.sagemaker_endpoint.SagemakerEndpoint`. (We have already created the embedding SageMaker wrapper class in the previous section.\n",
    "2. Prepare the dataset to build the knowledge data base. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e04f987-5478-40b4-be60-a978b7e9164f",
   "metadata": {},
   "source": [
    "Now we need to deploy a **Llama 3.1 8B LLM** onto a SageMaker real-time endpoint and prepare the SageMaker Endpoint class for LangChain integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33c61ebb-c73b-42e6-b6b5-3ebff6e25bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id_llm, model_version = \"meta-textgeneration-llama-3-1-8b-instruct\", \"*\"\n",
    "accept_eula = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e56e839-dc01-4cfe-9212-3e46044b03b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model 'meta-textgeneration-llama-3-1-8b-instruct' requires accepting end-user license agreement (EULA). See https://jumpstart-cache-prod-us-east-1.s3.us-east-1.amazonaws.com/fmhMetadata/eula/llama3_1Eula.txt for terms of use.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/18/25 07:47:10] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Model <span style=\"color: #008700; text-decoration-color: #008700\">'meta-textgeneration-llama-3-1-8b-instruct'</span> requires accepting      <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/utils.py#597\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">597</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         end-user license agreement <span style=\"font-weight: bold\">(</span>EULA<span style=\"font-weight: bold\">)</span>. See                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://jumpstart-cache-prod-us-east-1.s3.us-east-1.amazonaws.com/fmhMeta</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">data/eula/llama3_1Eula.txt</span> for terms of use.                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/18/25 07:47:10]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Model \u001b[38;2;0;135;0m'meta-textgeneration-llama-3-1-8b-instruct'\u001b[0m requires accepting      \u001b]8;id=469954;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=979800;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/utils.py#597\u001b\\\u001b[2m597\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         end-user license agreement \u001b[1m(\u001b[0mEULA\u001b[1m)\u001b[0m. See                                    \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://jumpstart-cache-prod-us-east-1.s3.us-east-1.amazonaws.com/fmhMeta\u001b[0m \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mdata/eula/llama3_1Eula.txt\u001b[0m for terms of use.                              \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'meta-textgeneration-llama-3-1-8b-instruct' with wildcard version identifier '*'. You can pin to version '2.7.2' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> Using model <span style=\"color: #008700; text-decoration-color: #008700\">'meta-textgeneration-llama-3-1-8b-instruct'</span> with wildcard     <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/cache.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cache.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/cache.py#630\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">630</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         version identifier <span style=\"color: #008700; text-decoration-color: #008700\">'*'</span>. You can pin to version <span style=\"color: #008700; text-decoration-color: #008700\">'2.7.2'</span> for more stable    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         results. Note that models may have different input/output signatures      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         after a major version upgrade.                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m Using model \u001b[38;2;0;135;0m'meta-textgeneration-llama-3-1-8b-instruct'\u001b[0m with wildcard     \u001b]8;id=238050;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/cache.py\u001b\\\u001b[2mcache.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=61826;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/cache.py#630\u001b\\\u001b[2m630\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         version identifier \u001b[38;2;0;135;0m'*'\u001b[0m. You can pin to version \u001b[38;2;0;135;0m'2.7.2'\u001b[0m for more stable    \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         results. Note that models may have different input/output signatures      \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         after a major version upgrade.                                            \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No instance type selected for inference hosting endpoint. Defaulting to ml.g5.4xlarge.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> No instance type selected for inference hosting endpoint. Defaulting to   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/factory/model.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/factory/model.py#238\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">238</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         ml.g5.4xlarge.                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m No instance type selected for inference hosting endpoint. Defaulting to   \u001b]8;id=689366;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/factory/model.py\u001b\\\u001b[2mmodel.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=469315;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/jumpstart/factory/model.py#238\u001b\\\u001b[2m238\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         ml.g5.4xlarge.                                                            \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = JumpStartModel(model_id=model_id_llm, model_version=model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbcd3b77-7000-41c4-af67-18f7dcbf83fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/18/25 07:47:12] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name:                                              <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-8b-instruct-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-04-18-07-47-10-864                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/18/25 07:47:12]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name:                                              \u001b]8;id=497912;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=98968;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         llama-\u001b[1;36m3\u001b[0m-\u001b[1;36m1\u001b[0m-8b-instruct-\u001b[1;36m2025\u001b[0m-04-18-07-47-10-864                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/18/25 07:47:13] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#6019\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6019</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-8b-instruct-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-04-18-07-47-12-485                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/18/25 07:47:13]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=818117;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=309474;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#6019\u001b\\\u001b[2m6019\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         llama-\u001b[1;36m3\u001b[0m-\u001b[1;36m1\u001b[0m-8b-instruct-\u001b[1;36m2025\u001b[0m-04-18-07-47-12-485                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name                                            <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4841\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4841</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-8b-instruct-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-04-18-07-47-12-485                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name                                            \u001b]8;id=48550;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=526188;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4841\u001b\\\u001b[2m4841\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         llama-\u001b[1;36m3\u001b[0m-\u001b[1;36m1\u001b[0m-8b-instruct-\u001b[1;36m2025\u001b[0m-04-18-07-47-12-485                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(accept_eula=accept_eula)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714efbb9-200c-462c-8b70-d18ccb2bb499",
   "metadata": {},
   "source": [
    "Invoke the LLM endpoint for a quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07b1b459-3d6b-4372-b29c-5172e2a3a936",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"generated_text\": \" A systematic review and meta-analysis of the effects of sleep disorders on quality of life?\\nA. yes\\nB. A\\nC. A\\nD. B\\nAnswer: A\\nExplanation: To assess the impact of sleep disorders on quality of life (QoL) and to determine whether adjustment for reporting heterogeneity is necessary.\\nA systematic review and meta-analysis of studies examining the relationship between sleep disorders and QoL was conducted. Studies were identified through a comprehensive search of electronic databases. Studies\"}\n"
     ]
    }
   ],
   "source": [
    "llm_endpoint_name = predictor.endpoint_name\n",
    "input_str = { \"inputs\": query_text, \n",
    "            \"parameters\": { \n",
    "                \"max_new_tokens\": 100, \n",
    "                \"top_p\": 0.9, \n",
    "                \"temperature\": 0.6 \n",
    "            }\n",
    "        }\n",
    "output = sm_runtime_client.invoke_endpoint(\n",
    "    EndpointName=llm_endpoint_name,\n",
    "    Body=json.dumps(input_str),\n",
    "    ContentType=\"application/json\"\n",
    ")\n",
    "embeddings = output[\"Body\"].read().decode(\"utf-8\")\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e5c343-08c6-47dd-86a8-4182246413be",
   "metadata": {},
   "source": [
    "Next, we wrap up our SageMaker endpoints for LLM into `langchain.llms.sagemaker_endpoint.SagemakerEndpoint`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10a82c1d-820a-499a-8160-ccacbf86426b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"max_new_tokens\": 100,\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_p\": 0.9\n",
    "}\n",
    "\n",
    "\n",
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs={}) -> bytes:\n",
    "        self.len_prompt = len(prompt)\n",
    "        input_str = json.dumps({\"inputs\": prompt, \"parameters\": {**model_kwargs}})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = output.read()\n",
    "        res = json.loads(response_json)\n",
    "        \n",
    "        ans = res['generated_text']\n",
    "        # print(ans)\n",
    "        return ans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebab516-c724-4433-b7f4-c8785797a413",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24554/4011141004.py:28: LangChainDeprecationWarning: The class `SagemakerEndpoint` was deprecated in LangChain 0.3.16 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-aws package and should be used instead. To use it run `pip install -U :class:`~langchain-aws` and import as `from :class:`~langchain_aws.llms import SagemakerEndpoint``.\n",
      "  sm_llm = SagemakerEndpoint(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/18/25 07:55:15] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/18/25 07:55:15]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=184058;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=130117;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "content_handler = ContentHandler()\n",
    "\n",
    "sm_llm = SagemakerEndpoint(\n",
    "    endpoint_name=llm_endpoint_name,\n",
    "    region_name=region,\n",
    "    model_kwargs=parameters,\n",
    "    content_handler=content_handler,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c8f2eb-7a9c-4de3-a2f1-cd58183950a9",
   "metadata": {},
   "source": [
    "We combine the retrieved documents with prompt and question and send them into SageMaker LLM.\n",
    "\n",
    "We define a customized prompt as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13bbdbe9-79e3-4386-8b81-9d878f68f857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.:\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "opensearch_url = f\"https://{aos_host}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ffe1a9-0e21-42f6-98cc-9b7f98a78674",
   "metadata": {},
   "source": [
    "For this example, we have created the OpenSearch cluster with this user-name and password. But in real application, we suggest you store the user name and password using services that can securely store the value, for example SecretsManager as [shown here](https://github.com/aws-samples/rag-with-amazon-opensearch-and-sagemaker/blob/main/app/opensearch_retriever_llama2.py#L89)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9de73a3-cb00-4e96-9826-9a0d790e9bd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "http_auth = (\"master\", \"ML-Search123!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74602217-4745-4a94-83a4-a27643a67daf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opensearch_vector_search = OpenSearchVectorSearch(\n",
    "    opensearch_url=opensearch_url,\n",
    "    index_name='opensearch-rag-index',\n",
    "    embedding_function=embeddings_function,\n",
    "    http_auth=http_auth\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e1f1c66-7358-41ac-8a88-04a4db8e3d57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = opensearch_vector_search.as_retriever(\n",
    "    search_kwargs={\"k\": 3, \"vector_field\": \"context_vector\", \"text_field\": \"contexts\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5aceb1b-764b-4c33-a80f-9120a0b87d0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain_type_kwargs = {\"prompt\": PROMPT, \"verbose\": True}\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    sm_llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    "    # return_source_documents=True, ## you can uncomment this line to see the detailed retrieved data source\n",
    "    # verbose=True, #DEBUG\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ad5c950-1a5f-4524-a287-908f6a26c11d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24554/1044071870.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  qa(query_text)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/18/25 07:55:26] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> <span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">POST</span>                                                                       <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py#258\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">258</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://search-opensearchservi-gtmmdbjee3lt-43vqrfek2ekx4ah6sdk3iw3eli.us-</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">east-1.es.amazonaws.com:443/opensearch-rag-index/_search</span>                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/18/25 07:55:26]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m \u001b[1;38;2;215;175;0mPOST\u001b[0m                                                                       \u001b]8;id=490954;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=203792;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py#258\u001b\\\u001b[2m258\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://search-opensearchservi-gtmmdbjee3lt-43vqrfek2ekx4ah6sdk3iw3eli.us-\u001b[0m \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255meast-1.es.amazonaws.com:443/opensearch-rag-index/_search\u001b[0m                   \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.:\n",
      "\n",
      "The prevalence of self-reported problems with sleep and energy was 53 %. Without correction of cut-point shifts, age, sex, and the number of comorbidities were significantly associated with a greater severity of sleep-related problems. After correction, age, the number of comorbidities, and regular exercise were significantly associated with a greater severity of sleep-related problems; sex was no longer a significant factor. Compared to the ordered probit model, the CHOPIT model provided two changes with a subtle difference in the magnitude of regression coefficients after correction for reporting heterogeneity.\n",
      "\n",
      "Anchoring vignettes are brief texts describing a hypothetical character who illustrates a certain fixed level of a trait under evaluation. This research uses vignettes to elucidate factors associated with sleep disorders in adult Japanese before and after adjustment for reporting heterogeneity in self-reports. This study also evaluates the need for adjusting for reporting heterogeneity in the management of sleep and energy related problems in Japan.\n",
      "\n",
      "Overall, no first night effects were found for most sleep variables. However, total sleep time, sleep efficiency, and stage transitions showed significant time and group interactions (repeated measures ANOVAs, p ≤ 0.05). The RMMA episode index did not differ between the 2 nights, whereas the second night showed significantly higher burst index, bruxism time index, and mean burst duration (repeated measure ANOVAs, p ≤ 0.05). Five patients of 8 in the low frequency group were classified into the moderate-high frequency group on the second night, whereas only one patient in the moderate-high frequency group moved to the low frequency group.\n",
      "\n",
      "Question: Is adjustment for reporting heterogeneity necessary in sleep disorders?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Is adjustment for reporting heterogeneity necessary in sleep disorders?',\n",
       " 'result': ' Yes, adjustment for reporting heterogeneity is necessary in sleep disorders. The study found that after correction for reporting heterogeneity, age, the number of comorbidities, and regular exercise were significantly associated with a greater severity of sleep-related problems, while sex was no longer a significant factor. This suggests that reporting heterogeneity can affect the results of studies on sleep disorders, and adjustment for it is necessary to get accurate results. Additionally, the study used anchoring vignettes to elucidate factors associated with'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(query_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea2a8bd-3694-4384-9e74-7ad37530b25f",
   "metadata": {},
   "source": [
    "# 📂 Test Evaluation Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cdf824-d977-4709-b552-9a2d46651e5e",
   "metadata": {},
   "source": [
    "Let's begin by setting up the Langfuse API authentication. You need to:\n",
    "- go to https://us.cloud.langfuse.com and sign up so you can create a new account\n",
    "- create a new project\n",
    "- once the project is created, then create the API keys (Secret Key and Public Key)\n",
    "- use these crypto keys and fill the below variables `os.environ[\"LANGFUSE_SECRET_KEY\"]` and `os.environ[\"LANGFUSE_PUBLIC_KEY\"]` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9b2bba-78fb-4998-aeef-cbed6214f0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you already define the environment variables in the .env of the vscode server, please skip the following cell\n",
    "# Define the environment variables for langfuse\n",
    "# You can find those values when you create the API key in Langfuse\n",
    "import os\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"<TODO>\" # Your Langfuse project secret key\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"<TODO>\" # Your Langfuse project public key\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # Langfuse domain\n",
    "\n",
    "# Required Langfuse environment variables\n",
    "required_env_vars = [\n",
    "    \"LANGFUSE_SECRET_KEY\",\n",
    "    \"LANGFUSE_PUBLIC_KEY\",\n",
    "    \"LANGFUSE_HOST\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4cbeecf-1ff1-4032-aecc-5e011d626c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to access Bedrock configuration\n",
    "bedrock = boto3.client(service_name=\"bedrock\", region_name=\"us-east-1\")\n",
    "\n",
    "bedrock_agent_runtime = boto3.client(\n",
    "    service_name=\"bedrock-agent-runtime\", region_name=\"us-east-1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f18ec2af-1907-4f4c-8e48-23f9fc7362b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langfuse has been set up correctly\n",
      "You can access your Langfuse instance at: https://us.cloud.langfuse.com\n"
     ]
    }
   ],
   "source": [
    "# langfuse client\n",
    "langfuse = Langfuse()\n",
    "if langfuse.auth_check():\n",
    "    print(\"Langfuse has been set up correctly\")\n",
    "    print(f\"You can access your Langfuse instance at: {os.environ['LANGFUSE_HOST']}\")\n",
    "else:\n",
    "    print(\n",
    "        \"Credentials not found or invalid. Check your Langfuse API key and host in the .env file.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8d3dfd-e721-4e81-9eb4-61f614cdac9f",
   "metadata": {},
   "source": [
    "Let's load the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c2c9be-3b7d-4be4-9393-a5ce6f6b0212",
   "metadata": {},
   "source": [
    "### 📊 RAGAS Evaluation Metrics\n",
    "\n",
    "We're going to measure the following aspects of a RAG system. These metrics are defined in **[RAGAS]**(https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/):\n",
    "\n",
    "- 🔍 **[Faithfulness](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/faithfulness/)**  \n",
    "  Measures how factually consistent the generated answer is with the retrieved context. It evaluates whether the answer could reasonably be derived from the context.\n",
    "\n",
    "- 🎯 **[Response Relevancy](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/answer_relevance/)**  \n",
    "  Assesses how relevant the generated answer is to the original user query. A high score indicates the answer is on-topic and useful.\n",
    "\n",
    "- 🧠 **[Context Precision](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/context_precision/)**  \n",
    "  Measures how many of the retrieved contexts are truly relevant to answering the question. Precision reflects the \"purity\" of the retrieved chunks.\n",
    "\n",
    "- 📥 **[Context Recall](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/context_recall/)**  \n",
    "  Evaluates how well the retrieved context covers the information needed to answer the question completely. High recall means fewer relevant facts are missed.\n",
    "\n",
    "- 🧬 **[Answer Similarity](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/answer_similarity/)**  \n",
    "  Compares the generated answer to a reference answer (if available), measuring how semantically close they are using embedding-based similarity.\n",
    "\n",
    "- ✅ **[Answer Correctness](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/answer_correctness/)**  \n",
    "  Evaluates whether the generated answer is factually correct and aligns with known ground-truth answers, if such references are available.\n",
    "\n",
    "> 📚 Want to dive deeper into how each metric is computed?  \n",
    "Check out the full [RAGAS metrics documentation](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09e7c109-4ee3-4f44-ad1a-ac35ad925b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import metrics\n",
    "metrics=[\n",
    "        ragas.metrics.answer_relevancy,\n",
    "        ragas.metrics.faithfulness,\n",
    "        ragas.metrics.context_precision,\n",
    "        ragas.metrics.context_recall,\n",
    "        ragas.metrics.answer_similarity,\n",
    "        ragas.metrics.answer_correctness,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9f494c7-6c9a-4691-a6e2-99b7cda1f19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# util function to init Ragas Metrics\n",
    "def init_ragas_metrics(metrics, llm, embedding):\n",
    "    for metric in metrics:\n",
    "        if isinstance(metric, MetricWithLLM):\n",
    "            print(metric.name + \" llm\")\n",
    "            metric.llm = llm\n",
    "        if isinstance(metric, MetricWithEmbeddings):\n",
    "            print(metric.name + \" embedding\")\n",
    "            metric.embeddings = embedding\n",
    "        run_config = RunConfig()\n",
    "        metric.init(run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b67d39-72d2-4bd5-8980-d06c09d798ab",
   "metadata": {},
   "source": [
    "Now we have to initialize the metrics with LLMs and embedding models of your choice. In this example we are going to use the Llama-3-1-8b-instruct model and amazon.titan-embed-text-v1 embedding model, and use the convenience wrappers from the `langchain-aws` library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04689e62-03d1-40d8-b905-11c52600c166",
   "metadata": {},
   "source": [
    "### Creating the Sagemaker Endpoint for Llama 3.1 8b Instruct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ab7e507-81a1-4582-8d3e-55829e528969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-3-1-8b-instruct-2025-04-20-22-17-54-324\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = predictor.endpoint_name\n",
    "print(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58a59383-e8ff-43fe-86e3-acd35f5bd962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/20/25 22:30:52] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/20/25 22:30:52]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=948481;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=902241;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sm = boto3.Session().client('sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "005bbe95-e87a-4f40-88de-2b3a905deecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_content_handler = ContentHandler()\n",
    "\n",
    "chat_llm = SagemakerEndpoint(\n",
    "    endpoint_name=endpoint_name,\n",
    "    client=sm,\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.7,  # Adjust temperature for balanced randomness\n",
    "        \"max_new_tokens\": 1200,  # Ensure sufficient token generation\n",
    "        \"top_p\": 0.95,  # Use nucleus sampling for diversity\n",
    "        \"do_sample\": True  # Enable sampling for generative tasks\n",
    "    },\n",
    "    content_handler=chat_content_handler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4517ee-0764-4ea0-8137-9b296616fa60",
   "metadata": {},
   "source": [
    "### Score with RAGAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536de9a8-26de-4733-8a72-2ff9fb5f702e",
   "metadata": {},
   "source": [
    "## Trace eval results with Langfuse\n",
    "\n",
    "You can use model-based evaluation with Ragas in 2 ways:\n",
    "1. Score every trace: This means you will run the evaluations for each trace item. This gives you much better idea of how each call made to your RAG pipelines is performing, but please be mindful of the cost.\n",
    "\n",
    "2. Score with sampling: In this method we will take random samples of traces on a periodic basis and score them. This brings down the cost and gives you a rough estimate the performance of your app but may miss out on important samples.\n",
    "\n",
    "In this example, we will demonstrate both solutions using prebuilt dataset and a live RAG pipeline with AWS Open Search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5908f17-1d1e-454a-a686-63e1ffedfb1e",
   "metadata": {},
   "source": [
    "### Score every trace\n",
    "\n",
    "Lets take a small example of a single trace and see how you can score that with Ragas. We first define a utility function to score your trace with the metrics you chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ac8b55d-c02e-49ee-bcca-7e3804f683f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def score_with_ragas(query, chunks, answer, metrics):\n",
    "    scores = {}\n",
    "    for metric in metrics:\n",
    "        sample = SingleTurnSample(\n",
    "            user_input=query,\n",
    "            retrieved_contexts=chunks,\n",
    "            response=answer,\n",
    "            reference=chunks[0]\n",
    "        )\n",
    "        print(f\"calculating {metric.name}\")\n",
    "        scores[metric.name] = await metric.single_turn_ascore(sample)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84e8409-7779-44da-9c39-d65eb3bdf762",
   "metadata": {},
   "source": [
    "#### Scoring RAG\n",
    "We have already setup the Open Search Database in the first section, we can now **evaluate** the quality of its results against a test dataset - to help us **optimize** the configuration for high quality and low cost.\n",
    "\n",
    "First, let's load the sample dataset of questions, reference answers, and their source documents (to find more of how to prepare this dataset, please see more details in [this github](https://github.com/aws-samples/llm-evaluation-methodology/blob/main/datasets/Prepare-SQuAD.ipynb)):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0263e4f3-710b-46d5-8490-024233a4be64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>QUESTION</th>\n",
       "      <th>CONTEXTS</th>\n",
       "      <th>LABELS</th>\n",
       "      <th>MESHES</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>reasoning_required_pred</th>\n",
       "      <th>reasoning_free_pred</th>\n",
       "      <th>final_decision</th>\n",
       "      <th>LONG_ANSWER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21645374</td>\n",
       "      <td>Do mitochondria play a role in remodelling lac...</td>\n",
       "      <td>['Programmed cell death (PCD) is the regulated...</td>\n",
       "      <td>['BACKGROUND', 'RESULTS']</td>\n",
       "      <td>['Alismataceae', 'Apoptosis', 'Cell Differenti...</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Results depicted mitochondrial dynamics in viv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16418930</td>\n",
       "      <td>Landolt C and snellen e acuity: differences in...</td>\n",
       "      <td>['Assessment of visual acuity depends on the o...</td>\n",
       "      <td>['BACKGROUND', 'PATIENTS AND METHODS', 'RESULTS']</td>\n",
       "      <td>['Adolescent', 'Adult', 'Aged', 'Aged, 80 and ...</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>Using the charts described, there was only a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9488747</td>\n",
       "      <td>Syncope during bathing in infants, a pediatric...</td>\n",
       "      <td>['Apparent life-threatening events in infants ...</td>\n",
       "      <td>['BACKGROUND', 'CASE REPORTS']</td>\n",
       "      <td>['Baths', 'Histamine', 'Humans', 'Infant', 'Sy...</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>\"Aquagenic maladies\" could be a pediatric form...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17208539</td>\n",
       "      <td>Are the long-term results of the transanal pul...</td>\n",
       "      <td>['The transanal endorectal pull-through (TERPT...</td>\n",
       "      <td>['PURPOSE', 'METHODS', 'RESULTS']</td>\n",
       "      <td>['Child', 'Child, Preschool', 'Colectomy', 'Fe...</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>Our long-term study showed significantly bette...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10808977</td>\n",
       "      <td>Can tailored interventions increase mammograph...</td>\n",
       "      <td>['Telephone counseling and tailored print comm...</td>\n",
       "      <td>['BACKGROUND', 'DESIGN', 'PARTICIPANTS', 'INTE...</td>\n",
       "      <td>['Cost-Benefit Analysis', 'Female', 'Health Ma...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>The effects of the intervention were most pron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23831910</td>\n",
       "      <td>Double balloon enteroscopy: is it efficacious ...</td>\n",
       "      <td>['From March 2007 to January 2011, 88 DBE proc...</td>\n",
       "      <td>['METHODS', 'RESULTS']</td>\n",
       "      <td>['Community Health Centers', 'Double-Balloon E...</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>DBE appears to be equally safe and effective w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26037986</td>\n",
       "      <td>30-Day and 1-year mortality in emergency gener...</td>\n",
       "      <td>['Emergency surgery is associated with poorer ...</td>\n",
       "      <td>['AIMS', 'METHODS', 'RESULTS']</td>\n",
       "      <td>['Adult', 'Age Factors', 'Aged', 'Aged, 80 and...</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>maybe</td>\n",
       "      <td>yes</td>\n",
       "      <td>maybe</td>\n",
       "      <td>Emergency laparotomy carries a high rate of mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26852225</td>\n",
       "      <td>Is adjustment for reporting heterogeneity nece...</td>\n",
       "      <td>['Anchoring vignettes are brief texts describi...</td>\n",
       "      <td>['BACKGROUND', 'METHODS', 'RESULTS']</td>\n",
       "      <td>['Adult', 'Aged', 'Female', 'Health Status Dis...</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>Sleep disorders are common in the general adul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17113061</td>\n",
       "      <td>Do mutations causing low HDL-C promote increas...</td>\n",
       "      <td>['Although observational data support an inver...</td>\n",
       "      <td>['BACKGROUND', 'METHODS', 'RESULTS']</td>\n",
       "      <td>['Cholesterol, HDL', 'Contrast Media', 'Corona...</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>Genetic variants identified in the present stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10966337</td>\n",
       "      <td>A short stay or 23-hour ward in a general and ...</td>\n",
       "      <td>[\"We evaluated the usefulness of a short stay ...</td>\n",
       "      <td>['OBJECTIVE', 'METHODS', 'RESULTS']</td>\n",
       "      <td>['Academic Medical Centers', 'Acute Disease', ...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>This data demonstrates the robust nature of th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           QUESTION  \\\n",
       "0    21645374  Do mitochondria play a role in remodelling lac...   \n",
       "1    16418930  Landolt C and snellen e acuity: differences in...   \n",
       "2     9488747  Syncope during bathing in infants, a pediatric...   \n",
       "3    17208539  Are the long-term results of the transanal pul...   \n",
       "4    10808977  Can tailored interventions increase mammograph...   \n",
       "5    23831910  Double balloon enteroscopy: is it efficacious ...   \n",
       "6    26037986  30-Day and 1-year mortality in emergency gener...   \n",
       "7    26852225  Is adjustment for reporting heterogeneity nece...   \n",
       "8    17113061  Do mutations causing low HDL-C promote increas...   \n",
       "9    10966337  A short stay or 23-hour ward in a general and ...   \n",
       "\n",
       "                                            CONTEXTS  \\\n",
       "0  ['Programmed cell death (PCD) is the regulated...   \n",
       "1  ['Assessment of visual acuity depends on the o...   \n",
       "2  ['Apparent life-threatening events in infants ...   \n",
       "3  ['The transanal endorectal pull-through (TERPT...   \n",
       "4  ['Telephone counseling and tailored print comm...   \n",
       "5  ['From March 2007 to January 2011, 88 DBE proc...   \n",
       "6  ['Emergency surgery is associated with poorer ...   \n",
       "7  ['Anchoring vignettes are brief texts describi...   \n",
       "8  ['Although observational data support an inver...   \n",
       "9  [\"We evaluated the usefulness of a short stay ...   \n",
       "\n",
       "                                              LABELS  \\\n",
       "0                          ['BACKGROUND', 'RESULTS']   \n",
       "1  ['BACKGROUND', 'PATIENTS AND METHODS', 'RESULTS']   \n",
       "2                     ['BACKGROUND', 'CASE REPORTS']   \n",
       "3                  ['PURPOSE', 'METHODS', 'RESULTS']   \n",
       "4  ['BACKGROUND', 'DESIGN', 'PARTICIPANTS', 'INTE...   \n",
       "5                             ['METHODS', 'RESULTS']   \n",
       "6                     ['AIMS', 'METHODS', 'RESULTS']   \n",
       "7               ['BACKGROUND', 'METHODS', 'RESULTS']   \n",
       "8               ['BACKGROUND', 'METHODS', 'RESULTS']   \n",
       "9                ['OBJECTIVE', 'METHODS', 'RESULTS']   \n",
       "\n",
       "                                              MESHES    YEAR  \\\n",
       "0  ['Alismataceae', 'Apoptosis', 'Cell Differenti...  2011.0   \n",
       "1  ['Adolescent', 'Adult', 'Aged', 'Aged, 80 and ...  2006.0   \n",
       "2  ['Baths', 'Histamine', 'Humans', 'Infant', 'Sy...  1997.0   \n",
       "3  ['Child', 'Child, Preschool', 'Colectomy', 'Fe...  2007.0   \n",
       "4  ['Cost-Benefit Analysis', 'Female', 'Health Ma...  2000.0   \n",
       "5  ['Community Health Centers', 'Double-Balloon E...  2013.0   \n",
       "6  ['Adult', 'Age Factors', 'Aged', 'Aged, 80 and...  2015.0   \n",
       "7  ['Adult', 'Aged', 'Female', 'Health Status Dis...  2016.0   \n",
       "8  ['Cholesterol, HDL', 'Contrast Media', 'Corona...  2007.0   \n",
       "9  ['Academic Medical Centers', 'Acute Disease', ...  2000.0   \n",
       "\n",
       "  reasoning_required_pred reasoning_free_pred final_decision  \\\n",
       "0                     yes                 yes            yes   \n",
       "1                      no                  no             no   \n",
       "2                     yes                 yes            yes   \n",
       "3                     yes                  no             no   \n",
       "4                     yes                  no            yes   \n",
       "5                     yes                 yes            yes   \n",
       "6                   maybe                 yes          maybe   \n",
       "7                     yes                  no             no   \n",
       "8                      no                  no             no   \n",
       "9                     yes                 yes            yes   \n",
       "\n",
       "                                         LONG_ANSWER  \n",
       "0  Results depicted mitochondrial dynamics in viv...  \n",
       "1  Using the charts described, there was only a s...  \n",
       "2  \"Aquagenic maladies\" could be a pediatric form...  \n",
       "3  Our long-term study showed significantly bette...  \n",
       "4  The effects of the intervention were most pron...  \n",
       "5  DBE appears to be equally safe and effective w...  \n",
       "6  Emergency laparotomy carries a high rate of mo...  \n",
       "7  Sleep disorders are common in the general adul...  \n",
       "8  Genetic variants identified in the present stu...  \n",
       "9  This data demonstrates the robust nature of th...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset_df = pd.read_csv(\"ori_pqal_10_records.csv\")\n",
    "dataset_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068445b5-befc-4157-adf8-23d6a7cfddeb",
   "metadata": {},
   "source": [
    "Records in this dataset include:\n",
    "\n",
    "- (`doc`) The full text of the source document for this example\n",
    "- (`doc_id`) A unique identifier for the source document\n",
    "- (`question`) The user question to be asked\n",
    "- (`question_id`) A unique identifier for the question\n",
    "- (`answers`) A list of (possibly multiple) reference 'correct' answers, supported by the document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314689a5-54b0-4571-b5d8-de6c4d0b807e",
   "metadata": {},
   "source": [
    "As shown in [Ragas' API Reference](https://docs.ragas.io/en/latest/references/evaluation.html), records in Ragas evaluation datasets typically include:\n",
    "\n",
    "- The `question` that was asked\n",
    "- The `answer` the system generated\n",
    "- The actual text `contexts` the answer was based on (i.e. snippets of document text retrieved by the search engine)\n",
    "- The `ground_truth` answer(s)\n",
    "\n",
    "Here we will integrate [Langfuse Tracking](https://langfuse.com/docs/tracing) into the RAG pipeline with the Langfuse Python SDK using the `@observe()` decorator.\n",
    "\n",
    "We can run an example question through the OpenSearch Vector database to retrieve and generate pipeline as shown below, and extract the references ready to calculate metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d216917-725b-4751-be5f-eb8f4d88117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bedrock Runtime\n",
    "bedrock_runtime = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\")\n",
    "\n",
    "@observe(name=\"OpenSearch RAG with Llama\")\n",
    "def retrieve_and_generate(\n",
    "    question: str,\n",
    "    top_k: int = 3,\n",
    "    system_prompt: str = \"You are a helpful assistant. Use the context to answer concisely.\",\n",
    "    **kwargs,\n",
    "):\n",
    "    # Step 1: Retrieve relevant context from OpenSearch\n",
    "    response = aos_client.search(\n",
    "        index=\"documents\",\n",
    "        body={\n",
    "            \"query\": {\n",
    "                \"match\": {\n",
    "                    \"content\": {\n",
    "                        \"query\": question\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        size=top_k\n",
    "    )\n",
    "    \n",
    "    hits = response[\"hits\"][\"hits\"]\n",
    "    contexts = [hit[\"_source\"][\"content\"] for hit in hits]\n",
    "    doc_ids = [hit[\"_id\"] for hit in hits]\n",
    "\n",
    "    # Step 2: Format prompt with retrieved context\n",
    "    combined_context = \"\\n\\n\".join(contexts)\n",
    "    full_prompt = f\"\"\"Context:\n",
    "{combined_context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    # Step 3: Call your SageMaker-hosted model using LangChain\n",
    "    messages: List = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=full_prompt)\n",
    "    ]\n",
    "    \n",
    "    response_chunk = chat_llm.invoke(messages)\n",
    "    answer = response_chunk  # already joined by your handler\n",
    "\n",
    "    # Step 4: Log trace to Langfuse\n",
    "    langfuse_context.update_current_observation(\n",
    "        input={\"question\": question, \"contexts\": contexts},\n",
    "        output=answer,\n",
    "        model=endpoint_name,\n",
    "        session_id=\"opensearch-rag-session\",\n",
    "        tags=[\"dev\", \"qwen\", \"opensearch\"],\n",
    "        metadata=kwargs,\n",
    "    )\n",
    "\n",
    "    trace_id = langfuse_context.get_current_trace_id()\n",
    "\n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"retrieved_doc_ids\": doc_ids,\n",
    "        \"retrieved_doc_texts\": contexts[:300],\n",
    "        \"trace_id\": trace_id,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15856376-f58a-47c0-a90b-5a2b9d2247e2",
   "metadata": {},
   "source": [
    "Run RAG as requests come in and score the results immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5af56b8a-9f82-4b7e-abb2-b22b94605fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from asyncio import run\n",
    "\n",
    "#langfuse\n",
    "langfuse_client = Langfuse()  # picks up env vars: LANGFUSE_PUBLIC_KEY, SECRET_KEY, HOST\n",
    "\n",
    "\n",
    "@observe(name=\"OpenSearch, Llama, Langfuse Pipeline\")\n",
    "def rag_pipeline(\n",
    "    question: str,\n",
    "    user_id: Optional[str] = None,\n",
    "    session_id: Optional[str] = None,\n",
    "    metrics: Optional[Any] = None,\n",
    "):\n",
    "    generated_answer = retrieve_and_generate(\n",
    "        question=question,\n",
    "        top_k=3,  # or whatever makes sense for your context window\n",
    "        system_prompt=\"You are a helpful assistant. Use the context below to answer the question.\"\n",
    "    )\n",
    "\n",
    "    answer = generated_answer[\"answer\"]\n",
    "    contexts = generated_answer[\"retrieved_doc_texts\"]\n",
    "    trace_id = generated_answer[\"trace_id\"]\n",
    "\n",
    "    \n",
    "    metrics=[\n",
    "            # A looot of metrics to give a general overview:\n",
    "            #ragas.metrics.answer_relevancy,\n",
    "            #ragas.metrics.faithfulness,\n",
    "            #ragas.metrics.context_precision,\n",
    "            #ragas.metrics.context_recall,\n",
    "            ragas.metrics.answer_similarity,\n",
    "            #ragas.metrics.answer_correctness,\n",
    "        ]\n",
    "\n",
    "\n",
    "    score = run(score_with_ragas(question, contexts, answer=answer, metrics=metrics))\n",
    "\n",
    "    langfuse_context.update_current_trace(\n",
    "        user_id=user_id,\n",
    "        session_id=session_id,\n",
    "        tags=[\"dev\", \"opensearch\", \"llama\"]\n",
    "    )\n",
    "\n",
    "    for s in score:\n",
    "        langfuse_client.score(name=s, value=score[s])\n",
    "\n",
    "\n",
    "    print(f\"🔗 Langfuse trace: https://cloud.langfuse.com/trace/{trace_id}\")\n",
    "\n",
    "    return trace_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24403a4-6b9c-4d8f-b5ed-ed40da41a09d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for index, row in dataset_df[[\"QUESTION\"]].iterrows():\n",
    "    #print(row[\"QUESTION\"])\n",
    "    response = rag_pipeline(\n",
    "        question=row[\"QUESTION\"],\n",
    "        user_id=\"AWSome-\"+str(index),\n",
    "        session_id=\"llama-test-session-\"+str(index)\n",
    "    )\n",
    "    print(f\"🔗 Langfuse trace for question {str(index)}: https://cloud.langfuse.com/trace/{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebd2a4f-b04a-41ed-a5a1-0ace23c39c59",
   "metadata": {},
   "source": [
    "![](images/LangfuseTraces.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ce200f-b73f-441a-864a-769eb3254cd7",
   "metadata": {},
   "source": [
    "### Key Workflow Summary\n",
    "- Data Preparation: Text is split into chunks and embedded.\n",
    "- OpenSearch Setup: A vector index is created and populated.\n",
    "- Model Deployment: Embedding and LLM models are hosted on SageMaker.\n",
    "- RAG Pipeline: Queries retrieve relevant context, and the LLM generates answers.\n",
    "- Use AWS Bedrock, Radas, and Langfuse to evaluate and score RAG workflows\n",
    "\n",
    "This notebook provides an end-to-end example of building a production-ready RAG system using AWS services. The same approach can be adapted for other domains by replacing the dataset and fine-tuning the models.\n",
    "\n",
    "# Congratulations for finishing Lab 3. Now please continue on to the next Lab."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
