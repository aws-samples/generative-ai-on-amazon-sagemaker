{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad38f5fa-4fe6-47c0-9a72-bfe84ea3e01e",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #FFDDDD; border-left: 5px solid red; padding: 10px; color: black;\">\n",
    "    <strong>Kernel: Python 3 (ipykernel)</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dbf00e-a289-4ed1-9efe-4c9ab3c5b11a",
   "metadata": {},
   "source": [
    "# Enhance Text Summarization with Human Feedback using SageMaker Ground Truth\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Downloading the samsum Hugging Face dataset](#Downloading-the-samsum-Hugging-Face-Dataset)\n",
    "3. [Convert to Ground Truth Input Manifest format](#Adding-a-unique-ID-and-converting-to-GroundTruth-format)\n",
    "4. [Upload the Input Manifest to S3](#Uploading-the-Input-Manifest-to-S3)\n",
    "5. [Run a Ground Truth labeling job](#Run-a-Ground-Truth-labeling-job)\n",
    "    1. [Create the instruction template](#Create-A-Worker-Task-Template)\n",
    "    2. [Submit the Labeling Job](#Submit-the-Ground-Truth-job-request)\n",
    "6. [Integrate Human Feedback into dataset](#Integrate-Human-Feedback-into-samsum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5d5117",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we will walk through a practical example of enriching a text dataset using Reinforcement Learning with Human Feedback (RLHF) using [SageMaker Ground Truth](https://aws.amazon.com/sagemaker/groundtruth/). We will start with the [samsum dataset](https://huggingface.co/datasets/Samsung/samsum) from Hugging Face for instruction-based fine-tuning with human feedback. You will begin by downloading the dataset, which consists of conversational dialogues and summaries. From there, you will enrich each data record by inserting a unique task ID that will help track each item during the human feedback process. Finally, you will convert the dataset into a format compatible with Amazon SageMaker Ground Truth [input manifest format](https://docs.aws.amazon.com/sagemaker/latest/dg/sms-input-data-input-manifest.html) to ensure it can be used for human annotation tasks. By the end of this section, you will have a fully prepared dataset that can be sent to Ground Truth for collecting human feedback on the summarization tasks.\n",
    "\n",
    "Amazon SageMaker Ground Truth provides labeling workflows for humans to work on image and text classification, object detection, and semantic segmentation labeling jobs. You can also build custom workflows to define the user interface (UI) for data labeling jobs.\n",
    "\n",
    "To help you get started, Amazon SageMaker provides [custom templates](https://github.com/aws-samples/amazon-sagemaker-ground-truth-task-uis/tree/master) for image, text, and audio data labeling jobs. These templates use the Amazon SageMaker Ground Truth crowd HTML elements, which simplify building data labeling UIs. You can also specify your own HTML for the UI.\n",
    "\n",
    "By the end of this notebook, you'll have a workflow for creating a refined dataset that combines machine-generated summaries with human insights, potentially leading to more effective and context-aware summarization models. Let's dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242da1f4",
   "metadata": {},
   "source": [
    "### Get latest version of AWS python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c834f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -Uq awscli==1.35.7\n",
    "%pip install -Uq boto3==1.35.29\n",
    "%pip install -Uq sagemaker==2.232.1\n",
    "%pip install -Uq py7zr==0.22.0\n",
    "%pip install -Uq datasets==2.21.0\n",
    "\n",
    "# NOTE: Restart Kernel after the above command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf859ab8-2d1d-41b2-8121-12bad4361f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#temp fix for a bug in SM Studio with ffspec-2023 not being properly updated\n",
    "export SITE_PACKAGES_FOLDER=$(python3 -c \"import sysconfig; print(sysconfig.get_paths()['purelib'])\")\n",
    "rm -rf $SITE_PACKAGES_FOLDER/fsspec-2023*\n",
    "\n",
    "echo \"ffspec-2023 bug fix run successfully\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d2a895",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "import random\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import datetime\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435c9378",
   "metadata": {},
   "source": [
    "### Pre-requisites\n",
    "\n",
    "Before we begin our data processing journey, we will create some of the resources you need to launch a Ground Truth labeling job in this notebook. \n",
    "\n",
    "A work team - A work team is a group of workers that complete labeling tasks. To create a private workforce in SageMaker Ground Truth, start by navigating to the SageMaker console and selecting Ground Truth from the menu. From there, click on Labeling Workforces and choose the Private tab to set up a private workforce. Next, create a new private work team by following the prompts and adding yourself as a member of this team. After creating the team, you will receive an email invite to join the labeling portal. Follow the instructions in the email to register, giving you access to the portal where you can begin labeling tasks. See [Create a Private Workforce](https://docs.aws.amazon.com/sagemaker/latest/dg/sms-workforce-create-private.html)\n",
    "\n",
    "Finally, be sure to fetch the Work Team ARN for your private workforce and paste it into the cell displayed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb000b7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WORKTEAM_ARN = \"\"\n",
    "\n",
    "print(f\"This notebook will use the work team ARN: {WORKTEAM_ARN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75d1c3c",
   "metadata": {},
   "source": [
    "* The IAM execution role you used to create this notebook instance must have the following permissions: \n",
    "    * AWS managed policy [AmazonSageMakerGroundTruthExecution](https://console.aws.amazon.com/iam/home#policies/arn:aws:iam::aws:policy/AmazonSageMakerGroundTruthExecution). Run the following code-block to see your IAM execution role name. This [GIF](add-policy.gif) demonstrates how to add this policy to an IAM role in the IAM console. You can also find instructions in the IAM User Guide: [Adding and removing IAM identity permissions](https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_manage-attach-detach.html#add-policies-console).\n",
    "    * When you create your role, you specify Amazon S3 permissions. Make sure that your IAM role has access to the S3 bucket that you plan to use in this example. If you do not specify an S3 bucket in this notebook, the default bucket in the AWS region you are running this notebook instance will be used. If you do not require granular permissions, you can attach [AmazonS3FullAccess](https://console.aws.amazon.com/iam/home#policies/arn:aws:iam::aws:policy/AmazonS3FullAccess) to your role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c66fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "role_name = role.split(\"/\")[-1]\n",
    "print(\"********************************************************************************\")\n",
    "print(\"The IAM execution role name:\", role_name)\n",
    "print(\"The IAM execution role ARN:\", role)\n",
    "print(\"********************************************************************************\")\n",
    "print(\n",
    "    \"IMPORTANT: Make sure this execution role has the AWS Managed policy AmazonGroundTruthExecution attached.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c144fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize SageMaker session and S3 resource\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "s3 = boto3.resource('s3')\n",
    "s3_client = boto3.client('s3')\n",
    "region = boto3.session.Session().region_name\n",
    "sm_client = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92797cf",
   "metadata": {},
   "source": [
    "## Downloading-the-samsum-Hugging-Face-Dataset\n",
    "\n",
    "In this step, we'll access and download the [samsum dataset](https://huggingface.co/datasets/Samsung/samsum) from the Hugging Face Hub. We'll use the Hugging Face datasets library to efficiently load this data into our working environment. This process allows us to work with a rich, pre-existing dataset without the need to create our own from scratch. By the end of this step, you'll have the raw data ready for exploration and preprocessing.\n",
    "\n",
    "Before proceeding, it's important to note that the use of this dataset is subject to the terms and conditions set by its creators and Hugging Face. Users of this notebook should ensure they comply with the dataset's license, which can be found on the Hugging Face dataset page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896bd011",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "ds = load_dataset(\"samsum\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e7d07b",
   "metadata": {},
   "source": [
    "We will display the first five rows of the ECTSum dataset, giving us a snapshot of the data we're working with. This preview will show us the format of the text passages and their summaries, helping us understand the nature of the summarization task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b2557d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the 'train' split to a pandas DataFrame for easier manipulation\n",
    "df = pd.DataFrame(ds['train'])\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"Dataset size: {len(df)} samples\")\n",
    "print(f\"Columns: {df.columns}\")\n",
    "\n",
    "# Display the first 5 samples\n",
    "print(\"\\nFirst 5 samples:\")\n",
    "for i, row in df.head().iterrows():\n",
    "    print(f\"\\nSample {i + 1}:\")\n",
    "    print(f\"Dialogue:\\n{row['dialogue']}\")\n",
    "    print(f\"Summary:\\n{row['summary']}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Display some statistics about the dialogue and summary lengths\n",
    "df['dialogue_length'] = df['dialogue'].str.split().str.len()\n",
    "df['summary_length'] = df['summary'].str.split().str.len()\n",
    "\n",
    "print(\"\\nDialogue length statistics:\")\n",
    "print(df['dialogue_length'].describe())\n",
    "\n",
    "print(\"\\nSummary length statistics:\")\n",
    "print(df['summary_length'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ce8cac",
   "metadata": {},
   "source": [
    "## Adding-a-unique-ID-and-converting-to-GroundTruth-format\n",
    "\n",
    "In this step, we will prepare our dataset for the human feedback process by adding a unique identifier to each row and restructuring it into the Ground Truth [input manifest format](https://docs.aws.amazon.com/sagemaker/latest/dg/sms-input-data-input-manifest.html). This format is a JSON file where each entry typically contains a \"source\" key pointing to the input dataâ€”in this case, the text. First, we'll generate a \"taskid\" for each entry, ensuring that we can track and manage individual samples throughout the feedback process. This ID will be crucial when associating the original data with the human feedback obtained later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5758e7a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a ground truth input manifest JSON\n",
    "import uuid\n",
    "\n",
    "# Assuming ds['train'] contains the dataset\n",
    "manifest = [\n",
    "    {\n",
    "        \"taskid\": str(uuid.uuid4()),  # Generate a unique task ID\n",
    "        \"source\": item['dialogue'], \n",
    "        \"summary\": item['summary']\n",
    "    } \n",
    "    for item in ds['train']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4073b166",
   "metadata": {},
   "source": [
    "#### Selecting 10 Records to Send to Ground Truth Labeling\n",
    "\n",
    "With the dataset formatted and IDs assigned, we'll now select a small subset of records to be sent for labeling. For testing purposes, we'll choose 10 records to keep the process quick and manageable. However, users can easily increase the number of records for their production workloads as needed.\n",
    "\n",
    "This selection step is crucial for validating the process before scaling up, ensuring that everything works as expected with a manageable amount of data before committing more resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4239ca2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select 10 random records\n",
    "random_sample = random.sample(manifest, 10)\n",
    "\n",
    "# Custom JSON formatting function\n",
    "def custom_json_format(obj):\n",
    "    return json.dumps(obj, ensure_ascii=False)\n",
    "\n",
    "# Write the manifest to a file\n",
    "with open('ground_truth_manifest.json', 'w', encoding='utf-8') as f:\n",
    "    for item in random_sample:\n",
    "        f.write(custom_json_format(item) + '\\n')\n",
    "\n",
    "print(\"Ground truth manifest created with 10 random records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82a4a8d",
   "metadata": {},
   "source": [
    "We'll display a select number of rows from the manifest to confirm that the data is correctly formatted and ready to be used in a Ground Truth labeling job. This step serves as a final check before the data is sent for human-in-the-loop verification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4919877",
   "metadata": {},
   "source": [
    "## Uploading-the-Input-Manifest-to-S3\n",
    "\n",
    "In this step, we will upload the prepared input manifest to an Amazon S3 bucket. Amazon SageMaker Ground Truth requires the input data to be stored in S3 in order to initiate the labeling process. Once uploaded, this S3 object will serve as the input file for the Ground Truth labeling job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a083c0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload the JSON file to an S3 bucket\n",
    "def upload_to_s3(local_file, bucket, s3_file):\n",
    "    s3 = boto3.client('s3')\n",
    "    try:\n",
    "        s3.upload_file(local_file, bucket, s3_file)\n",
    "        print(f\"Upload Successful: {s3_file}\")\n",
    "        return True\n",
    "    except FileNotFoundError:\n",
    "        print(\"The file was not found\")\n",
    "        return False\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available\")\n",
    "        return False\n",
    "\n",
    "# Replace these with your actual S3 bucket details\n",
    "s3_file_path = \"textsummary/ground_truth_manifest.json\"\n",
    "input_manifest_uri = f's3://{bucket}/{s3_file_path}'\n",
    "\n",
    "if upload_to_s3('ground_truth_manifest.json', bucket, s3_file_path):\n",
    "    print(f\"File uploaded to S3: {input_manifest_uri}\")\n",
    "else:\n",
    "    print(\"Upload failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f81090c",
   "metadata": {},
   "source": [
    "## Run-a-Ground-Truth-labeling-job\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743bee7a",
   "metadata": {},
   "source": [
    "### Create-A-Worker-Task-Template\n",
    "\n",
    "The instruction template dictates what is be displayed on the UI at the time when the human annotators review the model responses and update the Summary. \n",
    "\n",
    "UI Structure:\n",
    "\n",
    "- Left Panel (Dialogue): The left side of the interface displays the dialogue from the Samsum dataset. Each conversation, typically between two or more people, will be presented in a clear and structured manner with turn-taking highlighted. The dialogue box allows the annotator to carefully review the full context of the conversation to understand the key points and flow of the interaction.\n",
    "\n",
    "- Right Panel (Summary): The right side of the interface contains the model-generated summary. This summary is based on the conversation shown on the left and should concisely capture the main points of the dialogue. Annotators will evaluate whether the summary aligns with the key information and is coherent, concise, and accurate.\n",
    "\n",
    "- Review: Annotators begin by reading the entire conversation in the left panel. They can scroll through longer dialogues if needed and assess the important aspects of the discussion. Afterward, they will review the summary in the right panel, comparing it with the content of the dialogue to identify discrepancies or inaccuracies.\n",
    "\n",
    "- Adjust: If the summary does not accurately reflect the conversation, annotators will have the option to edit the summary directly in the right panel. They can rewrite, add, or remove sections to ensure the summary is a true representation of the dialogue. The edits are expected to capture the core information without deviating from the intent of the original conversation.\n",
    "\n",
    "- Submit: Once the summary is adjusted, the annotator will submit their revised version. The updated summaries will be used to train and fine-tune the underlying summarization model, thereby improving its performance based on real-world human feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c596fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def make_template(save_fname=\"instructions_tr.template\"):\n",
    "    template = \"\"\"\n",
    "<script src=\"https://assets.crowd.aws/crowd-html-elements.js\"></script>\n",
    "\n",
    "<crowd-form>\n",
    "  <div style=\"display: flex; min-height: 600px;\">\n",
    "    <!-- Left Panel: Source Text in Scrollable Container -->\n",
    "    <div style=\"flex: 1; padding: 20px; border-right: 1px solid #ccc; display: flex; flex-direction: column;\">\n",
    "      <h3>Source Text</h3>\n",
    "      <div style=\"flex: 1; overflow-y: auto; border: 1px solid #ccc; padding: 10px; margin-bottom: 20px; max-height: 600px;\">\n",
    "        <p style=\"white-space: pre-wrap;\">{{ task.input.source }}</p>\n",
    "      </div>\n",
    "    </div>\n",
    "\n",
    "    <!-- Right Panel: Summary and Questions -->\n",
    "    <div style=\"flex: 1; padding: 20px; display: flex; flex-direction: column;\">\n",
    "      <h3>Summary</h3>\n",
    "      <crowd-text-area \n",
    "        name=\"summary\" \n",
    "        rows=\"10\" \n",
    "        value=\"{{ task.input.summary }}\"\n",
    "        required\n",
    "      ></crowd-text-area>\n",
    "\n",
    "      <div style=\"margin-top: 20px;\">\n",
    "        <h4>How do you rate the model response? (1-10)</h4>\n",
    "        <crowd-slider \n",
    "          name=\"rating\" \n",
    "          min=\"1\" \n",
    "          max=\"10\" \n",
    "          step=\"1\" \n",
    "          pin=\"true\" \n",
    "          required\n",
    "        ></crowd-slider>\n",
    "      </div>\n",
    "\n",
    "      <!-- Submit button -->\n",
    "      <div style=\"margin-top: 20px; text-align: right;\">\n",
    "        <crowd-button variant=\"primary\" form-action=\"submit\">Submit</crowd-button>\n",
    "      </div>\n",
    "    </div>\n",
    "  </div>\n",
    "</crowd-form>\n",
    "    \"\"\"\n",
    "    with open(save_fname, \"w\") as f:\n",
    "        f.write(template)\n",
    "\n",
    "# Create the template file locally\n",
    "make_template(save_fname=\"./instructions_tr.template\")\n",
    "\n",
    "# Define the S3 path\n",
    "file_name = 'instructions_tr.template'\n",
    "prefix = 'uitemplate'\n",
    "ui_s3_path = f\"{prefix}/{file_name}\"\n",
    "UITEMPLATES3URI = f\"s3://{bucket}/{ui_s3_path}\"\n",
    "\n",
    "# Upload the file to S3 using the s3 client\n",
    "s3_client.upload_file(\"./instructions_tr.template\", bucket, ui_s3_path)\n",
    "\n",
    "print(f\"File uploaded to {UITEMPLATES3URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66766e0",
   "metadata": {},
   "source": [
    "### Submit-the-Ground-Truth-job-request\n",
    "\n",
    "The API starts a Ground Truth job by submitting a request. The request contains the full configuration of the annotation task, and allows you to modify the fine details of the job that are fixed to default values when you use the AWS Console. The parameters that make up the request are described in more detail in the SageMaker Ground Truth documentation.\n",
    "\n",
    "After you submit the request, you should be able to see the job in your AWS Console, at Amazon SageMaker > Labeling Jobs. You can track the progress of the job there. This job will take several hours to complete. If your job is larger (say 10,000 review text), the speed and cost benefit of auto-labeling should be larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f7ef4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "timestamp_str = now.strftime(\"%Y%m%d-%H%M%S\")\n",
    "labeling_job_name = \"genai-text-summarization-\" + timestamp_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0b16ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = boto3.client('sagemaker')\n",
    "\n",
    "client.create_labeling_job(\n",
    "    LabelingJobName=labeling_job_name,\n",
    "    LabelAttributeName='label',\n",
    "    InputConfig={\n",
    "        'DataSource': {\n",
    "            'S3DataSource': {\n",
    "                'ManifestS3Uri': input_manifest_uri #Enter S3 URI of Input Data Json\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    OutputConfig={\n",
    "        'S3OutputPath': f's3://{bucket}/output/' #Enter S3 URI of Output folder\n",
    "    },\n",
    "    RoleArn=role, #Enter IAM Sagemaker Execution Role here,\n",
    "    HumanTaskConfig={\n",
    "        'WorkteamArn': WORKTEAM_ARN, #Enter Workteam ARN\n",
    "        'UiConfig': {\n",
    "            'UiTemplateS3Uri': UITEMPLATES3URI #Enter S3 URI of UI template\n",
    "        },\n",
    "        'TaskKeywords': [\n",
    "            'QnA',\n",
    "        ],\n",
    "        'TaskTitle': 'Generative AI - Dialogue Summarization',\n",
    "        'TaskDescription': \"Adjust the Summary provided by the Model based on the Full text on the left\",\n",
    "        'NumberOfHumanWorkersPerDataObject': 1,\n",
    "        'TaskTimeLimitInSeconds': 60*30,\n",
    "        'TaskAvailabilityLifetimeInSeconds': 60*60*24*10,\n",
    "        'MaxConcurrentTaskCount': 100\n"
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d5f7b4",
   "metadata": {},
   "source": [
    "### Monitor the Status of Labeling Job using the DescribeLabelingJob API\n",
    "\n",
    "We track the status of the ongoing labeling job. It is essential to monitor the job's progress and wait for its completion by the annotators. Once the labeling job is finished, we can then proceed to gather feedback from the annotators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac0255a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "workforce = sm_client.describe_workforce(WorkforceName=\"default\")\n",
    "worker_portal_url = 'https://' + workforce[\"Workforce\"][\"SubDomain\"]\n",
    "\n",
    "\n",
    "# Display the URL and instructions\n",
    "display(HTML(f\"\"\"\n",
    "<body>\n",
    "<h3>Gather human preference data</h3>\n",
    "<p>Please complete the human evaluation tasks available in the labeling portal.</p>\n",
    "<p><a href=\"{worker_portal_url}\">{worker_portal_url}</a>\n",
    "<p><b>Ensure all tasks are completed before proceeding to the next steps in this notebook.<b></p>\n",
    "<body>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fdcfaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm_client.describe_labeling_job(LabelingJobName=labeling_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c244eb",
   "metadata": {},
   "source": [
    "## Integrate-Human-Feedback-into-samsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d97815-24a5-4f22-98bf-38c547470566",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_key = f'output/{labeling_job_name}/manifests/output/output.manifest'\n",
    "\n",
    "# Read the file from S3\n",
    "response = s3_client.get_object(Bucket=bucket, Key=file_key)\n",
    "lines = response['Body'].read().decode('utf-8').splitlines()\n",
    "\n",
    "# Process the file and extract the desired data\n",
    "output_data = []\n",
    "for line in lines:\n",
    "    data = json.loads(line)\n",
    "    task_id = data['taskid']\n",
    "    source = data['source']\n",
    "    \n",
    "    # Get the worker response file reference\n",
    "    worker_response_ref = data['label-metadata']['worker-response-ref']\n",
    "    \n",
    "    # Extract the worker response file key from the S3 URI\n",
    "    worker_response_key = '/'.join(worker_response_ref.split('/')[3:])\n",
    "    \n",
    "    # Read the worker response file\n",
    "    worker_response = s3_client.get_object(Bucket=bucket, Key=worker_response_key)\n",
    "    worker_data = json.loads(worker_response['Body'].read().decode('utf-8'))\n",
    "    \n",
    "    # Extract the summary from the worker response\n",
    "    summary = worker_data['answers'][0]['answerContent']['summary']\n",
    "    \n",
    "    # Prepare the output dictionary\n",
    "    output = {\n",
    "        'taskid': task_id,\n",
    "        'text': source,\n",
    "        'summary': summary\n",
    "    }\n",
    "    \n",
    "    output_data.append(output)\n",
    "\n",
    "# Convert the output to JSON\n",
    "output_json = json.dumps(output_data, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2223cfe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "\n",
    "# Parse the Ground Truth output\n",
    "ground_truth_output = json.loads(output_json)\n",
    "\n",
    "# Create a dictionary mapping taskid to updated summary from Ground Truth output\n",
    "updated_summaries = {item['taskid']: item['summary'] for item in ground_truth_output}\n",
    "\n",
    "# Update the manifest with new summaries\n",
    "updated_manifest = []\n",
    "for item in manifest:\n",
    "    if item['taskid'] in updated_summaries:\n",
    "        item['summary'] = updated_summaries[item['taskid']]\n",
    "    updated_manifest.append(item)\n",
    "\n",
    "# Convert the updated manifest to JSON\n",
    "updated_json = json.dumps(updated_manifest, indent=2)\n",
    "\n",
    "# Function to upload to S3\n",
    "def upload_to_s3(json_data, bucket, s3_file):\n",
    "    s3 = boto3.client('s3')\n",
    "    try:\n",
    "        s3.put_object(Body=json_data, Bucket=bucket, Key=s3_file)\n",
    "        print(f\"Upload Successful: s3://{bucket}/{s3_file}\")\n",
    "        return True\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available\")\n",
    "        return False\n",
    "\n",
    "# S3 bucket and file details\n",
    "s3_file_path = \"sagemaker/datasets/sum/updated_dataset_samsum.json\"\n",
    "# Upload to S3\n",
    "if upload_to_s3(updated_json, bucket, s3_file_path):\n",
    "    print(\"File uploaded successfully\")\n",
    "else:\n",
    "    print(\"Failed to upload file\")\n",
    "\n",
    "# Print statistics\n",
    "total_records = len(manifest)\n",
    "updated_records = sum(1 for item in updated_manifest if item['taskid'] in updated_summaries)\n",
    "print(f\"Total records in manifest: {total_records}\")\n",
    "print(f\"Records updated: {updated_records}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
